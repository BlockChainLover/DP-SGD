{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahaichao/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "# The main BackPACK functionalities\n",
    "from backpack import backpack, extend\n",
    "# The diagonal GGN extension\n",
    "from backpack.extensions import DiagGGNMC\n",
    "# This layer did not exist in Pytorch 1.0\n",
    "#from backpack.cores import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6cb8588270>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "STEP_SIZE = 0.01\n",
    "DAMPING = 1.0\n",
    "MAX_ITER = 100\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 10)\n",
    ")\n",
    "lossfunc = torch.nn.CrossEntropyLoss()\n",
    "model = extend(model)\n",
    "lossfunc = extend(lossfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import rand\n",
    "from torch.nn import CrossEntropyLoss, Flatten, Linear, Sequential\n",
    "\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import (\n",
    "    GGNMP,\n",
    "    HMP,\n",
    "    KFAC,\n",
    "    KFLR,\n",
    "    KFRA,\n",
    "    PCHMP,\n",
    "    BatchDiagGGNExact,\n",
    "    BatchDiagGGNMC,\n",
    "    BatchDiagHessian,\n",
    "    BatchGrad,\n",
    "    BatchL2Grad,\n",
    "    DiagGGNExact,\n",
    "    DiagGGNMC,\n",
    "    DiagHessian,\n",
    "    SqrtGGNExact,\n",
    "    SqrtGGNMC,\n",
    "    SumGradSquared,\n",
    "    Variance,\n",
    ")\n",
    "from backpack.utils.examples import load_one_batch_mnist\n",
    "\n",
    "X, y = load_one_batch_mnist(batch_size=516)\n",
    "\n",
    "model = Sequential(Flatten(), Linear(784, 10))\n",
    "lossfunc = CrossEntropyLoss()\n",
    "\n",
    "model = extend(model)\n",
    "lossfunc = extend(lossfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight\n",
      ".grad.shape:              torch.Size([10, 784])\n",
      ".grad_batch.shape:        torch.Size([516, 10, 784])\n",
      "1.bias\n",
      ".grad.shape:              torch.Size([10])\n",
      ".grad_batch.shape:        torch.Size([516, 10])\n"
     ]
    }
   ],
   "source": [
    "loss = lossfunc(model(X), y)\n",
    "with backpack(BatchGrad()):\n",
    "    loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(\".grad.shape:             \", param.grad.shape)\n",
    "    #print(\".grad.shape:             \", param.grad)\n",
    "    print(\".grad_batch.shape:       \", param.grad_batch.shape)\n",
    "    #print(\".grad_batch.shape:             \", param.grad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([516, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.grad_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight\n",
      ".grad.shape:              torch.Size([10, 784])\n",
      "tensor([[6.7788e-08, 6.7788e-08, 6.7788e-08,  ..., 6.7788e-08, 6.7788e-08,\n",
      "         6.7788e-08],\n",
      "        [7.3879e-08, 7.3879e-08, 7.3879e-08,  ..., 7.3879e-08, 7.3879e-08,\n",
      "         7.3879e-08],\n",
      "        [4.6309e-08, 4.6309e-08, 4.6309e-08,  ..., 4.6309e-08, 4.6309e-08,\n",
      "         4.6309e-08],\n",
      "        ...,\n",
      "        [5.2762e-08, 5.2762e-08, 5.2762e-08,  ..., 5.2762e-08, 5.2762e-08,\n",
      "         5.2762e-08],\n",
      "        [5.3723e-08, 5.3723e-08, 5.3723e-08,  ..., 5.3723e-08, 5.3723e-08,\n",
      "         5.3723e-08],\n",
      "        [5.2177e-08, 5.2177e-08, 5.2177e-08,  ..., 5.2177e-08, 5.2177e-08,\n",
      "         5.2177e-08]])\n",
      ".variance.shape:          torch.Size([10, 784])\n",
      "1.bias\n",
      ".grad.shape:              torch.Size([10])\n",
      "tensor([3.7669e-07, 4.1054e-07, 2.5734e-07, 3.8201e-07, 3.1100e-07, 3.2592e-07,\n",
      "        4.3967e-07, 2.9320e-07, 2.9853e-07, 2.8994e-07])\n",
      ".variance.shape:          torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "loss = lossfunc(model(X), y)\n",
    "with backpack(Variance()):\n",
    "    loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(\".grad.shape:             \", param.grad.shape)\n",
    "    print(param.variance)\n",
    "    print(\".variance.shape:         \", param.variance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x7ff030843970>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight\n",
      "tensor([[-0.0218, -0.0218, -0.0218,  ..., -0.0218, -0.0218, -0.0218],\n",
      "        [ 0.0834,  0.0834,  0.0834,  ...,  0.0834,  0.0834,  0.0834],\n",
      "        [-0.0731, -0.0731, -0.0731,  ..., -0.0731, -0.0731, -0.0731],\n",
      "        ...,\n",
      "        [-0.0252, -0.0252, -0.0252,  ..., -0.0252, -0.0252, -0.0252],\n",
      "        [-0.0195, -0.0195, -0.0195,  ..., -0.0195, -0.0195, -0.0195],\n",
      "        [ 0.0027,  0.0027,  0.0027,  ...,  0.0027,  0.0027,  0.0027]])\n",
      ".grad.shape:              torch.Size([10, 784])\n",
      "tensor([[3.5081e-05, 3.5081e-05, 3.5081e-05,  ..., 3.5081e-05, 3.5081e-05,\n",
      "         3.5081e-05],\n",
      "        [3.9619e-05, 3.9619e-05, 3.9619e-05,  ..., 3.9619e-05, 3.9619e-05,\n",
      "         3.9619e-05],\n",
      "        [2.5046e-05, 2.5046e-05, 2.5046e-05,  ..., 2.5046e-05, 2.5046e-05,\n",
      "         2.5046e-05],\n",
      "        ...,\n",
      "        [2.7363e-05, 2.7363e-05, 2.7363e-05,  ..., 2.7363e-05, 2.7363e-05,\n",
      "         2.7363e-05],\n",
      "        [2.7803e-05, 2.7803e-05, 2.7803e-05,  ..., 2.7803e-05, 2.7803e-05,\n",
      "         2.7803e-05],\n",
      "        [2.6925e-05, 2.6925e-05, 2.6925e-05,  ..., 2.6925e-05, 2.6925e-05,\n",
      "         2.6925e-05]])\n",
      ".sum_grad_squared.shape:  torch.Size([10, 784])\n",
      "1.bias\n",
      "tensor([ 0.0514, -0.1966,  0.1723,  0.0202, -0.0877,  0.1162, -0.1749,  0.0595,\n",
      "         0.0461, -0.0064])\n",
      ".grad.shape:              torch.Size([10])\n",
      "tensor([0.0002, 0.0002, 0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0001])\n",
      ".sum_grad_squared.shape:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "loss = lossfunc(model(X), y)\n",
    "with backpack(SumGradSquared()):\n",
    "    loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.grad)\n",
    "    print(\".grad.shape:             \", param.grad.shape)\n",
    "    print(param.sum_grad_squared)\n",
    "    print(\".sum_grad_squared.shape: \", param.sum_grad_squared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0514, -0.1966,  0.1723,  0.0202, -0.0877,  0.1162, -0.1749,  0.0595,\n",
       "         0.0461, -0.0064])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight\n",
      ".grad.shape:              torch.Size([10, 784])\n",
      "tensor([0.0023, 0.0029, 0.0039, 0.0024, 0.0023, 0.0057, 0.0024, 0.0013, 0.0024,\n",
      "        0.0037, 0.0028, 0.0026, 0.0018, 0.0013, 0.0021, 0.0029, 0.0020, 0.0018,\n",
      "        0.0039, 0.0018, 0.0018, 0.0017, 0.0019, 0.0048, 0.0026, 0.0029, 0.0045,\n",
      "        0.0028, 0.0027, 0.0014, 0.0027, 0.0036, 0.0016, 0.0027, 0.0033, 0.0029,\n",
      "        0.0022, 0.0025, 0.0016, 0.0022, 0.0017, 0.0026, 0.0017, 0.0045, 0.0021,\n",
      "        0.0022, 0.0028, 0.0027, 0.0063, 0.0027, 0.0022, 0.0023, 0.0027, 0.0027,\n",
      "        0.0020, 0.0032, 0.0020, 0.0018, 0.0029, 0.0016, 0.0032, 0.0022, 0.0035,\n",
      "        0.0025, 0.0018, 0.0013, 0.0026, 0.0035, 0.0019, 0.0024, 0.0036, 0.0050,\n",
      "        0.0038, 0.0015, 0.0053, 0.0030, 0.0032, 0.0046, 0.0028, 0.0032, 0.0028,\n",
      "        0.0038, 0.0031, 0.0040, 0.0021, 0.0024, 0.0037, 0.0033, 0.0018, 0.0022,\n",
      "        0.0032, 0.0022, 0.0029, 0.0024, 0.0019, 0.0021, 0.0018, 0.0015, 0.0027,\n",
      "        0.0029, 0.0029, 0.0029, 0.0029, 0.0025, 0.0025, 0.0027, 0.0025, 0.0023,\n",
      "        0.0039, 0.0014, 0.0034, 0.0034, 0.0021, 0.0021, 0.0023, 0.0029, 0.0020,\n",
      "        0.0045, 0.0024, 0.0014, 0.0015, 0.0022, 0.0046, 0.0025, 0.0028, 0.0024,\n",
      "        0.0029, 0.0030, 0.0025, 0.0042, 0.0036, 0.0029, 0.0018, 0.0043, 0.0029,\n",
      "        0.0025, 0.0035, 0.0026, 0.0019, 0.0021, 0.0020, 0.0035, 0.0022, 0.0032,\n",
      "        0.0029, 0.0023, 0.0022, 0.0035, 0.0030, 0.0034, 0.0023, 0.0043, 0.0026,\n",
      "        0.0015, 0.0015, 0.0026, 0.0036, 0.0038, 0.0020, 0.0036, 0.0013, 0.0028,\n",
      "        0.0024, 0.0031, 0.0014, 0.0018, 0.0028, 0.0025, 0.0021, 0.0019, 0.0032,\n",
      "        0.0022, 0.0017, 0.0033, 0.0022, 0.0031, 0.0030, 0.0032, 0.0015, 0.0014,\n",
      "        0.0029, 0.0038, 0.0015, 0.0030, 0.0017, 0.0025, 0.0033, 0.0020, 0.0017,\n",
      "        0.0040, 0.0029, 0.0029, 0.0029, 0.0032, 0.0032, 0.0015, 0.0033, 0.0023,\n",
      "        0.0016, 0.0036, 0.0018, 0.0024, 0.0040, 0.0032, 0.0018, 0.0021, 0.0028,\n",
      "        0.0025, 0.0032, 0.0025, 0.0029, 0.0034, 0.0035, 0.0012, 0.0022, 0.0040,\n",
      "        0.0035, 0.0020, 0.0029, 0.0040, 0.0014, 0.0029, 0.0026, 0.0026, 0.0028,\n",
      "        0.0038, 0.0030, 0.0012, 0.0024, 0.0039, 0.0021, 0.0037, 0.0040, 0.0026,\n",
      "        0.0046, 0.0027, 0.0030, 0.0018, 0.0024, 0.0041, 0.0021, 0.0025, 0.0022,\n",
      "        0.0018, 0.0014, 0.0062, 0.0019, 0.0027, 0.0039, 0.0020, 0.0024, 0.0042,\n",
      "        0.0021, 0.0041, 0.0045, 0.0026, 0.0017, 0.0025, 0.0031, 0.0021, 0.0029,\n",
      "        0.0032, 0.0020, 0.0018, 0.0034, 0.0033, 0.0019, 0.0011, 0.0026, 0.0034,\n",
      "        0.0029, 0.0022, 0.0041, 0.0017, 0.0037, 0.0015, 0.0030, 0.0023, 0.0039,\n",
      "        0.0051, 0.0021, 0.0018, 0.0032, 0.0028, 0.0016, 0.0034, 0.0024, 0.0025,\n",
      "        0.0027, 0.0026, 0.0026, 0.0030, 0.0024, 0.0022, 0.0022, 0.0029, 0.0027,\n",
      "        0.0034, 0.0020, 0.0035, 0.0014, 0.0028, 0.0040, 0.0036, 0.0012, 0.0018,\n",
      "        0.0033, 0.0024, 0.0030, 0.0027, 0.0027, 0.0024, 0.0043, 0.0043, 0.0027,\n",
      "        0.0025, 0.0032, 0.0023, 0.0032, 0.0019, 0.0014, 0.0036, 0.0051, 0.0040,\n",
      "        0.0039, 0.0025, 0.0030, 0.0035, 0.0023, 0.0019, 0.0019, 0.0027, 0.0040,\n",
      "        0.0025, 0.0021, 0.0013, 0.0022, 0.0046, 0.0044, 0.0031, 0.0034, 0.0032,\n",
      "        0.0027, 0.0030, 0.0022, 0.0023, 0.0036, 0.0034, 0.0018, 0.0025, 0.0043,\n",
      "        0.0028, 0.0046, 0.0027, 0.0021, 0.0032, 0.0040, 0.0027, 0.0033, 0.0017,\n",
      "        0.0027, 0.0030, 0.0048, 0.0020, 0.0025, 0.0024, 0.0028, 0.0017, 0.0032,\n",
      "        0.0019, 0.0024, 0.0033, 0.0019, 0.0012, 0.0040, 0.0033, 0.0029, 0.0027,\n",
      "        0.0028, 0.0028, 0.0017, 0.0031, 0.0016, 0.0028, 0.0025, 0.0022, 0.0014,\n",
      "        0.0046, 0.0048, 0.0018, 0.0035, 0.0026, 0.0022, 0.0018, 0.0021, 0.0026,\n",
      "        0.0016, 0.0035, 0.0012, 0.0013, 0.0046, 0.0020, 0.0018, 0.0015, 0.0019,\n",
      "        0.0014, 0.0039, 0.0022, 0.0021, 0.0015, 0.0022, 0.0038, 0.0012, 0.0014,\n",
      "        0.0049, 0.0028, 0.0028, 0.0014, 0.0019, 0.0025, 0.0020, 0.0011, 0.0029,\n",
      "        0.0024, 0.0025, 0.0049, 0.0021, 0.0032, 0.0015, 0.0023, 0.0026, 0.0022,\n",
      "        0.0023, 0.0027, 0.0026, 0.0035, 0.0016, 0.0041, 0.0025, 0.0046, 0.0026,\n",
      "        0.0016, 0.0018, 0.0035, 0.0033, 0.0011, 0.0032, 0.0026, 0.0055, 0.0027,\n",
      "        0.0018, 0.0017, 0.0039, 0.0019, 0.0031, 0.0025, 0.0022, 0.0014, 0.0021,\n",
      "        0.0017, 0.0034, 0.0018, 0.0034, 0.0032, 0.0024, 0.0014, 0.0020, 0.0017,\n",
      "        0.0028, 0.0037, 0.0042, 0.0045, 0.0022, 0.0020, 0.0033, 0.0029, 0.0036,\n",
      "        0.0035, 0.0023, 0.0041, 0.0036, 0.0026, 0.0035, 0.0042, 0.0019, 0.0018,\n",
      "        0.0036, 0.0043, 0.0040, 0.0045, 0.0015, 0.0024, 0.0018, 0.0036, 0.0024,\n",
      "        0.0033, 0.0014, 0.0029, 0.0010, 0.0026, 0.0031, 0.0029, 0.0019, 0.0023,\n",
      "        0.0012, 0.0031, 0.0020, 0.0023, 0.0039, 0.0035, 0.0037, 0.0029, 0.0026,\n",
      "        0.0037, 0.0019, 0.0047])\n",
      ".batch_l2.shape:          torch.Size([516])\n",
      "1.bias\n",
      ".grad.shape:              torch.Size([10])\n",
      "tensor([3.1502e-06, 3.5684e-06, 4.1981e-06, 3.5316e-06, 3.3082e-06, 4.4562e-06,\n",
      "        2.6961e-06, 3.0004e-06, 3.4506e-06, 3.7239e-06, 3.6732e-06, 4.0367e-06,\n",
      "        3.0085e-06, 3.3835e-06, 3.5026e-06, 3.7332e-06, 3.2224e-06, 3.4809e-06,\n",
      "        3.5981e-06, 3.0844e-06, 3.0736e-06, 3.4549e-06, 3.6218e-06, 3.8512e-06,\n",
      "        2.9685e-06, 3.3008e-06, 3.9312e-06, 3.7365e-06, 3.6433e-06, 2.7740e-06,\n",
      "        3.1213e-06, 3.8965e-06, 3.6018e-06, 3.8239e-06, 3.0184e-06, 3.2014e-06,\n",
      "        3.5518e-06, 3.0626e-06, 3.6177e-06, 3.2726e-06, 3.2432e-06, 3.6371e-06,\n",
      "        3.3684e-06, 3.3315e-06, 3.5265e-06, 3.9848e-06, 3.1271e-06, 3.2102e-06,\n",
      "        3.9511e-06, 3.3170e-06, 3.6596e-06, 3.0403e-06, 2.9387e-06, 3.8590e-06,\n",
      "        3.7765e-06, 3.9643e-06, 3.0758e-06, 2.9899e-06, 3.5556e-06, 2.5635e-06,\n",
      "        3.7017e-06, 3.5640e-06, 2.8102e-06, 3.6749e-06, 3.3700e-06, 3.1482e-06,\n",
      "        3.6881e-06, 3.4630e-06, 3.1370e-06, 3.1656e-06, 3.2402e-06, 3.9411e-06,\n",
      "        3.4203e-06, 3.3839e-06, 3.7313e-06, 3.1515e-06, 3.9930e-06, 3.7438e-06,\n",
      "        2.1396e-06, 3.7856e-06, 2.7381e-06, 3.6051e-06, 3.5073e-06, 3.9133e-06,\n",
      "        3.1606e-06, 2.6713e-06, 3.3049e-06, 3.6211e-06, 3.0212e-06, 3.6670e-06,\n",
      "        3.8959e-06, 3.5997e-06, 3.7731e-06, 3.7621e-06, 3.9107e-06, 3.6346e-06,\n",
      "        2.8761e-06, 3.5198e-06, 3.3231e-06, 4.1585e-06, 3.6501e-06, 3.1567e-06,\n",
      "        3.7247e-06, 3.4614e-06, 3.7440e-06, 3.7934e-06, 3.4350e-06, 3.4797e-06,\n",
      "        3.8676e-06, 3.0089e-06, 3.2431e-06, 2.8354e-06, 3.8098e-06, 3.3257e-06,\n",
      "        3.3441e-06, 3.3578e-06, 3.3407e-06, 3.5995e-06, 3.2535e-06, 3.2597e-06,\n",
      "        3.0105e-06, 3.1459e-06, 4.1322e-06, 3.9726e-06, 3.3005e-06, 3.4861e-06,\n",
      "        3.5447e-06, 2.9447e-06, 3.6697e-06, 3.4759e-06, 3.6846e-06, 3.4509e-06,\n",
      "        3.2176e-06, 4.2750e-06, 2.8234e-06, 3.8152e-06, 3.7107e-06, 3.1282e-06,\n",
      "        2.8967e-06, 3.3958e-06, 3.5396e-06, 3.5600e-06, 3.9194e-06, 3.5886e-06,\n",
      "        3.7175e-06, 3.5172e-06, 3.4915e-06, 3.8741e-06, 3.2812e-06, 3.4716e-06,\n",
      "        3.2722e-06, 3.1838e-06, 3.8885e-06, 3.5397e-06, 3.5009e-06, 3.1826e-06,\n",
      "        3.3115e-06, 3.0477e-06, 3.2815e-06, 2.5418e-06, 3.6314e-06, 3.1968e-06,\n",
      "        3.7412e-06, 3.9913e-06, 2.3452e-06, 3.7101e-06, 3.3966e-06, 3.0292e-06,\n",
      "        3.9065e-06, 3.4049e-06, 3.9680e-06, 2.5015e-06, 2.2410e-06, 4.0279e-06,\n",
      "        3.5827e-06, 3.9844e-06, 3.9933e-06, 3.6696e-06, 2.5949e-06, 2.6980e-06,\n",
      "        3.5497e-06, 3.4833e-06, 3.2314e-06, 2.5241e-06, 2.9509e-06, 3.4170e-06,\n",
      "        2.6914e-06, 3.0595e-06, 2.5511e-06, 4.1441e-06, 3.9999e-06, 3.3281e-06,\n",
      "        3.7318e-06, 3.6789e-06, 3.1349e-06, 3.1802e-06, 2.9893e-06, 3.6436e-06,\n",
      "        3.5039e-06, 3.8108e-06, 2.9006e-06, 3.2531e-06, 3.2055e-06, 4.0360e-06,\n",
      "        3.7716e-06, 3.2918e-06, 3.3919e-06, 3.1594e-06, 3.0901e-06, 3.5797e-06,\n",
      "        3.9442e-06, 3.8548e-06, 3.6587e-06, 2.8934e-06, 2.5004e-06, 3.6547e-06,\n",
      "        4.0257e-06, 3.5929e-06, 3.4851e-06, 4.1599e-06, 2.4587e-06, 3.9523e-06,\n",
      "        3.2664e-06, 3.8410e-06, 2.8467e-06, 3.2210e-06, 3.8972e-06, 2.1877e-06,\n",
      "        3.6868e-06, 3.7167e-06, 3.4919e-06, 3.9531e-06, 3.8295e-06, 4.1437e-06,\n",
      "        3.7421e-06, 2.5929e-06, 3.6261e-06, 2.7226e-06, 3.2280e-06, 4.1359e-06,\n",
      "        2.6670e-06, 3.7853e-06, 3.0738e-06, 3.1788e-06, 3.3750e-06, 4.1177e-06,\n",
      "        2.6566e-06, 2.7687e-06, 3.9236e-06, 3.5788e-06, 2.4733e-06, 3.7583e-06,\n",
      "        3.2666e-06, 3.4366e-06, 3.9159e-06, 3.2847e-06, 3.5044e-06, 2.6664e-06,\n",
      "        3.3411e-06, 3.6998e-06, 3.5997e-06, 3.5025e-06, 3.2293e-06, 3.6230e-06,\n",
      "        3.7673e-06, 3.7761e-06, 2.2530e-06, 3.0128e-06, 3.3619e-06, 2.7299e-06,\n",
      "        3.5291e-06, 3.5275e-06, 3.9521e-06, 2.8393e-06, 3.7940e-06, 3.4142e-06,\n",
      "        3.0573e-06, 2.6496e-06, 3.2707e-06, 4.2398e-06, 3.5692e-06, 3.3316e-06,\n",
      "        4.1154e-06, 3.2975e-06, 3.6245e-06, 2.3689e-06, 3.2605e-06, 3.4890e-06,\n",
      "        3.3707e-06, 3.4587e-06, 3.4689e-06, 4.0235e-06, 3.6557e-06, 3.5340e-06,\n",
      "        3.9108e-06, 3.6223e-06, 3.2264e-06, 3.2572e-06, 3.7449e-06, 3.7370e-06,\n",
      "        3.0195e-06, 3.1304e-06, 4.4417e-06, 3.5040e-06, 3.4803e-06, 3.9472e-06,\n",
      "        3.4964e-06, 3.8354e-06, 3.6282e-06, 3.1577e-06, 3.5026e-06, 3.3114e-06,\n",
      "        3.8919e-06, 4.0325e-06, 4.0096e-06, 3.9329e-06, 3.7163e-06, 3.3221e-06,\n",
      "        3.8785e-06, 3.6686e-06, 3.0396e-06, 3.6510e-06, 3.5528e-06, 3.7581e-06,\n",
      "        3.4976e-06, 3.4536e-06, 3.8880e-06, 4.1998e-06, 3.5352e-06, 3.2970e-06,\n",
      "        2.6486e-06, 3.0405e-06, 3.3627e-06, 3.2907e-06, 3.9529e-06, 3.5499e-06,\n",
      "        3.2769e-06, 3.4938e-06, 3.9087e-06, 3.9269e-06, 4.0899e-06, 2.9589e-06,\n",
      "        3.7878e-06, 3.4768e-06, 3.6835e-06, 3.3116e-06, 3.9022e-06, 3.7327e-06,\n",
      "        3.3301e-06, 3.4383e-06, 3.9314e-06, 3.8048e-06, 3.6496e-06, 3.5114e-06,\n",
      "        2.7938e-06, 3.1551e-06, 4.0861e-06, 2.7555e-06, 3.0572e-06, 3.3341e-06,\n",
      "        3.1953e-06, 3.9328e-06, 3.5558e-06, 3.9995e-06, 3.5389e-06, 3.5376e-06,\n",
      "        3.2321e-06, 3.2319e-06, 3.7816e-06, 3.1699e-06, 3.4946e-06, 2.8759e-06,\n",
      "        3.0734e-06, 2.7099e-06, 3.7046e-06, 2.8153e-06, 3.5867e-06, 3.6169e-06,\n",
      "        3.5326e-06, 3.6554e-06, 3.5317e-06, 2.5741e-06, 3.5453e-06, 3.6589e-06,\n",
      "        2.9758e-06, 3.4549e-06, 3.2551e-06, 3.1500e-06, 3.6893e-06, 3.6733e-06,\n",
      "        3.2452e-06, 3.7121e-06, 3.6652e-06, 3.4980e-06, 2.5292e-06, 2.9014e-06,\n",
      "        2.6361e-06, 3.8453e-06, 2.9912e-06, 3.6862e-06, 4.0093e-06, 3.4542e-06,\n",
      "        3.2209e-06, 3.1104e-06, 3.2537e-06, 3.2886e-06, 3.9711e-06, 3.5684e-06,\n",
      "        3.4961e-06, 3.4929e-06, 3.4769e-06, 3.9268e-06, 3.0639e-06, 2.8362e-06,\n",
      "        3.9249e-06, 3.4210e-06, 3.7804e-06, 3.4164e-06, 3.8262e-06, 3.6862e-06,\n",
      "        3.4667e-06, 3.2741e-06, 3.9729e-06, 2.9735e-06, 3.7344e-06, 3.3987e-06,\n",
      "        3.2698e-06, 2.9566e-06, 3.5259e-06, 3.7014e-06, 3.3475e-06, 2.6190e-06,\n",
      "        3.6457e-06, 3.6704e-06, 3.0857e-06, 3.7838e-06, 3.7846e-06, 3.9777e-06,\n",
      "        3.5742e-06, 3.7288e-06, 3.4299e-06, 3.6565e-06, 3.7197e-06, 3.2810e-06,\n",
      "        3.5722e-06, 2.9842e-06, 2.6696e-06, 3.4664e-06, 4.3343e-06, 3.6800e-06,\n",
      "        2.8616e-06, 3.7912e-06, 3.1525e-06, 3.3505e-06, 3.8930e-06, 3.5786e-06,\n",
      "        3.7855e-06, 3.4192e-06, 3.9591e-06, 3.6617e-06, 2.7193e-06, 2.7117e-06,\n",
      "        3.2986e-06, 4.0080e-06, 3.4592e-06, 2.7756e-06, 3.5441e-06, 3.9424e-06,\n",
      "        3.1246e-06, 4.0278e-06, 3.9375e-06, 3.9690e-06, 3.0195e-06, 3.3618e-06,\n",
      "        3.1368e-06, 4.0165e-06, 3.4435e-06, 2.9407e-06, 3.5822e-06, 3.1937e-06,\n",
      "        3.4260e-06, 3.9065e-06, 3.3087e-06, 4.0019e-06, 2.8651e-06, 3.2336e-06,\n",
      "        4.0884e-06, 4.0162e-06, 3.4258e-06, 2.4899e-06, 3.3440e-06, 2.8784e-06,\n",
      "        3.5137e-06, 2.8092e-06, 3.2323e-06, 3.4905e-06, 3.2204e-06, 3.3465e-06,\n",
      "        2.5757e-06, 3.7267e-06, 3.2827e-06, 3.4991e-06, 2.9408e-06, 3.5266e-06,\n",
      "        3.5887e-06, 3.0643e-06, 3.5048e-06, 3.2831e-06, 3.8422e-06, 3.8102e-06,\n",
      "        3.1748e-06, 3.6467e-06, 4.0785e-06, 3.1827e-06, 3.3589e-06, 3.2528e-06])\n",
      ".batch_l2.shape:          torch.Size([516])\n"
     ]
    }
   ],
   "source": [
    "loss = lossfunc(model(X), y)\n",
    "with backpack(BatchL2Grad()):\n",
    "    loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(\".grad.shape:             \", param.grad.shape)\n",
    "    print(param.batch_l2)\n",
    "    print(\".batch_l2.shape:         \", param.batch_l2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = []\n",
    "batch_l2 = []\n",
    "for name, param in model.named_parameters():\n",
    "    grad.append(param.grad)\n",
    "    batch_l2.append(param.batch_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0291, -0.0291, -0.0291,  ..., -0.0291, -0.0291, -0.0291],\n",
       "         [ 0.1112,  0.1112,  0.1112,  ...,  0.1112,  0.1112,  0.1112],\n",
       "         [-0.0975, -0.0975, -0.0975,  ..., -0.0975, -0.0975, -0.0975],\n",
       "         ...,\n",
       "         [-0.0336, -0.0336, -0.0336,  ..., -0.0336, -0.0336, -0.0336],\n",
       "         [-0.0261, -0.0261, -0.0261,  ..., -0.0261, -0.0261, -0.0261],\n",
       "         [ 0.0036,  0.0036,  0.0036,  ...,  0.0036,  0.0036,  0.0036]]),\n",
       " tensor([ 0.0685, -0.2621,  0.2297,  0.0269, -0.1170,  0.1549, -0.2332,  0.0793,\n",
       "          0.0614, -0.0086])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0023, 0.0029, 0.0039, 0.0024, 0.0023, 0.0057, 0.0024, 0.0013, 0.0024,\n",
       "         0.0037, 0.0028, 0.0026, 0.0018, 0.0013, 0.0021, 0.0029, 0.0020, 0.0018,\n",
       "         0.0039, 0.0018, 0.0018, 0.0017, 0.0019, 0.0048, 0.0026, 0.0029, 0.0045,\n",
       "         0.0028, 0.0027, 0.0014, 0.0027, 0.0036, 0.0016, 0.0027, 0.0033, 0.0029,\n",
       "         0.0022, 0.0025, 0.0016, 0.0022, 0.0017, 0.0026, 0.0017, 0.0045, 0.0021,\n",
       "         0.0022, 0.0028, 0.0027, 0.0063, 0.0027, 0.0022, 0.0023, 0.0027, 0.0027,\n",
       "         0.0020, 0.0032, 0.0020, 0.0018, 0.0029, 0.0016, 0.0032, 0.0022, 0.0035,\n",
       "         0.0025, 0.0018, 0.0013, 0.0026, 0.0035, 0.0019, 0.0024, 0.0036, 0.0050,\n",
       "         0.0038, 0.0015, 0.0053, 0.0030, 0.0032, 0.0046, 0.0028, 0.0032, 0.0028,\n",
       "         0.0038, 0.0031, 0.0040, 0.0021, 0.0024, 0.0037, 0.0033, 0.0018, 0.0022,\n",
       "         0.0032, 0.0022, 0.0029, 0.0024, 0.0019, 0.0021, 0.0018, 0.0015, 0.0027,\n",
       "         0.0029, 0.0029, 0.0029, 0.0029, 0.0025, 0.0025, 0.0027, 0.0025, 0.0023,\n",
       "         0.0039, 0.0014, 0.0034, 0.0034, 0.0021, 0.0021, 0.0023, 0.0029, 0.0020,\n",
       "         0.0045, 0.0024, 0.0014, 0.0015, 0.0022, 0.0046, 0.0025, 0.0028, 0.0024,\n",
       "         0.0029, 0.0030, 0.0025, 0.0042, 0.0036, 0.0029, 0.0018, 0.0043, 0.0029,\n",
       "         0.0025, 0.0035, 0.0026, 0.0019, 0.0021, 0.0020, 0.0035, 0.0022, 0.0032,\n",
       "         0.0029, 0.0023, 0.0022, 0.0035, 0.0030, 0.0034, 0.0023, 0.0043, 0.0026,\n",
       "         0.0015, 0.0015, 0.0026, 0.0036, 0.0038, 0.0020, 0.0036, 0.0013, 0.0028,\n",
       "         0.0024, 0.0031, 0.0014, 0.0018, 0.0028, 0.0025, 0.0021, 0.0019, 0.0032,\n",
       "         0.0022, 0.0017, 0.0033, 0.0022, 0.0031, 0.0030, 0.0032, 0.0015, 0.0014,\n",
       "         0.0029, 0.0038, 0.0015, 0.0030, 0.0017, 0.0025, 0.0033, 0.0020, 0.0017,\n",
       "         0.0040, 0.0029, 0.0029, 0.0029, 0.0032, 0.0032, 0.0015, 0.0033, 0.0023,\n",
       "         0.0016, 0.0036, 0.0018, 0.0024, 0.0040, 0.0032, 0.0018, 0.0021, 0.0028,\n",
       "         0.0025, 0.0032, 0.0025, 0.0029, 0.0034, 0.0035, 0.0012, 0.0022, 0.0040,\n",
       "         0.0035, 0.0020, 0.0029, 0.0040, 0.0014, 0.0029, 0.0026, 0.0026, 0.0028,\n",
       "         0.0038, 0.0030, 0.0012, 0.0024, 0.0039, 0.0021, 0.0037, 0.0040, 0.0026,\n",
       "         0.0046, 0.0027, 0.0030, 0.0018, 0.0024, 0.0041, 0.0021, 0.0025, 0.0022,\n",
       "         0.0018, 0.0014, 0.0062, 0.0019, 0.0027, 0.0039, 0.0020, 0.0024, 0.0042,\n",
       "         0.0021, 0.0041, 0.0045, 0.0026, 0.0017, 0.0025, 0.0031, 0.0021, 0.0029,\n",
       "         0.0032, 0.0020, 0.0018, 0.0034, 0.0033, 0.0019, 0.0011, 0.0026, 0.0034,\n",
       "         0.0029, 0.0022, 0.0041, 0.0017, 0.0037, 0.0015, 0.0030, 0.0023, 0.0039,\n",
       "         0.0051, 0.0021, 0.0018, 0.0032, 0.0028, 0.0016, 0.0034, 0.0024, 0.0025,\n",
       "         0.0027, 0.0026, 0.0026, 0.0030, 0.0024, 0.0022, 0.0022, 0.0029, 0.0027,\n",
       "         0.0034, 0.0020, 0.0035, 0.0014, 0.0028, 0.0040, 0.0036, 0.0012, 0.0018,\n",
       "         0.0033, 0.0024, 0.0030, 0.0027, 0.0027, 0.0024, 0.0043, 0.0043, 0.0027,\n",
       "         0.0025, 0.0032, 0.0023, 0.0032, 0.0019, 0.0014, 0.0036, 0.0051, 0.0040,\n",
       "         0.0039, 0.0025, 0.0030, 0.0035, 0.0023, 0.0019, 0.0019, 0.0027, 0.0040,\n",
       "         0.0025, 0.0021, 0.0013, 0.0022, 0.0046, 0.0044, 0.0031, 0.0034, 0.0032,\n",
       "         0.0027, 0.0030, 0.0022, 0.0023, 0.0036, 0.0034, 0.0018, 0.0025, 0.0043,\n",
       "         0.0028, 0.0046, 0.0027, 0.0021, 0.0032, 0.0040, 0.0027, 0.0033, 0.0017,\n",
       "         0.0027, 0.0030, 0.0048, 0.0020, 0.0025, 0.0024, 0.0028, 0.0017, 0.0032,\n",
       "         0.0019, 0.0024, 0.0033, 0.0019, 0.0012, 0.0040, 0.0033, 0.0029, 0.0027,\n",
       "         0.0028, 0.0028, 0.0017, 0.0031, 0.0016, 0.0028, 0.0025, 0.0022, 0.0014,\n",
       "         0.0046, 0.0048, 0.0018, 0.0035, 0.0026, 0.0022, 0.0018, 0.0021, 0.0026,\n",
       "         0.0016, 0.0035, 0.0012, 0.0013, 0.0046, 0.0020, 0.0018, 0.0015, 0.0019,\n",
       "         0.0014, 0.0039, 0.0022, 0.0021, 0.0015, 0.0022, 0.0038, 0.0012, 0.0014,\n",
       "         0.0049, 0.0028, 0.0028, 0.0014, 0.0019, 0.0025, 0.0020, 0.0011, 0.0029,\n",
       "         0.0024, 0.0025, 0.0049, 0.0021, 0.0032, 0.0015, 0.0023, 0.0026, 0.0022,\n",
       "         0.0023, 0.0027, 0.0026, 0.0035, 0.0016, 0.0041, 0.0025, 0.0046, 0.0026,\n",
       "         0.0016, 0.0018, 0.0035, 0.0033, 0.0011, 0.0032, 0.0026, 0.0055, 0.0027,\n",
       "         0.0018, 0.0017, 0.0039, 0.0019, 0.0031, 0.0025, 0.0022, 0.0014, 0.0021,\n",
       "         0.0017, 0.0034, 0.0018, 0.0034, 0.0032, 0.0024, 0.0014, 0.0020, 0.0017,\n",
       "         0.0028, 0.0037, 0.0042, 0.0045, 0.0022, 0.0020, 0.0033, 0.0029, 0.0036,\n",
       "         0.0035, 0.0023, 0.0041, 0.0036, 0.0026, 0.0035, 0.0042, 0.0019, 0.0018,\n",
       "         0.0036, 0.0043, 0.0040, 0.0045, 0.0015, 0.0024, 0.0018, 0.0036, 0.0024,\n",
       "         0.0033, 0.0014, 0.0029, 0.0010, 0.0026, 0.0031, 0.0029, 0.0019, 0.0023,\n",
       "         0.0012, 0.0031, 0.0020, 0.0023, 0.0039, 0.0035, 0.0037, 0.0029, 0.0026,\n",
       "         0.0037, 0.0019, 0.0047]),\n",
       " tensor([3.1502e-06, 3.5684e-06, 4.1981e-06, 3.5316e-06, 3.3082e-06, 4.4562e-06,\n",
       "         2.6961e-06, 3.0004e-06, 3.4506e-06, 3.7239e-06, 3.6732e-06, 4.0367e-06,\n",
       "         3.0085e-06, 3.3835e-06, 3.5026e-06, 3.7332e-06, 3.2224e-06, 3.4809e-06,\n",
       "         3.5981e-06, 3.0844e-06, 3.0736e-06, 3.4549e-06, 3.6218e-06, 3.8512e-06,\n",
       "         2.9685e-06, 3.3008e-06, 3.9312e-06, 3.7365e-06, 3.6433e-06, 2.7740e-06,\n",
       "         3.1213e-06, 3.8965e-06, 3.6018e-06, 3.8239e-06, 3.0184e-06, 3.2014e-06,\n",
       "         3.5518e-06, 3.0626e-06, 3.6177e-06, 3.2726e-06, 3.2432e-06, 3.6371e-06,\n",
       "         3.3684e-06, 3.3315e-06, 3.5265e-06, 3.9848e-06, 3.1271e-06, 3.2102e-06,\n",
       "         3.9511e-06, 3.3170e-06, 3.6596e-06, 3.0403e-06, 2.9387e-06, 3.8590e-06,\n",
       "         3.7765e-06, 3.9643e-06, 3.0758e-06, 2.9899e-06, 3.5556e-06, 2.5635e-06,\n",
       "         3.7017e-06, 3.5640e-06, 2.8102e-06, 3.6749e-06, 3.3700e-06, 3.1482e-06,\n",
       "         3.6881e-06, 3.4630e-06, 3.1370e-06, 3.1656e-06, 3.2402e-06, 3.9411e-06,\n",
       "         3.4203e-06, 3.3839e-06, 3.7313e-06, 3.1515e-06, 3.9930e-06, 3.7438e-06,\n",
       "         2.1396e-06, 3.7856e-06, 2.7381e-06, 3.6051e-06, 3.5073e-06, 3.9133e-06,\n",
       "         3.1606e-06, 2.6713e-06, 3.3049e-06, 3.6211e-06, 3.0212e-06, 3.6670e-06,\n",
       "         3.8959e-06, 3.5997e-06, 3.7731e-06, 3.7621e-06, 3.9107e-06, 3.6346e-06,\n",
       "         2.8761e-06, 3.5198e-06, 3.3231e-06, 4.1585e-06, 3.6501e-06, 3.1567e-06,\n",
       "         3.7247e-06, 3.4614e-06, 3.7440e-06, 3.7934e-06, 3.4350e-06, 3.4797e-06,\n",
       "         3.8676e-06, 3.0089e-06, 3.2431e-06, 2.8354e-06, 3.8098e-06, 3.3257e-06,\n",
       "         3.3441e-06, 3.3578e-06, 3.3407e-06, 3.5995e-06, 3.2535e-06, 3.2597e-06,\n",
       "         3.0105e-06, 3.1459e-06, 4.1322e-06, 3.9726e-06, 3.3005e-06, 3.4861e-06,\n",
       "         3.5447e-06, 2.9447e-06, 3.6697e-06, 3.4759e-06, 3.6846e-06, 3.4509e-06,\n",
       "         3.2176e-06, 4.2750e-06, 2.8234e-06, 3.8152e-06, 3.7107e-06, 3.1282e-06,\n",
       "         2.8967e-06, 3.3958e-06, 3.5396e-06, 3.5600e-06, 3.9194e-06, 3.5886e-06,\n",
       "         3.7175e-06, 3.5172e-06, 3.4915e-06, 3.8741e-06, 3.2812e-06, 3.4716e-06,\n",
       "         3.2722e-06, 3.1838e-06, 3.8885e-06, 3.5397e-06, 3.5009e-06, 3.1826e-06,\n",
       "         3.3115e-06, 3.0477e-06, 3.2815e-06, 2.5418e-06, 3.6314e-06, 3.1968e-06,\n",
       "         3.7412e-06, 3.9913e-06, 2.3452e-06, 3.7101e-06, 3.3966e-06, 3.0292e-06,\n",
       "         3.9065e-06, 3.4049e-06, 3.9680e-06, 2.5015e-06, 2.2410e-06, 4.0279e-06,\n",
       "         3.5827e-06, 3.9844e-06, 3.9933e-06, 3.6696e-06, 2.5949e-06, 2.6980e-06,\n",
       "         3.5497e-06, 3.4833e-06, 3.2314e-06, 2.5241e-06, 2.9509e-06, 3.4170e-06,\n",
       "         2.6914e-06, 3.0595e-06, 2.5511e-06, 4.1441e-06, 3.9999e-06, 3.3281e-06,\n",
       "         3.7318e-06, 3.6789e-06, 3.1349e-06, 3.1802e-06, 2.9893e-06, 3.6436e-06,\n",
       "         3.5039e-06, 3.8108e-06, 2.9006e-06, 3.2531e-06, 3.2055e-06, 4.0360e-06,\n",
       "         3.7716e-06, 3.2918e-06, 3.3919e-06, 3.1594e-06, 3.0901e-06, 3.5797e-06,\n",
       "         3.9442e-06, 3.8548e-06, 3.6587e-06, 2.8934e-06, 2.5004e-06, 3.6547e-06,\n",
       "         4.0257e-06, 3.5929e-06, 3.4851e-06, 4.1599e-06, 2.4587e-06, 3.9523e-06,\n",
       "         3.2664e-06, 3.8410e-06, 2.8467e-06, 3.2210e-06, 3.8972e-06, 2.1877e-06,\n",
       "         3.6868e-06, 3.7167e-06, 3.4919e-06, 3.9531e-06, 3.8295e-06, 4.1437e-06,\n",
       "         3.7421e-06, 2.5929e-06, 3.6261e-06, 2.7226e-06, 3.2280e-06, 4.1359e-06,\n",
       "         2.6670e-06, 3.7853e-06, 3.0738e-06, 3.1788e-06, 3.3750e-06, 4.1177e-06,\n",
       "         2.6566e-06, 2.7687e-06, 3.9236e-06, 3.5788e-06, 2.4733e-06, 3.7583e-06,\n",
       "         3.2666e-06, 3.4366e-06, 3.9159e-06, 3.2847e-06, 3.5044e-06, 2.6664e-06,\n",
       "         3.3411e-06, 3.6998e-06, 3.5997e-06, 3.5025e-06, 3.2293e-06, 3.6230e-06,\n",
       "         3.7673e-06, 3.7761e-06, 2.2530e-06, 3.0128e-06, 3.3619e-06, 2.7299e-06,\n",
       "         3.5291e-06, 3.5275e-06, 3.9521e-06, 2.8393e-06, 3.7940e-06, 3.4142e-06,\n",
       "         3.0573e-06, 2.6496e-06, 3.2707e-06, 4.2398e-06, 3.5692e-06, 3.3316e-06,\n",
       "         4.1154e-06, 3.2975e-06, 3.6245e-06, 2.3689e-06, 3.2605e-06, 3.4890e-06,\n",
       "         3.3707e-06, 3.4587e-06, 3.4689e-06, 4.0235e-06, 3.6557e-06, 3.5340e-06,\n",
       "         3.9108e-06, 3.6223e-06, 3.2264e-06, 3.2572e-06, 3.7449e-06, 3.7370e-06,\n",
       "         3.0195e-06, 3.1304e-06, 4.4417e-06, 3.5040e-06, 3.4803e-06, 3.9472e-06,\n",
       "         3.4964e-06, 3.8354e-06, 3.6282e-06, 3.1577e-06, 3.5026e-06, 3.3114e-06,\n",
       "         3.8919e-06, 4.0325e-06, 4.0096e-06, 3.9329e-06, 3.7163e-06, 3.3221e-06,\n",
       "         3.8785e-06, 3.6686e-06, 3.0396e-06, 3.6510e-06, 3.5528e-06, 3.7581e-06,\n",
       "         3.4976e-06, 3.4536e-06, 3.8880e-06, 4.1998e-06, 3.5352e-06, 3.2970e-06,\n",
       "         2.6486e-06, 3.0405e-06, 3.3627e-06, 3.2907e-06, 3.9529e-06, 3.5499e-06,\n",
       "         3.2769e-06, 3.4938e-06, 3.9087e-06, 3.9269e-06, 4.0899e-06, 2.9589e-06,\n",
       "         3.7878e-06, 3.4768e-06, 3.6835e-06, 3.3116e-06, 3.9022e-06, 3.7327e-06,\n",
       "         3.3301e-06, 3.4383e-06, 3.9314e-06, 3.8048e-06, 3.6496e-06, 3.5114e-06,\n",
       "         2.7938e-06, 3.1551e-06, 4.0861e-06, 2.7555e-06, 3.0572e-06, 3.3341e-06,\n",
       "         3.1953e-06, 3.9328e-06, 3.5558e-06, 3.9995e-06, 3.5389e-06, 3.5376e-06,\n",
       "         3.2321e-06, 3.2319e-06, 3.7816e-06, 3.1699e-06, 3.4946e-06, 2.8759e-06,\n",
       "         3.0734e-06, 2.7099e-06, 3.7046e-06, 2.8153e-06, 3.5867e-06, 3.6169e-06,\n",
       "         3.5326e-06, 3.6554e-06, 3.5317e-06, 2.5741e-06, 3.5453e-06, 3.6589e-06,\n",
       "         2.9758e-06, 3.4549e-06, 3.2551e-06, 3.1500e-06, 3.6893e-06, 3.6733e-06,\n",
       "         3.2452e-06, 3.7121e-06, 3.6652e-06, 3.4980e-06, 2.5292e-06, 2.9014e-06,\n",
       "         2.6361e-06, 3.8453e-06, 2.9912e-06, 3.6862e-06, 4.0093e-06, 3.4542e-06,\n",
       "         3.2209e-06, 3.1104e-06, 3.2537e-06, 3.2886e-06, 3.9711e-06, 3.5684e-06,\n",
       "         3.4961e-06, 3.4929e-06, 3.4769e-06, 3.9268e-06, 3.0639e-06, 2.8362e-06,\n",
       "         3.9249e-06, 3.4210e-06, 3.7804e-06, 3.4164e-06, 3.8262e-06, 3.6862e-06,\n",
       "         3.4667e-06, 3.2741e-06, 3.9729e-06, 2.9735e-06, 3.7344e-06, 3.3987e-06,\n",
       "         3.2698e-06, 2.9566e-06, 3.5259e-06, 3.7014e-06, 3.3475e-06, 2.6190e-06,\n",
       "         3.6457e-06, 3.6704e-06, 3.0857e-06, 3.7838e-06, 3.7846e-06, 3.9777e-06,\n",
       "         3.5742e-06, 3.7288e-06, 3.4299e-06, 3.6565e-06, 3.7197e-06, 3.2810e-06,\n",
       "         3.5722e-06, 2.9842e-06, 2.6696e-06, 3.4664e-06, 4.3343e-06, 3.6800e-06,\n",
       "         2.8616e-06, 3.7912e-06, 3.1525e-06, 3.3505e-06, 3.8930e-06, 3.5786e-06,\n",
       "         3.7855e-06, 3.4192e-06, 3.9591e-06, 3.6617e-06, 2.7193e-06, 2.7117e-06,\n",
       "         3.2986e-06, 4.0080e-06, 3.4592e-06, 2.7756e-06, 3.5441e-06, 3.9424e-06,\n",
       "         3.1246e-06, 4.0278e-06, 3.9375e-06, 3.9690e-06, 3.0195e-06, 3.3618e-06,\n",
       "         3.1368e-06, 4.0165e-06, 3.4435e-06, 2.9407e-06, 3.5822e-06, 3.1937e-06,\n",
       "         3.4260e-06, 3.9065e-06, 3.3087e-06, 4.0019e-06, 2.8651e-06, 3.2336e-06,\n",
       "         4.0884e-06, 4.0162e-06, 3.4258e-06, 2.4899e-06, 3.3440e-06, 2.8784e-06,\n",
       "         3.5137e-06, 2.8092e-06, 3.2323e-06, 3.4905e-06, 3.2204e-06, 3.3465e-06,\n",
       "         2.5757e-06, 3.7267e-06, 3.2827e-06, 3.4991e-06, 2.9408e-06, 3.5266e-06,\n",
       "         3.5887e-06, 3.0643e-06, 3.5048e-06, 3.2831e-06, 3.8422e-06, 3.8102e-06,\n",
       "         3.1748e-06, 3.6467e-06, 4.0785e-06, 3.1827e-06, 3.3589e-06, 3.2528e-06])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.4269, -4.2561])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.distributions import Normal\n",
    "import math\n",
    "\n",
    "mu = torch.tensor([0, 0], dtype=torch.float32)\n",
    "a = math.exp(1)\n",
    "sigma = torch.tensor(a, dtype=torch.float32)\n",
    " \n",
    "dist = Normal(mu, sigma)  # 设置高斯分布的均值和方差\n",
    " \n",
    "dist.sample()  # 采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 生成一维高斯分布N\n",
    "#a = math.exp(1)\n",
    "mu, sigma = 0, 1  # 均值和标准差\n",
    "N = np.random.normal(mu, sigma, size=100000)\n",
    "# 绘制直方图\n",
    "plt.hist(N, bins=50, density=True, alpha=0.5, color='r')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Gaussian Distribution')\n",
    "# 绘制概率密度函数\n",
    "x = np.linspace(mu - 10, mu + 10, 10000)\n",
    "y = 1 / (np.sqrt(2 * np.pi) * sigma) * np.exp(-(x - mu) ** 2 / (2 * sigma ** 2))\n",
    "plt.plot(x, y, color='b')\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.38905609893065"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahaichao/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "### dpsgd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import BatchGrad, BatchL2Grad\n",
    "from backpack.utils.examples import get_mnist_dataloader\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "PRINT_EVERY = 50\n",
    "MAX_ITER = 20\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def make_broadcastable(v, X):\n",
    "    \"\"\"Returns a view of `v` that can be broadcast with `X`.\n",
    "\n",
    "    If `v` is a one-dimensional tensor [N] and `X` is a tensor of shape\n",
    "    `[N, ..., ]`, returns a view of v with singleton dimensions appended.\n",
    "\n",
    "    Example:\n",
    "        `v` is a tensor of shape `[10]` and `X` is a tensor of shape `[10, 3, 3]`.\n",
    "        We want to multiply each `[3, 3]` element of `X` by the corresponding\n",
    "        element of `v` to get a matrix `Y` of shape `[10, 3, 3]` such that\n",
    "        `Y[i, a, b] = v[i] * X[i, a, b]`.\n",
    "\n",
    "        `w = make_broadcastable(v, X)` gives a `w` of shape `[10, 1, 1]`,\n",
    "        and we can now broadcast `Y = w * X`.\n",
    "    \"\"\"\n",
    "    broadcasting_shape = (-1, *[1 for _ in X.shape[1:]])\n",
    "    return v.reshape(broadcasting_shape)\n",
    "\n",
    "\n",
    "def accuracy(output, targets):\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_small_cnn(outputs=10, channels=(16, 32), fc_dim=32, kernels=(8, 4)):\n",
    "    return nn.Sequential(\n",
    "        nn.ZeroPad2d((3, 4, 3, 4)),\n",
    "        nn.Conv2d(1, channels[0], kernels[0], stride=2, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, stride=1),\n",
    "        nn.Conv2d(channels[0], channels[1], kernels[1], stride=2, padding=0),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, stride=1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(channels[1] * 4 * 4, fc_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(fc_dim, outputs),\n",
    "    )\n",
    "\n",
    "\n",
    "mnist_dataloader = get_mnist_dataloader(batch_size=BATCH_SIZE)\n",
    "\n",
    "model = make_small_cnn().to(DEVICE)\n",
    "loss_function = nn.CrossEntropyLoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels=(16, 32)\n",
    "channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = extend(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(mnist_dataloader))\n",
    "x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "loss = loss_function(model(x), y)\n",
    "with backpack(BatchL2Grad(), BatchGrad()):\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 8, 8])    torch.Size([64, 16, 1, 8, 8])    torch.Size([64])\n",
      "torch.Size([16])             torch.Size([64, 16])             torch.Size([64])\n",
      "torch.Size([32, 16, 4, 4])   torch.Size([64, 32, 16, 4, 4])   torch.Size([64])\n",
      "torch.Size([32])             torch.Size([64, 32])             torch.Size([64])\n",
      "torch.Size([32, 512])        torch.Size([64, 32, 512])        torch.Size([64])\n",
      "torch.Size([32])             torch.Size([64, 32])             torch.Size([64])\n",
      "torch.Size([10, 32])         torch.Size([64, 10, 32])         torch.Size([64])\n",
      "torch.Size([10])             torch.Size([64, 10])             torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    #print(name)\n",
    "    print(\n",
    "        \"{:28} {:32} {}\".format(\n",
    "            str(p.grad.shape), str(p.grad_batch.shape), str(p.batch_l2.shape)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norms_squared_all_params = torch.stack([p.batch_l2 for p in model.parameters()])\n",
    "l2_norms = torch.sqrt(torch.sum(l2_norms_squared_all_params, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norms_squared_all_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0859, 0.0776, 0.0813, 0.0615, 0.0798, 0.0787, 0.0991, 0.0924, 0.0762,\n",
       "        0.0659, 0.0836, 0.0971, 0.0690, 0.0656, 0.0839, 0.0606, 0.0797, 0.0723,\n",
       "        0.0832, 0.0726, 0.0703, 0.0756, 0.0792, 0.0622, 0.0884, 0.0689, 0.0677,\n",
       "        0.0822, 0.0948, 0.0704, 0.0816, 0.0886, 0.0899, 0.0765, 0.0782, 0.0697,\n",
       "        0.0708, 0.0753, 0.0925, 0.0578, 0.0723, 0.0725, 0.0651, 0.0672, 0.0641,\n",
       "        0.0880, 0.0558, 0.0562, 0.0642, 0.0749, 0.0745, 0.0639, 0.0785, 0.0641,\n",
       "        0.0839, 0.0863, 0.0831, 0.0801, 0.0564, 0.0715, 0.0877, 0.0555, 0.0774,\n",
       "        0.0955], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0.1\n",
    "scaling_factors = torch.clamp_max(l2_norms / C, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    clipped_grads = p.grad_batch * make_broadcastable(scaling_factors, p.grad_batch)\n",
    "    clipped_grad = torch.sum(clipped_grads, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DP_SGD(Optimizer):\n",
    "    \"\"\"Differentially Private SGD.\n",
    "\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): coefficient that scale delta before it is applied\n",
    "            to the parameters (default: 1.0)\n",
    "        max_norm (float, optional): maximum norm of the individual gradient,\n",
    "            to which they will be clipped if exceeded (default: 0.01)\n",
    "        stddev (float, optional): standard deviation of the added noise\n",
    "            (default: 1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, grad_norm, noise_norm, lr=0.1, max_norm=0.1, stddev=2.0):\n",
    "        self.lr = lr\n",
    "        self.max_norm = max_norm\n",
    "        self.stddev = stddev\n",
    "        self.noise_norm = noise_norm\n",
    "        \n",
    "        super().__init__(params, dict())\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        The function expects the gradients to have been computed by BackPACK\n",
    "        and the parameters to have a ``batch_l2`` and ``grad_batch`` attribute.\n",
    "        \"\"\"\n",
    "        l2_norms_all_params_list = []\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                #print(\"p:\", len(p))\n",
    "                l2_norms_all_params_list.append(p.batch_l2)\n",
    "\n",
    "        l2_norms_all_params = torch.stack(l2_norms_all_params_list)\n",
    "        print(\"l2_norms_all_params:\", l2_norms_all_params.shape)\n",
    "        total_norms = torch.sqrt(torch.sum(l2_norms_all_params, dim=0))\n",
    "        print(\"total_norms:\",total_norms.shape)\n",
    "        scaling_factors = torch.clamp_max(total_norms / self.max_norm, 1.0)\n",
    "        print(\"scaling_factors:\",scaling_factors.shape)\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            i = 0\n",
    "            for p in group[\"params\"]:\n",
    "                clipped_grads = p.grad_batch * make_broadcastable(\n",
    "                    scaling_factors, p.grad_batch\n",
    "                )\n",
    "                clipped_grad = torch.sum(clipped_grads, dim=0)\n",
    "\n",
    "                noise_magnitude = self.stddev * self.max_norm\n",
    "                noise = torch.randn_like(clipped_grad) * noise_magnitude\n",
    "                if i == 4:\n",
    "                    print(\"noise:\", torch.norm(noise))\n",
    "                    self.noise_norm.append(torch.norm(noise))\n",
    "\n",
    "                perturbed_update = clipped_grad + noise\n",
    "\n",
    "                p.data.add_(-self.lr * perturbed_update)\n",
    "                i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.5363, device='cuda:0')\n",
      "Epoch   0/1 Iteration   0 Minibatch Loss 2.309  Accuracy 0.094\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.4161, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.4562, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.1893, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.8125, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.7622, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.6466, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.4966, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.5468, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.7693, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.5660, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.3709, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.7996, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.5772, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.2257, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.5585, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.6492, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.5295, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.6665, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.3882, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.4782, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "scaling_factors: torch.Size([64])\n",
      "noise: tensor(25.9262, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "grad_norm = []\n",
    "noise_norm = []\n",
    "\n",
    "optimizer = DP_SGD(model.parameters(), grad_norm, noise_norm, lr=0.1, max_norm=0.1, stddev=2.0)\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"epoch:\", epoch)\n",
    "    for batch_idx, (x, y) in enumerate(mnist_dataloader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"noise_norm:\", noise_norm)\n",
    "        outputs = model(x)\n",
    "        loss = loss_function(outputs, y)\n",
    "\n",
    "        with backpack(BatchGrad(), BatchL2Grad()):\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        losses.append(loss.detach().item())\n",
    "        accuracies.append(accuracy(outputs, y))\n",
    "\n",
    "        if (batch_idx % PRINT_EVERY) == 0:\n",
    "            print(\n",
    "                \"Epoch %3.d/%d Iteration %3.d \" % (epoch, NUM_EPOCHS, batch_idx)\n",
    "                + \"Minibatch Loss %.3f  \" % losses[-1]\n",
    "                + \"Accuracy %.3f\" % accuracies[-1]\n",
    "            )\n",
    "\n",
    "        if MAX_ITER is not None and batch_idx > MAX_ITER:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iteration')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "axes = [fig.add_subplot(1, 3, 1), fig.add_subplot(1, 3, 2), fig.add_subplot(1, 3, 3)]\n",
    "\n",
    "axes[0].plot(losses)\n",
    "axes[0].set_title(\"Loss\")\n",
    "axes[0].set_xlabel(\"Iteration\")\n",
    "\n",
    "axes[1].plot(accuracies)\n",
    "axes[1].set_title(\"Accuracy\")\n",
    "axes[1].set_xlabel(\"Iteration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#noise_norm_cpu = noise_norm.cpu()\n",
    "import numpy as np\n",
    "t = np.arange(22)\n",
    "plt.figure()\n",
    "l1=plt.plot(t, np.array(torch.tensor(noise_norm, device='cpu')), label='dpsgd-noise_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_norm: 22\n"
     ]
    }
   ],
   "source": [
    "print(\"noise_norm:\", len(noise_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### sparsity\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDP_SGD\u001b[39;00m(\u001b[43mOptimizer\u001b[49m):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Differentially Private SGD.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m            (default: 1.0)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, grad_norm, noise_norm, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, stddev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.0\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "### sparsity\n",
    "class DP_SGD(Optimizer):\n",
    "    \"\"\"Differentially Private SGD.\n",
    "\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): coefficient that scale delta before it is applied\n",
    "            to the parameters (default: 1.0)\n",
    "        max_norm (float, optional): maximum norm of the individual gradient,\n",
    "            to which they will be clipped if exceeded (default: 0.01)\n",
    "        stddev (float, optional): standard deviation of the added noise\n",
    "            (default: 1.0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, grad_norm, noise_norm, lr=0.1, max_norm=0.1, stddev=2.0):\n",
    "        self.lr = lr\n",
    "        self.max_norm = max_norm\n",
    "        self.stddev = stddev\n",
    "        self.noise_norm = noise_norm\n",
    "        \n",
    "        super().__init__(params, dict())\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        The function expects the gradients to have been computed by BackPACK\n",
    "        and the parameters to have a ``batch_l2`` and ``grad_batch`` attribute.\n",
    "        \"\"\"\n",
    "        l2_norms_all_params_list = []\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                print(\"p.batch_l2:\", p.batch_l2)\n",
    "                print(\"p.grad_batch-shape:\", p.grad_batch.shape)\n",
    "                print(\"p.grad_batch-norm:\", torch.norm(p.grad_batch[0].reshape(-1,1).squeeze()))\n",
    "                print(\"p.grad_batch-norm:\", torch.norm(p.grad_batch[1].reshape(-1,1).squeeze()))\n",
    "                l2_norms_all_params_list.append(p.batch_l2)\n",
    "        \n",
    "        l2_norms_all_params = torch.stack(l2_norms_all_params_list)\n",
    "        print(\"l2_norms_all_params:\", l2_norms_all_params.shape)\n",
    "        #print(\"l2_norms_all_params:\", l2_norms_all_params.shape)\n",
    "        total_norms = torch.sqrt(torch.sum(l2_norms_all_params, dim=0))\n",
    "        scaling_factors = torch.clamp_max(total_norms / self.max_norm, 1.0)\n",
    "        print(\"total_norms:\", total_norms.shape)\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            i = 0\n",
    "            for p in group[\"params\"]:\n",
    "                clipped_grads = p.grad_batch * make_broadcastable(\n",
    "                    scaling_factors, p.grad_batch\n",
    "                )\n",
    "                print(\"clipped_grads:\", clipped_grads.shape)\n",
    "                clipped_grad = torch.sum(clipped_grads, dim=0)\n",
    "\n",
    "                noise_magnitude = self.stddev * self.max_norm\n",
    "                noise = torch.randn_like(clipped_grad) * noise_magnitude\n",
    "                if i == 4:\n",
    "                    print(\"noise:\", torch.norm(noise))\n",
    "                    self.noise_norm.append(torch.norm(noise))\n",
    "\n",
    "                perturbed_update = clipped_grad + noise\n",
    "\n",
    "                p.data.add_(-self.lr * perturbed_update)\n",
    "                i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "p.batch_l2: tensor([4.4997e-03, 1.7281e-03, 1.9564e-03, 3.0419e-02, 1.0252e-02, 1.2383e-02,\n",
      "        9.2400e-03, 1.1565e-02, 2.7908e-03, 1.6076e-02, 1.2413e-02, 2.9156e-03,\n",
      "        8.0995e-04, 7.6552e-03, 1.1830e-02, 7.0774e-03, 1.1208e-02, 6.3561e-03,\n",
      "        5.9798e-03, 8.0870e-03, 2.7075e-03, 1.1986e-02, 1.1714e-02, 1.0914e-02,\n",
      "        2.6329e-03, 7.3661e-03, 1.9859e-02, 1.4037e-02, 5.6484e-03, 9.7185e-03,\n",
      "        4.0683e-03, 1.6134e-02, 2.5009e-02, 8.9288e-03, 1.9991e-02, 1.2827e-02,\n",
      "        7.7101e-03, 4.2399e-03, 1.5549e-03, 7.7393e-05, 6.9114e-03, 8.2746e-03,\n",
      "        6.7250e-03, 1.5159e-02, 5.8999e-03, 1.0146e-03, 1.4294e-02, 1.9029e-03,\n",
      "        7.9649e-03, 6.3235e-03, 4.3431e-03, 5.8983e-03, 4.3676e-03, 1.4369e-02,\n",
      "        9.8081e-03, 8.3875e-03, 2.9355e-03, 1.3890e-02, 2.0931e-02, 2.2558e-02,\n",
      "        6.5083e-03, 1.2021e-02, 4.1243e-03, 7.4022e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0671, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0416, device='cuda:0')\n",
      "p.batch_l2: tensor([2.8445e-05, 1.9051e-05, 4.5268e-05, 3.6672e-04, 1.9788e-04, 3.0690e-04,\n",
      "        6.0740e-05, 1.4406e-04, 1.0500e-05, 2.2517e-04, 2.8124e-04, 2.2721e-05,\n",
      "        1.3891e-05, 6.9863e-05, 2.9763e-04, 1.5765e-04, 2.1648e-04, 1.6449e-04,\n",
      "        1.5446e-04, 1.8209e-04, 3.5800e-05, 1.0262e-04, 1.1172e-04, 5.4954e-05,\n",
      "        3.3507e-05, 2.8673e-04, 2.7461e-04, 1.5143e-04, 7.9055e-05, 8.4712e-05,\n",
      "        6.3795e-05, 1.2705e-04, 3.7678e-04, 3.1998e-04, 1.6601e-04, 2.3614e-04,\n",
      "        9.4126e-05, 5.4340e-05, 2.2476e-05, 1.6828e-06, 1.4735e-04, 1.3117e-04,\n",
      "        3.1811e-04, 1.3738e-04, 7.2750e-05, 8.3811e-06, 3.1190e-04, 7.6523e-05,\n",
      "        5.4185e-05, 9.1652e-05, 7.4821e-05, 2.3188e-04, 3.8788e-05, 9.6168e-05,\n",
      "        1.5387e-04, 1.5898e-04, 2.4681e-05, 1.7133e-04, 8.8484e-05, 1.1862e-04,\n",
      "        1.1021e-04, 5.0868e-05, 6.7276e-05, 4.9446e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0053, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0044, device='cuda:0')\n",
      "p.batch_l2: tensor([5.7023e-03, 2.3424e-03, 2.8552e-03, 2.8988e-02, 1.7440e-02, 2.1363e-02,\n",
      "        7.0774e-03, 1.7599e-02, 3.2675e-03, 2.1886e-02, 1.8905e-02, 4.5513e-03,\n",
      "        2.0150e-03, 1.0913e-02, 2.0941e-02, 1.0970e-02, 1.6211e-02, 8.5367e-03,\n",
      "        7.2325e-03, 1.4107e-02, 3.4612e-03, 1.4247e-02, 2.4107e-02, 9.2163e-03,\n",
      "        3.9357e-03, 9.2738e-03, 1.8970e-02, 1.8821e-02, 9.7822e-03, 1.5125e-02,\n",
      "        4.4086e-03, 1.8117e-02, 2.2464e-02, 1.9669e-02, 2.6533e-02, 1.4162e-02,\n",
      "        1.1946e-02, 6.5578e-03, 1.8293e-03, 9.5487e-05, 1.4778e-02, 9.8513e-03,\n",
      "        1.5678e-02, 2.4154e-02, 7.7062e-03, 1.0591e-03, 1.9490e-02, 4.0359e-03,\n",
      "        1.3325e-02, 1.0365e-02, 9.2921e-03, 1.1884e-02, 6.5205e-03, 2.0867e-02,\n",
      "        1.2727e-02, 1.1276e-02, 4.0015e-03, 2.7522e-02, 2.1870e-02, 1.9654e-02,\n",
      "        1.0759e-02, 7.8090e-03, 5.8463e-03, 6.9352e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.0755, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0484, device='cuda:0')\n",
      "p.batch_l2: tensor([1.6316e-05, 6.6195e-06, 1.8430e-05, 6.9622e-05, 5.1708e-05, 9.6270e-05,\n",
      "        1.1154e-05, 4.3496e-05, 6.7892e-06, 9.8239e-05, 7.9876e-05, 1.1980e-05,\n",
      "        6.1787e-06, 2.0848e-05, 9.2385e-05, 7.8521e-05, 4.5942e-05, 3.1996e-05,\n",
      "        2.7679e-05, 4.6856e-05, 1.2165e-05, 4.2695e-05, 5.3621e-05, 1.6237e-05,\n",
      "        9.5361e-06, 3.6463e-05, 3.4188e-05, 4.6178e-05, 3.2375e-05, 4.2425e-05,\n",
      "        1.6607e-05, 4.5081e-05, 8.3447e-05, 8.8796e-05, 5.6894e-05, 4.2582e-05,\n",
      "        2.4019e-05, 1.3321e-05, 6.3614e-06, 2.7330e-07, 4.1871e-05, 3.8587e-05,\n",
      "        5.6274e-05, 4.2710e-05, 1.3351e-05, 1.6850e-06, 7.0626e-05, 1.7683e-05,\n",
      "        3.2508e-05, 2.7357e-05, 3.2546e-05, 4.5476e-05, 1.7760e-05, 4.8833e-05,\n",
      "        3.2930e-05, 3.4387e-05, 1.1511e-05, 7.1252e-05, 3.3677e-05, 4.4656e-05,\n",
      "        3.9047e-05, 1.3482e-05, 2.4624e-05, 1.4042e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0040, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0026, device='cuda:0')\n",
      "p.batch_l2: tensor([3.7877e-03, 2.5367e-03, 1.4430e-03, 1.8856e-02, 1.3349e-02, 9.8852e-03,\n",
      "        7.3049e-03, 1.3986e-02, 4.0468e-03, 5.4801e-03, 1.6523e-02, 2.0674e-03,\n",
      "        7.8018e-04, 1.4636e-02, 1.0307e-02, 5.6140e-03, 9.5101e-03, 9.1969e-03,\n",
      "        2.6040e-03, 8.5879e-03, 2.5551e-03, 5.4650e-03, 1.7356e-02, 1.7537e-02,\n",
      "        3.6921e-03, 3.5559e-03, 1.3036e-02, 4.9820e-03, 6.4118e-03, 2.6470e-03,\n",
      "        3.6822e-03, 2.5236e-02, 1.7032e-02, 7.4768e-03, 1.9840e-02, 2.1335e-02,\n",
      "        1.4456e-02, 2.6167e-03, 1.2114e-03, 7.6931e-05, 8.4336e-03, 4.6793e-03,\n",
      "        3.3497e-02, 1.4083e-02, 5.9449e-03, 2.4246e-03, 1.7405e-02, 1.4640e-03,\n",
      "        2.7465e-02, 9.6420e-03, 3.3872e-03, 1.5268e-02, 1.8568e-02, 1.3984e-02,\n",
      "        1.7945e-02, 5.3651e-03, 4.4939e-03, 1.6481e-02, 2.4237e-02, 2.3299e-02,\n",
      "        1.8778e-02, 3.8277e-03, 5.3948e-03, 3.3901e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0615, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0504, device='cuda:0')\n",
      "p.batch_l2: tensor([1.3537e-05, 6.1785e-06, 7.2912e-06, 5.2975e-05, 2.0622e-05, 5.0537e-05,\n",
      "        1.5368e-05, 2.3881e-05, 9.3040e-06, 3.4764e-05, 3.2535e-05, 5.2610e-06,\n",
      "        2.9271e-06, 1.6000e-05, 4.0805e-05, 2.7343e-05, 2.8973e-05, 1.5671e-05,\n",
      "        1.2111e-05, 2.1944e-05, 7.9872e-06, 2.0704e-05, 3.1407e-05, 3.7636e-05,\n",
      "        1.0205e-05, 1.2094e-05, 2.1169e-05, 1.9188e-05, 7.9424e-06, 1.0526e-05,\n",
      "        1.1086e-05, 4.5860e-05, 7.9138e-05, 2.3326e-05, 4.6091e-05, 3.0229e-05,\n",
      "        2.3706e-05, 9.4031e-06, 4.0518e-06, 1.8021e-07, 2.1086e-05, 2.7120e-05,\n",
      "        3.7959e-05, 2.9896e-05, 1.2598e-05, 2.1895e-06, 4.1129e-05, 6.9527e-06,\n",
      "        3.7749e-05, 1.5742e-05, 8.2763e-06, 2.0341e-05, 2.1382e-05, 1.6255e-05,\n",
      "        2.9371e-05, 2.1539e-05, 1.4307e-05, 3.5224e-05, 4.1956e-05, 4.8508e-05,\n",
      "        1.8966e-05, 2.1976e-05, 1.2394e-05, 9.8304e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0037, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0025, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0025, 0.0047, 0.0016, 0.0050, 0.0091, 0.0037, 0.0023, 0.0028, 0.0026,\n",
      "        0.0009, 0.0004, 0.0017, 0.0025, 0.0066, 0.0015, 0.0019, 0.0056, 0.0040,\n",
      "        0.0015, 0.0043, 0.0004, 0.0023, 0.0112, 0.0012, 0.0052, 0.0006, 0.0002,\n",
      "        0.0039, 0.0049, 0.0030, 0.0013, 0.0005, 0.0060, 0.0010, 0.0044, 0.0021,\n",
      "        0.0127, 0.0073, 0.0014, 0.0003, 0.0043, 0.0003, 0.0048, 0.0025, 0.0069,\n",
      "        0.0021, 0.0048, 0.0003, 0.0083, 0.0039, 0.0027, 0.0016, 0.0041, 0.0034,\n",
      "        0.0092, 0.0031, 0.0034, 0.0037, 0.0031, 0.0002, 0.0069, 0.0022, 0.0004,\n",
      "        0.0007], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0496, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0687, device='cuda:0')\n",
      "p.batch_l2: tensor([2.0417e-04, 1.9322e-04, 2.3690e-04, 2.6020e-04, 1.7282e-04, 1.9251e-04,\n",
      "        6.9479e-05, 2.5413e-04, 2.1119e-04, 2.5185e-04, 1.7264e-04, 2.1540e-04,\n",
      "        2.1261e-04, 6.6978e-05, 2.4425e-04, 2.2585e-04, 2.3079e-04, 1.3935e-04,\n",
      "        2.2437e-04, 1.2161e-04, 2.1351e-04, 1.9220e-04, 1.4248e-04, 2.3240e-04,\n",
      "        2.0257e-04, 2.0950e-04, 1.9972e-04, 1.7984e-04, 1.8739e-04, 2.1329e-04,\n",
      "        2.0985e-04, 2.0925e-04, 2.7431e-04, 2.1556e-04, 2.6067e-04, 2.4181e-04,\n",
      "        2.5881e-04, 1.1680e-04, 2.4351e-04, 2.1217e-04, 1.0972e-04, 2.4059e-04,\n",
      "        1.6125e-04, 2.1684e-04, 2.2246e-04, 9.3485e-06, 2.2558e-04, 2.3206e-04,\n",
      "        1.3525e-04, 1.5133e-04, 2.1506e-04, 2.0557e-04, 2.0407e-04, 2.3641e-04,\n",
      "        1.1304e-04, 1.8599e-04, 2.1759e-04, 1.9963e-04, 1.8233e-04, 2.1754e-04,\n",
      "        1.5139e-04, 1.9662e-04, 2.2215e-04, 1.8564e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0143, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0139, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.6049, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "Epoch   0/1 Iteration   0 Minibatch Loss 1.986  Accuracy 0.297\n",
      "p.batch_l2: tensor([0.0078, 0.0244, 0.0007, 0.0019, 0.0077, 0.0175, 0.0039, 0.0124, 0.0105,\n",
      "        0.0097, 0.0401, 0.0187, 0.0111, 0.0224, 0.0065, 0.0125, 0.0043, 0.0226,\n",
      "        0.0096, 0.0250, 0.0020, 0.0137, 0.0053, 0.0162, 0.0045, 0.0049, 0.0110,\n",
      "        0.0026, 0.0120, 0.0047, 0.0250, 0.0193, 0.0030, 0.0071, 0.0034, 0.0070,\n",
      "        0.0085, 0.0129, 0.0320, 0.0064, 0.0098, 0.0068, 0.0134, 0.0150, 0.0100,\n",
      "        0.0094, 0.0107, 0.0045, 0.0111, 0.0083, 0.0118, 0.0069, 0.0132, 0.0059,\n",
      "        0.0074, 0.0108, 0.0056, 0.0161, 0.0159, 0.0163, 0.0240, 0.0107, 0.0036,\n",
      "        0.0102], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0880, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1561, device='cuda:0')\n",
      "p.batch_l2: tensor([1.3996e-04, 2.8786e-04, 1.4350e-05, 2.9989e-05, 1.5637e-04, 2.0605e-04,\n",
      "        1.5084e-04, 2.1330e-04, 1.1874e-04, 1.1125e-04, 5.9621e-04, 2.7393e-04,\n",
      "        1.6257e-04, 1.9494e-04, 5.4330e-05, 2.1118e-04, 1.4215e-04, 3.0636e-04,\n",
      "        1.6448e-04, 5.6022e-04, 2.0715e-05, 1.0787e-04, 2.8770e-05, 5.2273e-04,\n",
      "        5.2417e-05, 1.5519e-04, 1.4670e-04, 4.4398e-05, 1.6789e-04, 1.2986e-04,\n",
      "        2.3288e-04, 2.1046e-04, 4.2734e-05, 8.2384e-05, 3.4019e-05, 5.5827e-05,\n",
      "        7.2973e-05, 1.8010e-04, 5.6553e-04, 4.7920e-05, 1.5018e-04, 7.2334e-05,\n",
      "        2.4982e-04, 4.0920e-04, 1.8809e-04, 6.6258e-05, 1.8311e-04, 1.0678e-04,\n",
      "        9.1051e-05, 1.5547e-04, 1.8790e-04, 1.2044e-04, 1.6864e-04, 2.0205e-04,\n",
      "        8.1918e-05, 1.4624e-04, 6.2005e-05, 2.2754e-04, 1.9536e-04, 8.6454e-05,\n",
      "        2.1170e-04, 2.7929e-04, 4.7655e-05, 2.1049e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0118, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0170, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0101, 0.0388, 0.0010, 0.0026, 0.0128, 0.0415, 0.0057, 0.0188, 0.0119,\n",
      "        0.0203, 0.0565, 0.0394, 0.0146, 0.0241, 0.0075, 0.0200, 0.0063, 0.0490,\n",
      "        0.0113, 0.0429, 0.0029, 0.0185, 0.0092, 0.0285, 0.0043, 0.0103, 0.0100,\n",
      "        0.0046, 0.0164, 0.0126, 0.0356, 0.0213, 0.0037, 0.0117, 0.0042, 0.0060,\n",
      "        0.0138, 0.0200, 0.0480, 0.0060, 0.0137, 0.0088, 0.0205, 0.0226, 0.0131,\n",
      "        0.0149, 0.0212, 0.0054, 0.0218, 0.0098, 0.0226, 0.0094, 0.0137, 0.0128,\n",
      "        0.0121, 0.0251, 0.0095, 0.0212, 0.0203, 0.0168, 0.0417, 0.0144, 0.0064,\n",
      "        0.0194], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1005, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1970, device='cuda:0')\n",
      "p.batch_l2: tensor([2.3679e-05, 7.0620e-05, 2.7634e-06, 9.1467e-06, 8.1551e-05, 1.3504e-04,\n",
      "        1.7277e-05, 5.9242e-05, 2.3465e-05, 4.5339e-05, 1.3450e-04, 8.4233e-05,\n",
      "        3.4732e-05, 5.1126e-05, 7.7127e-06, 5.2007e-05, 2.4407e-05, 8.0381e-05,\n",
      "        4.3878e-05, 1.4378e-04, 1.0576e-05, 4.5746e-05, 1.6363e-05, 1.8484e-04,\n",
      "        1.0080e-05, 4.1922e-05, 4.0621e-05, 1.2409e-05, 6.1596e-05, 3.2413e-05,\n",
      "        6.6524e-05, 4.3957e-05, 1.3588e-05, 4.0614e-05, 7.9475e-06, 3.2904e-05,\n",
      "        3.1579e-05, 3.2060e-05, 1.1547e-04, 1.2420e-05, 2.8207e-05, 1.4636e-05,\n",
      "        1.0698e-04, 1.3363e-04, 3.4456e-05, 2.2035e-05, 5.0999e-05, 1.6968e-05,\n",
      "        4.1281e-05, 2.3966e-05, 9.8663e-05, 1.7398e-05, 8.1110e-05, 6.3194e-05,\n",
      "        1.7813e-05, 4.4980e-05, 2.4966e-05, 4.8740e-05, 7.8290e-05, 2.2802e-05,\n",
      "        7.9315e-05, 5.2122e-05, 1.5285e-05, 7.1430e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0049, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0084, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0148, 0.0357, 0.0010, 0.0028, 0.0071, 0.0215, 0.0074, 0.0144, 0.0078,\n",
      "        0.0132, 0.0336, 0.0281, 0.0100, 0.0404, 0.0078, 0.0165, 0.0017, 0.0426,\n",
      "        0.0051, 0.0375, 0.0052, 0.0078, 0.0154, 0.0106, 0.0079, 0.0075, 0.0053,\n",
      "        0.0171, 0.0057, 0.0058, 0.0129, 0.0160, 0.0048, 0.0024, 0.0087, 0.0043,\n",
      "        0.0207, 0.0317, 0.0251, 0.0047, 0.0138, 0.0068, 0.0110, 0.0079, 0.0196,\n",
      "        0.0111, 0.0168, 0.0022, 0.0231, 0.0113, 0.0046, 0.0052, 0.0102, 0.0074,\n",
      "        0.0057, 0.0154, 0.0147, 0.0238, 0.0173, 0.0253, 0.0362, 0.0102, 0.0034,\n",
      "        0.0384], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.1215, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1889, device='cuda:0')\n",
      "p.batch_l2: tensor([2.3496e-05, 4.9778e-05, 1.8793e-06, 4.7832e-06, 3.1531e-05, 5.4237e-05,\n",
      "        8.8107e-06, 2.1469e-05, 1.1676e-05, 2.9575e-05, 6.6063e-05, 4.0664e-05,\n",
      "        2.8339e-05, 8.1967e-05, 9.1691e-06, 3.3586e-05, 5.7478e-06, 3.5352e-05,\n",
      "        1.6518e-05, 5.7655e-05, 7.8266e-06, 1.6715e-05, 1.9929e-05, 5.5898e-05,\n",
      "        8.0505e-06, 1.2885e-05, 2.4135e-05, 1.3510e-05, 2.7994e-05, 1.5175e-05,\n",
      "        3.5749e-05, 4.2903e-05, 9.4509e-06, 9.9802e-06, 8.3538e-06, 3.0527e-05,\n",
      "        2.3990e-05, 2.5609e-05, 5.7418e-05, 1.4479e-05, 2.4595e-05, 1.5206e-05,\n",
      "        5.5331e-05, 5.1716e-05, 4.3943e-05, 1.4890e-05, 3.7901e-05, 1.0577e-05,\n",
      "        2.5813e-05, 1.7891e-05, 2.0270e-05, 1.2887e-05, 4.9642e-05, 2.6294e-05,\n",
      "        1.3741e-05, 2.9328e-05, 2.3481e-05, 4.9056e-05, 4.7737e-05, 3.0053e-05,\n",
      "        3.7452e-05, 3.0066e-05, 1.4240e-05, 5.1511e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0048, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0071, device='cuda:0')\n",
      "p.batch_l2: tensor([3.3991e-03, 3.9335e-03, 1.0012e-03, 2.8333e-03, 3.5764e-03, 2.1741e-03,\n",
      "        4.4675e-03, 1.6624e-03, 9.5359e-03, 3.1465e-03, 3.3361e-02, 1.1757e-02,\n",
      "        5.9135e-03, 5.5971e-03, 5.5879e-03, 4.0997e-03, 8.2970e-04, 1.6313e-02,\n",
      "        6.1259e-03, 1.7595e-03, 9.4490e-03, 3.3547e-03, 3.6442e-03, 1.6572e-03,\n",
      "        4.8545e-03, 7.2526e-03, 5.7634e-05, 1.2114e-02, 3.8802e-03, 7.7029e-03,\n",
      "        3.3624e-03, 1.0815e-02, 5.4323e-03, 4.5814e-03, 6.6163e-03, 8.3391e-04,\n",
      "        2.0839e-03, 6.6593e-03, 1.8178e-02, 2.1445e-03, 4.0605e-04, 4.6208e-03,\n",
      "        2.8854e-03, 1.9354e-03, 1.3517e-03, 1.0072e-03, 1.8720e-02, 2.7625e-03,\n",
      "        1.8619e-02, 7.9476e-03, 4.3532e-04, 5.2905e-03, 3.9064e-03, 4.1420e-03,\n",
      "        2.9036e-03, 8.9174e-03, 7.5748e-04, 1.3376e-02, 2.4085e-04, 1.1801e-02,\n",
      "        5.6850e-03, 4.1523e-03, 5.8563e-04, 1.1102e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0583, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0627, device='cuda:0')\n",
      "p.batch_l2: tensor([2.4412e-04, 2.5498e-04, 2.0415e-04, 2.3107e-05, 2.4604e-04, 2.2845e-04,\n",
      "        9.2931e-05, 9.6773e-05, 1.6624e-04, 1.4014e-04, 3.7581e-04, 2.4275e-04,\n",
      "        1.4860e-04, 2.2336e-04, 8.0449e-05, 2.3830e-04, 2.1984e-04, 1.3843e-04,\n",
      "        2.7657e-04, 1.8252e-04, 2.6174e-04, 1.0127e-04, 8.4658e-05, 2.5578e-04,\n",
      "        2.2912e-05, 1.8029e-04, 2.0297e-04, 1.5851e-04, 2.4363e-04, 1.1113e-04,\n",
      "        1.6940e-04, 1.4466e-04, 1.7715e-04, 2.4963e-04, 7.4361e-05, 2.2790e-04,\n",
      "        1.8576e-04, 1.7005e-04, 2.9717e-04, 2.0482e-04, 2.1692e-04, 1.9302e-04,\n",
      "        2.1533e-04, 2.4008e-04, 1.7384e-04, 1.6837e-04, 2.9077e-04, 1.9398e-04,\n",
      "        3.1628e-04, 1.5321e-04, 2.1613e-04, 1.8093e-04, 2.2082e-04, 1.6222e-04,\n",
      "        1.9230e-04, 2.1012e-04, 1.8026e-04, 2.9511e-04, 2.0238e-04, 1.5701e-04,\n",
      "        2.0734e-04, 2.4426e-04, 2.2512e-04, 1.9065e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0156, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0160, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.4761, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([0.0071, 0.0045, 0.0136, 0.0019, 0.0769, 0.0118, 0.0112, 0.0045, 0.0121,\n",
      "        0.0029, 0.0087, 0.0136, 0.0044, 0.0033, 0.0207, 0.0194, 0.0048, 0.0801,\n",
      "        0.0039, 0.0056, 0.0044, 0.0102, 0.0077, 0.0069, 0.0064, 0.0159, 0.0597,\n",
      "        0.0315, 0.0099, 0.0206, 0.0030, 0.0274, 0.0008, 0.0143, 0.0052, 0.0307,\n",
      "        0.0023, 0.0083, 0.0154, 0.0006, 0.0243, 0.0225, 0.0166, 0.0081, 0.0097,\n",
      "        0.0221, 0.0167, 0.0030, 0.0316, 0.0188, 0.0084, 0.0121, 0.0036, 0.0115,\n",
      "        0.0060, 0.0143, 0.0066, 0.0475, 0.0101, 0.0040, 0.0098, 0.0204, 0.0248,\n",
      "        0.0157], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0845, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0672, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2282e-04, 3.8636e-05, 2.1732e-04, 4.3587e-05, 8.5657e-04, 7.6513e-05,\n",
      "        2.1584e-04, 7.7086e-05, 1.2627e-04, 5.1658e-05, 1.3193e-04, 1.9334e-04,\n",
      "        5.6496e-05, 1.7268e-05, 3.2230e-04, 4.1570e-04, 4.2824e-05, 4.5525e-04,\n",
      "        4.2924e-05, 6.4434e-05, 3.8956e-05, 1.8237e-04, 1.3500e-04, 6.6914e-05,\n",
      "        8.9794e-05, 1.8535e-04, 3.8356e-04, 3.2998e-04, 1.1799e-04, 4.5532e-04,\n",
      "        2.4552e-05, 2.9553e-04, 8.0325e-06, 2.2937e-04, 6.6961e-05, 2.9214e-04,\n",
      "        3.2058e-05, 5.1614e-05, 3.3785e-04, 4.7333e-06, 3.1211e-04, 3.2556e-04,\n",
      "        1.8297e-04, 7.5685e-05, 1.1296e-04, 1.2554e-04, 2.1749e-04, 1.9626e-05,\n",
      "        6.6818e-04, 2.0381e-04, 3.7722e-05, 2.1856e-04, 1.6789e-04, 1.5170e-04,\n",
      "        9.3287e-05, 2.0984e-04, 5.8703e-05, 5.3461e-04, 2.3666e-04, 3.5279e-05,\n",
      "        1.7984e-04, 2.3656e-04, 2.2803e-04, 1.4829e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0111, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0062, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0102, 0.0053, 0.0184, 0.0031, 0.0895, 0.0297, 0.0126, 0.0080, 0.0152,\n",
      "        0.0036, 0.0151, 0.0277, 0.0068, 0.0061, 0.0239, 0.0299, 0.0051, 0.0718,\n",
      "        0.0107, 0.0179, 0.0081, 0.0122, 0.0098, 0.0135, 0.0078, 0.0157, 0.0689,\n",
      "        0.0464, 0.0121, 0.0535, 0.0027, 0.0739, 0.0014, 0.0173, 0.0057, 0.0310,\n",
      "        0.0033, 0.0094, 0.0233, 0.0009, 0.0474, 0.0587, 0.0289, 0.0061, 0.0246,\n",
      "        0.0280, 0.0237, 0.0051, 0.0322, 0.0179, 0.0147, 0.0134, 0.0072, 0.0199,\n",
      "        0.0104, 0.0158, 0.0103, 0.0425, 0.0123, 0.0083, 0.0188, 0.0310, 0.0284,\n",
      "        0.0181], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1010, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0731, device='cuda:0')\n",
      "p.batch_l2: tensor([5.6368e-05, 1.1052e-05, 4.6514e-05, 1.0585e-05, 2.5144e-04, 5.8282e-05,\n",
      "        3.6880e-05, 2.3343e-05, 3.4468e-05, 9.9069e-06, 7.1938e-05, 8.9614e-05,\n",
      "        3.0919e-05, 8.3826e-06, 7.3408e-05, 9.1688e-05, 9.7412e-06, 9.7218e-05,\n",
      "        1.9554e-05, 4.4852e-05, 1.9747e-05, 3.6934e-05, 2.9000e-05, 3.9724e-05,\n",
      "        2.1600e-05, 2.4871e-05, 1.4997e-04, 9.0819e-05, 2.7469e-05, 1.3215e-04,\n",
      "        6.3239e-06, 1.4374e-04, 3.7537e-06, 6.7281e-05, 1.3563e-05, 7.5973e-05,\n",
      "        1.0444e-05, 1.8982e-05, 7.3919e-05, 1.5316e-06, 1.0352e-04, 1.3575e-04,\n",
      "        7.1938e-05, 1.7168e-05, 5.2074e-05, 4.5802e-05, 4.5782e-05, 6.4891e-06,\n",
      "        1.5594e-04, 4.9447e-05, 2.3411e-05, 2.7021e-05, 3.0775e-05, 4.9829e-05,\n",
      "        2.9707e-05, 5.3082e-05, 1.5310e-05, 1.7909e-04, 4.2966e-05, 1.6026e-05,\n",
      "        6.1627e-05, 8.8786e-05, 7.5225e-05, 4.6279e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0075, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0033, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0066, 0.0055, 0.0276, 0.0016, 0.0572, 0.0147, 0.0320, 0.0095, 0.0074,\n",
      "        0.0050, 0.0096, 0.0382, 0.0058, 0.0017, 0.0122, 0.0148, 0.0170, 0.0537,\n",
      "        0.0086, 0.0070, 0.0057, 0.0062, 0.0182, 0.0141, 0.0059, 0.0209, 0.0479,\n",
      "        0.0322, 0.0097, 0.0244, 0.0019, 0.0764, 0.0020, 0.0146, 0.0161, 0.0183,\n",
      "        0.0039, 0.0094, 0.0228, 0.0012, 0.0190, 0.0286, 0.0256, 0.0064, 0.0177,\n",
      "        0.0209, 0.0177, 0.0040, 0.0237, 0.0387, 0.0113, 0.0222, 0.0048, 0.0317,\n",
      "        0.0209, 0.0071, 0.0199, 0.0257, 0.0063, 0.0064, 0.0090, 0.0480, 0.0165,\n",
      "        0.0125], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0815, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0744, device='cuda:0')\n",
      "p.batch_l2: tensor([3.0430e-05, 1.4994e-05, 3.3547e-05, 5.0729e-06, 1.0118e-04, 2.4331e-05,\n",
      "        4.2326e-05, 1.3170e-05, 1.3839e-05, 6.7966e-06, 3.4967e-05, 4.1124e-05,\n",
      "        1.4624e-05, 2.6092e-06, 2.6669e-05, 3.6405e-05, 1.7525e-05, 1.1234e-04,\n",
      "        6.7024e-06, 1.2121e-05, 6.8970e-06, 1.4324e-05, 3.2397e-05, 2.0097e-05,\n",
      "        1.1107e-05, 4.5790e-05, 6.8490e-05, 3.7807e-05, 1.3642e-05, 3.1565e-05,\n",
      "        4.3575e-06, 5.7925e-05, 2.3370e-06, 4.9910e-05, 1.3209e-05, 4.9935e-05,\n",
      "        4.0885e-06, 1.5937e-05, 4.0810e-05, 1.2478e-06, 4.0377e-05, 4.0810e-05,\n",
      "        3.5394e-05, 1.4425e-05, 1.7374e-05, 2.4060e-05, 3.1305e-05, 5.6073e-06,\n",
      "        1.0890e-04, 5.9682e-05, 1.3833e-05, 2.5339e-05, 1.9904e-05, 2.3428e-05,\n",
      "        2.3002e-05, 2.0621e-05, 2.9632e-05, 4.0269e-05, 2.5837e-05, 9.2802e-06,\n",
      "        2.5266e-05, 5.1694e-05, 4.2763e-05, 1.6426e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0055, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0039, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0013, 0.0045, 0.0056, 0.0036, 0.0229, 0.0091, 0.0079, 0.0067, 0.0036,\n",
      "        0.0036, 0.0016, 0.0090, 0.0031, 0.0025, 0.0031, 0.0021, 0.0213, 0.0187,\n",
      "        0.0064, 0.0051, 0.0028, 0.0041, 0.0248, 0.0074, 0.0033, 0.0083, 0.0224,\n",
      "        0.0117, 0.0116, 0.0068, 0.0026, 0.0087, 0.0014, 0.0060, 0.0023, 0.0056,\n",
      "        0.0029, 0.0023, 0.0145, 0.0010, 0.0081, 0.0047, 0.0274, 0.0052, 0.0097,\n",
      "        0.0096, 0.0047, 0.0018, 0.0018, 0.0093, 0.0096, 0.0126, 0.0029, 0.0078,\n",
      "        0.0041, 0.0049, 0.0069, 0.0108, 0.0048, 0.0034, 0.0130, 0.0464, 0.0019,\n",
      "        0.0097], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0361, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0668, device='cuda:0')\n",
      "p.batch_l2: tensor([2.1633e-04, 2.1532e-04, 1.4031e-04, 2.2021e-04, 2.9014e-04, 1.5176e-04,\n",
      "        1.0939e-04, 2.4838e-04, 9.6346e-05, 4.5412e-05, 2.3541e-04, 1.3854e-04,\n",
      "        2.2600e-04, 1.8650e-05, 2.0271e-04, 1.5141e-04, 2.3163e-04, 3.4273e-04,\n",
      "        3.6209e-05, 8.1790e-05, 3.7752e-05, 2.3065e-04, 2.6953e-04, 1.7912e-04,\n",
      "        9.3562e-05, 1.5806e-04, 2.4208e-04, 1.8231e-04, 1.0635e-04, 2.3569e-04,\n",
      "        1.9254e-05, 2.5418e-04, 1.6652e-05, 2.4173e-04, 2.4231e-04, 2.2975e-04,\n",
      "        1.1690e-05, 9.2043e-05, 1.4443e-04, 4.9646e-06, 1.8608e-04, 2.4503e-04,\n",
      "        1.9649e-04, 1.8866e-04, 2.0159e-04, 2.6533e-04, 1.3654e-04, 1.6741e-05,\n",
      "        2.5031e-04, 2.6744e-04, 5.9918e-05, 1.0222e-04, 2.4003e-04, 9.4959e-05,\n",
      "        2.2528e-04, 1.0749e-04, 1.6567e-04, 2.2121e-04, 2.1170e-04, 2.3498e-04,\n",
      "        2.3980e-04, 3.0875e-04, 1.2542e-04, 1.5614e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0147, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0147, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.4339, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.batch_l2: tensor([6.8523e-03, 1.2883e-02, 4.5884e-02, 1.6217e-02, 1.8674e-02, 3.4732e-02,\n",
      "        8.5769e-03, 2.1522e-02, 1.6805e-02, 2.9150e-02, 3.1486e-02, 3.6061e-02,\n",
      "        1.9201e-02, 1.3991e-02, 1.4675e-02, 2.5713e-02, 2.4208e-02, 3.4612e-02,\n",
      "        3.7172e-02, 1.2184e-01, 3.6149e-02, 1.2438e-02, 2.1832e-02, 5.9907e-03,\n",
      "        4.0478e-02, 1.6984e-03, 7.1861e-02, 4.1793e-02, 1.9676e-02, 3.3890e-02,\n",
      "        6.9903e-03, 2.0003e-02, 7.3101e-02, 1.2459e-06, 1.5437e-02, 2.9746e-02,\n",
      "        1.8632e-02, 6.8217e-03, 9.1178e-02, 9.4678e-02, 1.1674e-02, 9.6668e-03,\n",
      "        1.5104e-02, 2.6124e-02, 9.0958e-03, 2.7097e-02, 1.4048e-02, 4.3987e-03,\n",
      "        6.0482e-02, 1.7285e-02, 3.6615e-02, 6.9567e-03, 2.7449e-02, 1.3691e-02,\n",
      "        1.0330e-02, 9.8010e-03, 1.1170e-04, 2.4655e-02, 2.3482e-02, 1.7552e-02,\n",
      "        3.5334e-02, 1.0694e-02, 2.6948e-02, 3.5631e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0828, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1135, device='cuda:0')\n",
      "p.batch_l2: tensor([1.4662e-04, 2.1824e-04, 9.4134e-04, 6.6732e-04, 4.1644e-04, 8.3716e-04,\n",
      "        8.1054e-05, 4.7793e-04, 4.1407e-04, 3.7919e-04, 5.1157e-04, 3.6122e-04,\n",
      "        3.9792e-04, 1.4107e-04, 3.2921e-04, 5.3954e-04, 1.1271e-04, 4.7748e-04,\n",
      "        2.7001e-04, 1.7056e-03, 4.1937e-04, 1.6069e-04, 4.8258e-04, 6.2938e-05,\n",
      "        8.4643e-04, 1.0523e-05, 1.3478e-03, 8.9999e-04, 5.8978e-04, 3.2147e-04,\n",
      "        1.5825e-04, 4.6910e-04, 9.7258e-04, 1.1849e-08, 9.0608e-05, 6.1736e-04,\n",
      "        3.4518e-04, 5.8570e-05, 4.6981e-04, 1.2521e-03, 1.4307e-04, 1.2971e-04,\n",
      "        1.7304e-04, 3.0014e-04, 4.2040e-05, 2.7129e-04, 2.9351e-04, 3.8806e-05,\n",
      "        6.6981e-04, 2.4757e-04, 1.4189e-03, 1.8433e-04, 3.6876e-04, 4.4677e-05,\n",
      "        2.3881e-04, 1.9757e-04, 8.7877e-07, 1.2334e-03, 5.0491e-04, 6.7584e-04,\n",
      "        3.6618e-04, 2.1717e-04, 6.1160e-04, 1.4921e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0121, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0148, device='cuda:0')\n",
      "p.batch_l2: tensor([9.0389e-03, 2.3691e-02, 5.9067e-02, 1.6898e-02, 2.6463e-02, 6.7605e-02,\n",
      "        1.4753e-02, 2.9629e-02, 2.4197e-02, 6.8367e-02, 3.0757e-02, 6.3433e-02,\n",
      "        4.7603e-02, 1.9629e-02, 2.1167e-02, 3.5431e-02, 5.2274e-02, 4.4486e-02,\n",
      "        5.2963e-02, 1.7711e-01, 5.0385e-02, 1.3074e-02, 3.8066e-02, 7.9405e-03,\n",
      "        6.4628e-02, 3.3258e-03, 1.4408e-01, 6.3998e-02, 2.0867e-02, 4.9066e-02,\n",
      "        9.2548e-03, 3.4442e-02, 8.2735e-02, 2.5895e-06, 2.4589e-02, 4.0318e-02,\n",
      "        3.4647e-02, 1.0262e-02, 1.5327e-01, 1.6811e-01, 1.7827e-02, 1.2185e-02,\n",
      "        1.9186e-02, 5.7708e-02, 1.1436e-02, 3.6255e-02, 1.3645e-02, 3.7424e-03,\n",
      "        1.3038e-01, 4.9622e-02, 6.4416e-02, 1.8186e-02, 4.8687e-02, 1.2781e-02,\n",
      "        1.5383e-02, 1.6871e-02, 1.6117e-04, 4.6677e-02, 2.7741e-02, 2.6619e-02,\n",
      "        8.4121e-02, 1.9369e-02, 5.7914e-02, 6.4724e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.0951, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1539, device='cuda:0')\n",
      "p.batch_l2: tensor([2.6406e-05, 5.2025e-05, 1.7945e-04, 8.8858e-05, 1.5803e-04, 1.9464e-04,\n",
      "        3.0890e-05, 9.1154e-05, 1.2870e-04, 1.1725e-04, 8.3166e-05, 1.2786e-04,\n",
      "        8.5049e-05, 4.5302e-05, 1.2076e-04, 1.0695e-04, 9.2717e-05, 9.5154e-05,\n",
      "        7.9072e-05, 4.1775e-04, 1.3178e-04, 2.9387e-05, 1.1858e-04, 2.4420e-05,\n",
      "        1.6792e-04, 5.8355e-06, 3.2197e-04, 1.0711e-04, 1.0347e-04, 8.9370e-05,\n",
      "        2.0074e-05, 1.5189e-04, 1.5092e-04, 4.0285e-09, 4.8758e-05, 1.1572e-04,\n",
      "        8.6372e-05, 2.8836e-05, 2.5302e-04, 3.4350e-04, 3.6118e-05, 2.7126e-05,\n",
      "        5.0088e-05, 1.3042e-04, 1.8551e-05, 6.2513e-05, 4.3963e-05, 8.3659e-06,\n",
      "        2.7922e-04, 1.0496e-04, 2.0963e-04, 4.1672e-05, 1.1242e-04, 1.6182e-05,\n",
      "        5.3209e-05, 5.3609e-05, 3.1187e-07, 2.5493e-04, 6.5628e-05, 1.4586e-04,\n",
      "        1.2965e-04, 4.6171e-05, 2.1690e-04, 6.6779e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0051, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0072, device='cuda:0')\n",
      "p.batch_l2: tensor([8.1942e-03, 1.6477e-02, 2.0822e-02, 1.8841e-02, 1.2097e-02, 7.6593e-02,\n",
      "        7.7326e-03, 1.8371e-02, 1.6996e-02, 4.9043e-02, 2.5007e-02, 4.4159e-02,\n",
      "        3.2344e-02, 8.4618e-03, 1.8486e-02, 1.6294e-02, 3.5237e-02, 3.1061e-02,\n",
      "        7.4434e-02, 1.5393e-01, 1.9780e-02, 1.2949e-02, 3.1711e-02, 7.8607e-03,\n",
      "        6.1029e-02, 1.4602e-03, 1.0298e-01, 1.9921e-02, 1.8090e-02, 4.0954e-02,\n",
      "        7.6235e-03, 2.1656e-02, 5.4070e-02, 2.9058e-06, 1.6066e-02, 4.5049e-02,\n",
      "        5.0780e-02, 1.2173e-02, 1.4269e-01, 6.3158e-02, 7.1661e-03, 2.1672e-02,\n",
      "        8.0972e-03, 3.1138e-02, 9.3863e-03, 2.4527e-02, 5.9965e-03, 1.2138e-02,\n",
      "        5.4214e-02, 3.5080e-02, 5.3588e-02, 1.3695e-02, 3.9027e-02, 1.4792e-02,\n",
      "        2.0701e-02, 1.8985e-02, 2.3850e-04, 3.1460e-02, 3.2740e-02, 1.6602e-02,\n",
      "        4.4900e-02, 1.8294e-02, 2.9536e-02, 6.2967e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0905, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1284, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2845e-05, 2.6986e-05, 4.1035e-05, 5.2778e-05, 3.8168e-05, 6.6799e-05,\n",
      "        1.5764e-05, 4.3731e-05, 5.0393e-05, 3.0025e-05, 7.1586e-05, 4.3306e-05,\n",
      "        3.1687e-05, 1.9516e-05, 4.9852e-05, 3.6450e-05, 4.5242e-05, 5.4299e-05,\n",
      "        7.6338e-05, 1.6098e-04, 4.2538e-05, 2.3593e-05, 4.9438e-05, 9.7897e-06,\n",
      "        9.6579e-05, 2.1140e-06, 9.1395e-05, 4.0704e-05, 5.9384e-05, 6.0449e-05,\n",
      "        8.9000e-06, 4.9722e-05, 7.2411e-05, 1.9716e-09, 2.2427e-05, 4.1781e-05,\n",
      "        6.0876e-05, 2.5542e-05, 1.4576e-04, 1.0207e-04, 1.2651e-05, 2.3851e-05,\n",
      "        2.2322e-05, 5.4904e-05, 1.3927e-05, 2.5756e-05, 1.7517e-05, 1.9941e-05,\n",
      "        9.6057e-05, 3.4908e-05, 6.1536e-05, 1.8393e-05, 5.4951e-05, 2.4444e-05,\n",
      "        2.5619e-05, 3.3627e-05, 1.6268e-07, 7.1928e-05, 5.1752e-05, 5.6718e-05,\n",
      "        5.9468e-05, 2.6070e-05, 7.0914e-05, 4.4431e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0036, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0052, device='cuda:0')\n",
      "p.batch_l2: tensor([4.9993e-03, 1.8034e-02, 8.9245e-03, 4.7247e-03, 1.3116e-02, 3.9807e-02,\n",
      "        9.3042e-03, 1.7654e-02, 1.2034e-02, 7.2103e-02, 5.4028e-03, 3.8955e-02,\n",
      "        1.2188e-02, 5.8284e-03, 1.2206e-02, 6.4857e-03, 3.3247e-02, 2.7090e-02,\n",
      "        5.6323e-02, 4.9579e-02, 1.3592e-02, 4.3973e-03, 1.5476e-02, 5.7329e-03,\n",
      "        2.8774e-02, 2.9127e-03, 4.7468e-02, 1.2955e-02, 7.0211e-03, 5.8712e-03,\n",
      "        9.2245e-03, 1.2845e-02, 1.2107e-02, 3.5686e-06, 1.8399e-02, 4.1996e-02,\n",
      "        2.3630e-02, 6.7626e-03, 8.5560e-02, 3.1842e-02, 1.4244e-02, 3.2975e-02,\n",
      "        3.6729e-03, 1.1907e-02, 1.0003e-02, 1.9824e-02, 1.5143e-02, 4.3876e-03,\n",
      "        1.6932e-02, 1.7895e-02, 2.6590e-02, 1.3855e-02, 2.5043e-02, 2.7302e-03,\n",
      "        5.6523e-03, 8.1032e-03, 9.4685e-05, 1.3468e-02, 7.9897e-03, 4.4117e-03,\n",
      "        3.0698e-02, 6.3666e-03, 1.8463e-02, 3.3933e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0707, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1343, device='cuda:0')\n",
      "p.batch_l2: tensor([8.0968e-05, 2.3588e-04, 1.7219e-04, 2.3102e-04, 2.5603e-04, 3.0932e-04,\n",
      "        1.6527e-04, 2.4061e-04, 2.2674e-04, 1.9551e-04, 2.1319e-04, 1.9249e-04,\n",
      "        2.2032e-04, 2.3117e-04, 2.2750e-04, 2.4428e-04, 1.4177e-04, 1.8764e-04,\n",
      "        2.4267e-04, 3.5908e-04, 2.6895e-04, 2.4034e-04, 1.7005e-04, 6.8790e-05,\n",
      "        2.8997e-04, 1.2501e-05, 3.7657e-04, 1.2430e-04, 2.3202e-04, 1.6249e-04,\n",
      "        7.4072e-05, 2.4212e-04, 2.2678e-04, 7.0487e-09, 9.4672e-05, 2.0719e-04,\n",
      "        2.7484e-04, 8.3395e-05, 4.4156e-04, 2.9986e-04, 6.8883e-05, 2.4266e-04,\n",
      "        6.8358e-05, 1.8971e-04, 7.4357e-05, 8.9072e-05, 1.8233e-04, 8.6988e-05,\n",
      "        2.5561e-04, 2.0032e-04, 2.4669e-04, 1.1741e-04, 2.6772e-04, 1.7215e-04,\n",
      "        1.2224e-04, 2.5948e-04, 3.3997e-07, 2.6753e-04, 1.9247e-04, 2.3708e-04,\n",
      "        2.6423e-04, 7.1362e-05, 2.5009e-04, 1.3008e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0090, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0154, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.6261, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([0.0124, 0.0012, 0.0287, 0.0026, 0.0210, 0.0184, 0.0052, 0.0062, 0.0168,\n",
      "        0.0312, 0.0059, 0.0075, 0.0120, 0.0018, 0.0038, 0.0490, 0.0006, 0.0210,\n",
      "        0.0253, 0.0085, 0.0119, 0.0154, 0.0132, 0.0127, 0.0181, 0.0061, 0.0196,\n",
      "        0.0097, 0.0242, 0.0195, 0.0041, 0.0057, 0.0119, 0.0311, 0.0319, 0.0184,\n",
      "        0.0451, 0.0082, 0.0072, 0.0145, 0.0586, 0.0112, 0.0090, 0.0045, 0.0085,\n",
      "        0.0408, 0.0330, 0.0104, 0.0117, 0.0106, 0.0274, 0.0143, 0.0072, 0.0624,\n",
      "        0.0044, 0.0088, 0.0035, 0.0630, 0.0260, 0.0041, 0.0138, 0.0046, 0.0216,\n",
      "        0.0024], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1113, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0346, device='cuda:0')\n",
      "p.batch_l2: tensor([5.2493e-04, 1.7295e-05, 3.1959e-04, 3.3978e-05, 2.3720e-04, 1.4309e-04,\n",
      "        6.4071e-05, 3.1845e-04, 9.7247e-05, 5.7610e-04, 7.6328e-05, 5.5399e-05,\n",
      "        1.8037e-04, 2.1839e-05, 4.8215e-05, 3.9084e-04, 1.2231e-05, 3.6142e-04,\n",
      "        1.8377e-04, 5.9121e-05, 1.8122e-04, 3.0503e-04, 1.2067e-04, 2.1690e-04,\n",
      "        1.3297e-04, 7.5082e-05, 1.6655e-04, 1.1760e-04, 2.5276e-04, 1.6198e-04,\n",
      "        3.4275e-05, 6.4315e-05, 1.5276e-04, 4.7418e-04, 2.0921e-04, 2.0530e-04,\n",
      "        7.6492e-04, 9.2373e-05, 1.6653e-04, 2.3628e-04, 4.8753e-04, 9.1885e-05,\n",
      "        2.1132e-04, 2.1502e-05, 1.1350e-04, 9.5495e-04, 2.4520e-04, 2.1421e-04,\n",
      "        1.4675e-04, 4.2101e-05, 3.2489e-04, 1.0280e-04, 9.3646e-05, 1.0793e-03,\n",
      "        6.8829e-05, 8.2781e-05, 1.0774e-04, 2.9888e-04, 2.8254e-04, 1.8496e-04,\n",
      "        1.0983e-04, 5.8138e-05, 1.9231e-04, 2.4436e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0229, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0042, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0211, 0.0025, 0.0319, 0.0042, 0.0240, 0.0191, 0.0126, 0.0118, 0.0305,\n",
      "        0.0785, 0.0108, 0.0109, 0.0154, 0.0036, 0.0061, 0.0397, 0.0011, 0.0306,\n",
      "        0.0378, 0.0101, 0.0184, 0.0187, 0.0240, 0.0174, 0.0306, 0.0079, 0.0294,\n",
      "        0.0113, 0.0326, 0.0258, 0.0051, 0.0065, 0.0193, 0.0348, 0.0498, 0.0141,\n",
      "        0.0458, 0.0120, 0.0109, 0.0228, 0.0827, 0.0170, 0.0147, 0.0052, 0.0100,\n",
      "        0.1062, 0.0445, 0.0110, 0.0144, 0.0128, 0.0397, 0.0182, 0.0118, 0.1056,\n",
      "        0.0050, 0.0092, 0.0082, 0.0481, 0.0337, 0.0094, 0.0174, 0.0088, 0.0172,\n",
      "        0.0037], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1454, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0495, device='cuda:0')\n",
      "p.batch_l2: tensor([1.1351e-04, 5.6272e-06, 7.9660e-05, 6.6236e-06, 4.8098e-05, 3.4050e-05,\n",
      "        2.4934e-05, 6.1163e-05, 5.4003e-05, 1.3917e-04, 2.3851e-05, 2.3264e-05,\n",
      "        3.3926e-05, 1.0448e-05, 1.6714e-05, 6.6864e-05, 3.0997e-06, 6.8534e-05,\n",
      "        6.3599e-05, 2.3318e-05, 3.0488e-05, 5.5616e-05, 5.3855e-05, 6.1490e-05,\n",
      "        4.4790e-05, 2.1547e-05, 8.0747e-05, 2.6176e-05, 9.4154e-05, 5.5699e-05,\n",
      "        1.4625e-05, 1.1947e-05, 5.9814e-05, 1.7118e-04, 9.1527e-05, 2.2152e-05,\n",
      "        2.3220e-04, 2.3976e-05, 4.6118e-05, 6.8642e-05, 1.5766e-04, 2.8779e-05,\n",
      "        5.2506e-05, 8.6332e-06, 3.1153e-05, 2.5818e-04, 9.8614e-05, 2.2231e-05,\n",
      "        2.8614e-05, 3.0916e-05, 9.1670e-05, 3.3949e-05, 4.1372e-05, 2.5885e-04,\n",
      "        1.3964e-05, 2.6735e-05, 2.8493e-05, 6.6701e-05, 6.3967e-05, 3.9754e-05,\n",
      "        5.2950e-05, 2.5516e-05, 4.1213e-05, 7.6503e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0107, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0024, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0136, 0.0040, 0.0423, 0.0055, 0.0326, 0.0138, 0.0216, 0.0102, 0.0455,\n",
      "        0.0735, 0.0112, 0.0066, 0.0287, 0.0036, 0.0051, 0.0474, 0.0047, 0.0231,\n",
      "        0.0381, 0.0062, 0.0370, 0.0236, 0.0206, 0.0124, 0.0777, 0.0077, 0.0228,\n",
      "        0.0217, 0.0195, 0.0341, 0.0131, 0.0082, 0.0356, 0.0264, 0.0403, 0.0212,\n",
      "        0.0278, 0.0181, 0.0112, 0.0204, 0.0561, 0.0133, 0.0095, 0.0194, 0.0190,\n",
      "        0.1191, 0.0716, 0.0130, 0.0084, 0.0190, 0.0084, 0.0082, 0.0098, 0.1129,\n",
      "        0.0144, 0.0092, 0.0161, 0.0294, 0.0893, 0.0095, 0.0191, 0.0089, 0.0112,\n",
      "        0.0049], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.1166, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0633, device='cuda:0')\n",
      "p.batch_l2: tensor([6.1341e-05, 3.5393e-06, 6.0467e-05, 3.8272e-06, 5.9453e-05, 2.5629e-05,\n",
      "        1.3920e-05, 3.4083e-05, 3.8343e-05, 5.7924e-05, 1.1247e-05, 1.9154e-05,\n",
      "        2.1598e-05, 5.6277e-06, 7.9817e-06, 5.0548e-05, 4.9731e-06, 4.2830e-05,\n",
      "        3.9243e-05, 9.2215e-06, 2.8202e-05, 3.6634e-05, 2.5219e-05, 4.6212e-05,\n",
      "        4.6052e-05, 1.3106e-05, 4.2708e-05, 2.6093e-05, 3.3830e-05, 5.2508e-05,\n",
      "        1.2406e-05, 6.5863e-06, 3.6221e-05, 6.3751e-05, 5.0233e-05, 2.9762e-05,\n",
      "        6.1336e-05, 2.0510e-05, 3.3795e-05, 4.4848e-05, 6.6480e-05, 2.2767e-05,\n",
      "        2.4094e-05, 1.1724e-05, 3.1036e-05, 8.7928e-05, 9.9401e-05, 1.3513e-05,\n",
      "        1.5385e-05, 2.2886e-05, 2.9178e-05, 2.0928e-05, 2.0862e-05, 1.2802e-04,\n",
      "        1.3283e-05, 2.7847e-05, 1.7334e-05, 5.0231e-05, 9.9891e-05, 1.6064e-05,\n",
      "        4.4772e-05, 1.4794e-05, 3.3410e-05, 4.9906e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0078, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0019, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0053, 0.0010, 0.0085, 0.0042, 0.0060, 0.0040, 0.0044, 0.0064, 0.0038,\n",
      "        0.0169, 0.0078, 0.0130, 0.0098, 0.0075, 0.0102, 0.0272, 0.0032, 0.0199,\n",
      "        0.0099, 0.0108, 0.0119, 0.0154, 0.0025, 0.0149, 0.0090, 0.0076, 0.0098,\n",
      "        0.0037, 0.0073, 0.0107, 0.0055, 0.0049, 0.0083, 0.0065, 0.0152, 0.0079,\n",
      "        0.0078, 0.0035, 0.0028, 0.0123, 0.0153, 0.0046, 0.0045, 0.0035, 0.0042,\n",
      "        0.0321, 0.0307, 0.0042, 0.0102, 0.0091, 0.0130, 0.0119, 0.0122, 0.0250,\n",
      "        0.0058, 0.0031, 0.0051, 0.0060, 0.0225, 0.0066, 0.0075, 0.0043, 0.0048,\n",
      "        0.0020], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0729, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0316, device='cuda:0')\n",
      "p.batch_l2: tensor([2.2048e-04, 1.4169e-05, 2.0914e-04, 3.2508e-05, 2.4143e-04, 7.1684e-05,\n",
      "        8.1247e-05, 2.2581e-04, 2.5401e-04, 2.8267e-04, 9.4603e-05, 1.6294e-04,\n",
      "        1.4117e-04, 5.2685e-05, 1.1225e-04, 2.2185e-04, 1.0995e-05, 2.0767e-04,\n",
      "        2.2340e-04, 2.3083e-04, 1.9780e-04, 1.8487e-04, 8.7607e-05, 2.2988e-04,\n",
      "        2.3601e-04, 2.5514e-04, 1.4543e-04, 1.2740e-04, 2.5861e-04, 1.8128e-04,\n",
      "        4.3261e-05, 5.7867e-05, 2.5374e-04, 2.1118e-04, 2.4426e-04, 1.6721e-04,\n",
      "        2.4309e-04, 2.2716e-04, 2.2090e-04, 2.3107e-04, 2.7865e-04, 2.4175e-04,\n",
      "        2.0676e-04, 8.1730e-05, 1.2272e-04, 1.7201e-04, 2.3923e-04, 1.1436e-04,\n",
      "        9.0499e-05, 7.9964e-05, 2.1370e-04, 2.4607e-04, 2.7568e-04, 2.8113e-04,\n",
      "        1.0268e-04, 2.2165e-04, 2.5137e-04, 1.4247e-04, 3.9929e-04, 2.4936e-04,\n",
      "        1.2488e-04, 2.1677e-04, 2.0535e-04, 1.1952e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0148, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0038, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.7056, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([3.4212e-02, 2.6863e-02, 2.8240e-03, 2.0077e-03, 2.0376e-02, 2.3953e-02,\n",
      "        1.9086e-02, 1.2338e-02, 7.8925e-03, 1.5006e-02, 5.9357e-02, 1.7908e-02,\n",
      "        1.5756e-02, 6.4335e-02, 9.1781e-03, 9.4127e-03, 4.7771e-02, 1.1102e-02,\n",
      "        1.4801e-02, 6.2837e-04, 5.2111e-03, 2.2475e-02, 1.9994e-02, 6.6001e-03,\n",
      "        2.3605e-02, 1.0993e-02, 8.0344e-03, 2.0435e-02, 1.0917e-02, 8.4301e-03,\n",
      "        5.5372e-03, 2.9818e-02, 3.7422e-02, 2.8795e-03, 1.5747e-02, 5.9428e-04,\n",
      "        8.4286e-03, 1.0761e-02, 1.5485e-02, 1.4627e-02, 2.7956e-02, 2.4693e-02,\n",
      "        1.1991e-02, 2.6457e-02, 4.4447e-05, 1.2678e-02, 2.6549e-02, 4.2220e-02,\n",
      "        2.3537e-02, 3.5218e-03, 1.5170e-01, 2.6029e-02, 2.1641e-02, 1.9905e-02,\n",
      "        4.6526e-03, 3.7842e-02, 2.5491e-02, 1.5810e-02, 7.2888e-03, 1.9458e-02,\n",
      "        1.5982e-03, 8.9404e-02, 3.4509e-02, 5.1028e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1850, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1639, device='cuda:0')\n",
      "p.batch_l2: tensor([6.2868e-04, 5.3712e-04, 3.5252e-05, 2.2335e-05, 4.0771e-04, 4.2771e-04,\n",
      "        1.0193e-04, 3.0905e-04, 6.1506e-05, 1.6445e-04, 6.8827e-04, 4.4058e-04,\n",
      "        4.2813e-04, 1.4521e-03, 2.2721e-04, 1.9438e-04, 4.7213e-04, 1.3120e-04,\n",
      "        4.4183e-04, 2.0733e-06, 4.4662e-05, 4.4975e-04, 5.6805e-04, 4.2295e-05,\n",
      "        1.8332e-04, 2.8991e-04, 7.4737e-05, 1.6637e-04, 1.4300e-04, 1.0970e-04,\n",
      "        5.6628e-05, 2.7082e-04, 4.7278e-04, 5.6089e-05, 2.3364e-04, 3.4869e-06,\n",
      "        2.6077e-04, 2.0600e-04, 2.1077e-04, 7.1623e-05, 1.8661e-04, 1.2780e-04,\n",
      "        4.0403e-04, 1.4437e-04, 4.6285e-07, 4.3466e-04, 2.8419e-04, 4.3402e-04,\n",
      "        3.7115e-04, 7.0940e-05, 1.1328e-03, 5.9809e-04, 9.8895e-05, 6.3957e-04,\n",
      "        8.1189e-05, 6.3346e-04, 2.3086e-04, 1.2341e-04, 7.2965e-05, 3.0453e-04,\n",
      "        1.7089e-05, 7.5732e-04, 6.6740e-04, 1.0688e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0251, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0232, device='cuda:0')\n",
      "p.batch_l2: tensor([6.7120e-02, 3.4572e-02, 4.3666e-03, 1.6407e-03, 2.2757e-02, 7.3693e-02,\n",
      "        2.0932e-02, 2.3098e-02, 7.0637e-03, 2.5278e-02, 6.4506e-02, 1.8712e-02,\n",
      "        2.1738e-02, 1.0754e-01, 1.5309e-02, 1.0334e-02, 7.1178e-02, 1.8711e-02,\n",
      "        1.8447e-02, 6.1852e-04, 5.6565e-03, 2.1363e-02, 3.7193e-02, 6.5236e-03,\n",
      "        4.5701e-02, 1.6183e-02, 8.2046e-03, 2.0229e-02, 1.9663e-02, 6.5405e-03,\n",
      "        5.3836e-03, 3.7451e-02, 3.6083e-02, 4.5649e-03, 2.1801e-02, 8.3621e-04,\n",
      "        1.5398e-02, 1.5303e-02, 1.6389e-02, 2.8515e-02, 3.5954e-02, 3.8291e-02,\n",
      "        1.8823e-02, 2.4339e-02, 4.4475e-05, 2.4460e-02, 3.2779e-02, 4.7347e-02,\n",
      "        3.2989e-02, 5.1570e-03, 1.4407e-01, 2.4269e-02, 3.2461e-02, 3.6258e-02,\n",
      "        6.0383e-03, 5.1029e-02, 3.4695e-02, 2.0595e-02, 1.0451e-02, 2.6063e-02,\n",
      "        2.0638e-03, 1.0237e-01, 3.7954e-02, 9.8123e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.2591, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1859, device='cuda:0')\n",
      "p.batch_l2: tensor([1.4379e-04, 1.3430e-04, 1.3771e-05, 2.7388e-06, 1.1337e-04, 1.7249e-04,\n",
      "        3.9870e-05, 1.1282e-04, 1.4599e-05, 7.2600e-05, 1.4829e-04, 7.3368e-05,\n",
      "        5.0903e-05, 2.8275e-04, 5.9693e-05, 3.3327e-05, 1.3151e-04, 3.5718e-05,\n",
      "        6.4294e-05, 7.7482e-07, 1.2487e-05, 1.0340e-04, 1.2755e-04, 7.8856e-06,\n",
      "        9.5163e-05, 5.2902e-05, 8.4764e-06, 3.1677e-05, 3.3620e-05, 1.8854e-05,\n",
      "        8.1315e-06, 5.9069e-05, 1.4727e-04, 1.4714e-05, 5.9674e-05, 1.9474e-06,\n",
      "        6.3163e-05, 2.6270e-05, 3.6026e-05, 5.0350e-05, 7.1043e-05, 5.3042e-05,\n",
      "        4.6021e-05, 4.7703e-05, 7.5249e-08, 7.3668e-05, 5.0152e-05, 7.3288e-05,\n",
      "        7.2136e-05, 1.1010e-05, 2.6521e-04, 9.0373e-05, 4.8661e-05, 1.0039e-04,\n",
      "        1.6184e-05, 1.6085e-04, 1.1031e-04, 4.1545e-05, 2.5347e-05, 1.1913e-04,\n",
      "        4.8056e-06, 2.0009e-04, 1.5938e-04, 2.9041e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0120, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0116, device='cuda:0')\n",
      "p.batch_l2: tensor([6.2317e-02, 2.9896e-02, 2.1446e-03, 2.1151e-03, 1.5824e-02, 4.9030e-02,\n",
      "        1.6224e-02, 1.6895e-02, 9.9449e-03, 1.2316e-02, 4.1404e-02, 3.0443e-02,\n",
      "        2.7811e-02, 4.5953e-02, 1.5976e-02, 8.1339e-03, 4.2591e-02, 2.5532e-02,\n",
      "        2.0626e-02, 5.7275e-04, 6.9080e-03, 1.6297e-02, 3.2136e-02, 1.2954e-02,\n",
      "        7.8961e-02, 1.6662e-02, 1.5824e-02, 2.3935e-02, 1.0814e-02, 4.8770e-03,\n",
      "        9.3288e-03, 2.0637e-02, 1.9297e-02, 8.2494e-03, 1.2324e-02, 9.8087e-04,\n",
      "        2.0979e-02, 1.0150e-02, 2.0579e-02, 1.7956e-02, 1.2653e-02, 4.7203e-02,\n",
      "        4.6181e-02, 2.0499e-02, 4.4701e-05, 8.7704e-03, 7.9208e-02, 4.2445e-02,\n",
      "        1.5305e-02, 7.7276e-03, 1.2941e-01, 1.4959e-02, 3.6665e-02, 2.8924e-02,\n",
      "        1.0750e-02, 8.5031e-02, 1.7291e-02, 3.5268e-02, 7.6472e-03, 1.5430e-02,\n",
      "        1.7092e-03, 9.0948e-02, 2.2400e-02, 7.0928e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.2496, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1729, device='cuda:0')\n",
      "p.batch_l2: tensor([4.8200e-05, 7.1162e-05, 3.4641e-06, 1.8600e-06, 3.8342e-05, 5.4006e-05,\n",
      "        2.3279e-05, 4.8697e-05, 1.0990e-05, 2.7097e-05, 7.5346e-05, 4.1046e-05,\n",
      "        2.7829e-05, 8.3044e-05, 1.8640e-05, 1.2428e-05, 6.1047e-05, 2.4920e-05,\n",
      "        2.6165e-05, 7.7102e-07, 7.0901e-06, 3.2950e-05, 6.8781e-05, 1.4665e-05,\n",
      "        4.5019e-05, 2.0659e-05, 2.0314e-05, 4.4083e-05, 1.0557e-05, 1.7764e-05,\n",
      "        6.6950e-06, 4.1309e-05, 5.5281e-05, 6.3919e-06, 2.9614e-05, 1.1999e-06,\n",
      "        2.0221e-05, 1.6140e-05, 2.4214e-05, 2.2647e-05, 2.1815e-05, 5.8841e-05,\n",
      "        3.4412e-05, 2.7016e-05, 4.8538e-08, 2.5811e-05, 8.6497e-05, 4.5095e-05,\n",
      "        2.7680e-05, 6.0323e-06, 1.2223e-04, 4.2853e-05, 5.1858e-05, 3.6041e-05,\n",
      "        1.3359e-05, 1.0441e-04, 4.1024e-05, 3.0840e-05, 1.3716e-05, 4.7208e-05,\n",
      "        2.9535e-06, 9.0819e-05, 6.0250e-05, 1.2022e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0069, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0084, device='cuda:0')\n",
      "p.batch_l2: tensor([1.6548e-02, 1.3361e-02, 4.6681e-04, 1.0268e-03, 7.1183e-03, 4.0038e-03,\n",
      "        6.1412e-03, 7.4912e-03, 2.7070e-03, 3.7456e-03, 3.7674e-02, 7.9122e-03,\n",
      "        1.0175e-02, 3.2278e-02, 8.7992e-03, 5.1801e-03, 3.9690e-03, 1.0353e-02,\n",
      "        8.7662e-03, 3.4814e-04, 3.6021e-03, 4.3260e-03, 1.2289e-03, 6.9551e-03,\n",
      "        1.2759e-02, 1.3843e-03, 1.3278e-02, 2.7526e-02, 6.7484e-03, 5.8401e-03,\n",
      "        2.8451e-03, 1.7178e-02, 8.4306e-03, 3.0404e-03, 3.6253e-03, 4.0503e-04,\n",
      "        7.7199e-03, 6.0355e-03, 3.2056e-03, 9.9691e-03, 6.9615e-03, 2.9852e-02,\n",
      "        1.7776e-02, 1.5956e-02, 2.4257e-05, 5.0336e-03, 1.3185e-02, 2.8875e-02,\n",
      "        1.4307e-02, 2.4368e-03, 3.2518e-02, 5.2660e-03, 1.5026e-02, 1.0300e-02,\n",
      "        6.1099e-03, 4.3698e-02, 1.3437e-02, 1.5937e-02, 5.3149e-03, 7.1100e-03,\n",
      "        7.5961e-03, 8.9649e-03, 7.9067e-03, 2.6761e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.1286, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1156, device='cuda:0')\n",
      "p.batch_l2: tensor([2.0290e-04, 2.3128e-04, 7.6226e-06, 1.1479e-05, 1.7313e-04, 1.6332e-04,\n",
      "        9.1249e-05, 2.0351e-04, 7.9319e-05, 1.4010e-04, 2.9026e-04, 1.8726e-04,\n",
      "        1.6574e-04, 1.9906e-04, 1.9721e-04, 5.8254e-05, 1.3576e-04, 2.1194e-04,\n",
      "        2.4620e-04, 1.8442e-06, 2.1642e-05, 2.3185e-04, 2.0386e-04, 5.9706e-05,\n",
      "        2.7239e-04, 2.2144e-04, 8.4721e-05, 1.7042e-04, 5.8332e-05, 2.4811e-04,\n",
      "        4.0916e-05, 2.3496e-04, 1.8378e-04, 1.8523e-04, 1.7853e-04, 3.2918e-06,\n",
      "        2.0830e-04, 2.2942e-04, 2.0570e-04, 2.2445e-04, 9.5926e-05, 2.3415e-04,\n",
      "        2.4363e-04, 6.9863e-05, 1.2251e-07, 2.4582e-04, 2.3833e-04, 2.4800e-04,\n",
      "        2.3607e-04, 3.9044e-05, 3.5201e-04, 2.5610e-04, 2.4387e-04, 2.1729e-04,\n",
      "        2.2082e-04, 3.1365e-04, 2.8734e-04, 2.6717e-04, 1.6223e-04, 1.8193e-04,\n",
      "        1.4093e-04, 2.8879e-04, 2.2860e-04, 2.0817e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0142, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0152, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.2839, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([4.9275e-05, 2.6340e-02, 1.6041e-02, 1.8468e-02, 1.1592e-02, 1.6448e-02,\n",
      "        5.2793e-02, 1.1372e-03, 2.5976e-03, 1.9876e-02, 7.7898e-02, 2.4010e-02,\n",
      "        9.8120e-02, 5.0626e-03, 2.1682e-02, 2.4637e-02, 2.8494e-02, 4.5836e-02,\n",
      "        1.5127e-03, 2.8293e-03, 2.3655e-03, 8.7499e-03, 1.3671e-02, 1.2150e-02,\n",
      "        2.8780e-03, 1.3376e-02, 8.8957e-03, 1.0127e-02, 1.6040e-02, 3.1968e-02,\n",
      "        2.5033e-02, 2.3870e-02, 1.1075e-02, 6.7705e-02, 1.5621e-02, 1.5611e-02,\n",
      "        7.4997e-03, 1.2200e-04, 1.3265e-02, 3.4811e-02, 1.9026e-02, 1.3029e-02,\n",
      "        1.2880e-02, 7.5955e-03, 7.4588e-04, 2.7802e-02, 4.3304e-03, 1.7870e-03,\n",
      "        6.7472e-03, 1.7031e-03, 5.2023e-03, 1.5211e-02, 1.2593e-02, 2.0764e-02,\n",
      "        1.7636e-02, 1.7105e-02, 1.8172e-03, 3.8297e-03, 9.7065e-02, 1.0150e-02,\n",
      "        2.1686e-02, 4.6538e-03, 6.6264e-03, 5.8364e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0070, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1623, device='cuda:0')\n",
      "p.batch_l2: tensor([4.9198e-07, 1.9220e-04, 2.1063e-04, 1.5442e-04, 1.0459e-04, 3.0742e-04,\n",
      "        6.0941e-04, 1.2317e-05, 2.3783e-05, 1.2051e-04, 8.1902e-04, 4.1747e-04,\n",
      "        2.9736e-03, 7.1970e-05, 2.4754e-04, 1.4557e-04, 4.3457e-04, 6.4690e-04,\n",
      "        1.5390e-05, 3.5000e-05, 6.6297e-05, 9.5320e-05, 4.0201e-04, 1.0301e-04,\n",
      "        2.9397e-05, 2.3724e-04, 2.6694e-04, 1.5663e-04, 9.0583e-05, 4.3358e-04,\n",
      "        8.5149e-04, 2.8062e-04, 1.3039e-04, 4.6375e-04, 1.5995e-04, 1.9382e-04,\n",
      "        6.1690e-05, 9.7720e-07, 9.5485e-05, 1.6044e-03, 3.1761e-04, 1.8258e-04,\n",
      "        2.0588e-04, 8.5537e-05, 5.3245e-06, 7.7329e-04, 4.6634e-05, 2.3124e-05,\n",
      "        6.9725e-05, 4.2925e-05, 5.4243e-05, 1.3616e-04, 1.4001e-04, 3.9794e-04,\n",
      "        6.7161e-05, 1.9616e-04, 2.4462e-05, 1.5837e-04, 6.7741e-04, 6.8691e-05,\n",
      "        2.2428e-04, 1.1519e-04, 5.9264e-05, 1.6704e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0007, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0139, device='cuda:0')\n",
      "p.batch_l2: tensor([1.0245e-04, 3.4505e-02, 1.7380e-02, 3.1237e-02, 1.8469e-02, 2.4265e-02,\n",
      "        6.5471e-02, 1.4032e-03, 6.4712e-03, 3.9171e-02, 1.0476e-01, 1.8826e-02,\n",
      "        1.4024e-01, 8.5507e-03, 4.5736e-02, 5.0733e-02, 4.3900e-02, 1.0586e-01,\n",
      "        2.5295e-03, 4.0770e-03, 2.7506e-03, 1.2783e-02, 1.5813e-02, 2.2147e-02,\n",
      "        4.7319e-03, 1.8545e-02, 1.5657e-02, 2.6018e-02, 1.5357e-02, 3.3007e-02,\n",
      "        5.1026e-02, 4.1381e-02, 1.0962e-02, 7.5905e-02, 2.6375e-02, 2.5989e-02,\n",
      "        1.4001e-02, 1.3344e-04, 2.1983e-02, 6.4350e-02, 2.7150e-02, 1.2866e-02,\n",
      "        1.9870e-02, 1.4221e-02, 1.3203e-03, 5.8357e-02, 7.3770e-03, 3.1335e-03,\n",
      "        7.9235e-03, 2.1719e-03, 8.0682e-03, 3.7359e-02, 1.7168e-02, 2.5028e-02,\n",
      "        2.2974e-02, 2.5837e-02, 2.6973e-03, 5.3082e-03, 9.2034e-02, 1.2067e-02,\n",
      "        2.3174e-02, 5.5360e-03, 1.1739e-02, 1.2972e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.0101, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1858, device='cuda:0')\n",
      "p.batch_l2: tensor([2.2408e-07, 4.5350e-05, 3.6578e-05, 6.8133e-05, 2.6766e-05, 6.3608e-05,\n",
      "        1.4237e-04, 2.4691e-06, 1.1874e-05, 3.8383e-05, 1.2954e-04, 7.2869e-05,\n",
      "        4.6791e-04, 1.7194e-05, 8.2708e-05, 1.0571e-04, 1.0571e-04, 2.0889e-04,\n",
      "        3.4817e-06, 7.5165e-06, 1.2277e-05, 2.2887e-05, 7.0089e-05, 1.9558e-05,\n",
      "        6.3575e-06, 6.8885e-05, 4.2325e-05, 5.5861e-05, 3.0867e-05, 6.5911e-05,\n",
      "        1.9932e-04, 9.0242e-05, 2.1097e-05, 1.0317e-04, 4.8390e-05, 7.7901e-05,\n",
      "        2.2716e-05, 2.7737e-07, 3.1464e-05, 2.3067e-04, 6.8461e-05, 3.3290e-05,\n",
      "        4.4578e-05, 1.7852e-05, 2.2713e-06, 1.2494e-04, 1.2578e-05, 4.7286e-06,\n",
      "        1.7496e-05, 1.1426e-05, 2.6345e-05, 6.1329e-05, 2.6970e-05, 7.1943e-05,\n",
      "        4.8412e-05, 3.4820e-05, 3.7365e-06, 2.2724e-05, 1.5396e-04, 1.4257e-05,\n",
      "        4.3952e-05, 2.7275e-05, 1.9909e-05, 2.6131e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0005, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0067, device='cuda:0')\n",
      "p.batch_l2: tensor([8.9011e-05, 4.3241e-02, 1.7670e-02, 7.2016e-03, 8.3316e-03, 2.9943e-02,\n",
      "        4.8904e-02, 1.4828e-03, 3.2471e-03, 2.0327e-02, 8.4229e-02, 2.4379e-02,\n",
      "        1.4945e-01, 8.3045e-03, 2.5257e-02, 2.7823e-02, 1.7254e-02, 3.7286e-02,\n",
      "        1.2311e-03, 2.0825e-03, 2.1591e-03, 1.2556e-02, 1.9588e-02, 2.5413e-02,\n",
      "        5.1634e-03, 1.1057e-02, 6.3408e-03, 5.4170e-03, 1.9074e-02, 3.0805e-02,\n",
      "        8.9552e-02, 1.0924e-02, 1.3496e-02, 6.4797e-02, 2.7379e-02, 1.7842e-02,\n",
      "        1.3277e-02, 1.3724e-04, 7.1457e-03, 2.7984e-02, 2.6754e-02, 1.1585e-02,\n",
      "        1.4009e-02, 7.4760e-03, 1.1278e-03, 4.3869e-02, 5.0843e-03, 4.0146e-03,\n",
      "        9.5582e-03, 1.5656e-03, 3.4917e-03, 2.5560e-02, 1.1774e-02, 1.7318e-02,\n",
      "        1.5893e-02, 1.3466e-02, 2.1597e-03, 3.4031e-03, 5.3782e-02, 5.8650e-03,\n",
      "        2.7279e-02, 2.1059e-03, 9.1908e-03, 6.7875e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0094, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2079, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.batch_l2: tensor([7.4271e-08, 2.1703e-05, 2.5411e-05, 1.7449e-05, 1.3866e-05, 3.8209e-05,\n",
      "        6.3378e-05, 1.0444e-06, 3.6055e-06, 3.6051e-05, 6.0658e-05, 5.0730e-05,\n",
      "        1.7855e-04, 1.2919e-05, 2.7585e-05, 3.5844e-05, 2.2276e-05, 5.5580e-05,\n",
      "        1.1175e-06, 1.7445e-06, 5.8914e-06, 1.7613e-05, 4.7483e-05, 1.7402e-05,\n",
      "        3.3081e-06, 2.4252e-05, 7.9613e-06, 1.1577e-05, 1.8864e-05, 3.1367e-05,\n",
      "        8.8884e-05, 2.0903e-05, 1.4518e-05, 7.6410e-05, 2.9227e-05, 2.9511e-05,\n",
      "        9.9034e-06, 9.7102e-08, 1.1043e-05, 4.3934e-05, 3.8785e-05, 2.3045e-05,\n",
      "        1.2367e-05, 7.6578e-06, 7.2175e-07, 4.9417e-05, 6.0403e-06, 2.9464e-06,\n",
      "        1.0852e-05, 4.3517e-06, 8.7126e-06, 2.2625e-05, 1.7336e-05, 3.3696e-05,\n",
      "        1.6051e-05, 3.2309e-05, 2.0449e-06, 6.6601e-06, 9.3042e-05, 7.2306e-06,\n",
      "        3.1331e-05, 7.1300e-06, 1.5489e-05, 7.1621e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0003, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0047, device='cuda:0')\n",
      "p.batch_l2: tensor([1.5475e-04, 1.5818e-02, 3.2865e-02, 1.3501e-02, 1.0629e-02, 6.4056e-03,\n",
      "        2.8709e-02, 2.8686e-03, 6.7153e-03, 6.5501e-03, 3.6201e-02, 9.6133e-03,\n",
      "        7.6838e-02, 1.0070e-02, 4.2032e-02, 6.5243e-03, 2.3377e-02, 2.7504e-02,\n",
      "        1.7146e-03, 5.4922e-03, 1.9907e-03, 1.4915e-02, 9.0590e-03, 6.9165e-03,\n",
      "        5.3741e-03, 3.3807e-03, 6.6906e-03, 1.0253e-02, 6.7113e-03, 2.1854e-02,\n",
      "        4.0590e-02, 1.1708e-02, 5.3347e-03, 3.8545e-02, 1.2399e-02, 1.6852e-02,\n",
      "        9.3300e-03, 7.2697e-05, 6.8225e-03, 9.5510e-03, 1.8784e-02, 4.9472e-03,\n",
      "        2.2996e-02, 4.0043e-03, 1.3020e-03, 1.3854e-02, 8.9819e-03, 6.4330e-03,\n",
      "        1.0498e-02, 1.8409e-03, 6.9909e-03, 1.5628e-02, 1.7466e-02, 2.1271e-02,\n",
      "        2.8242e-02, 1.4136e-02, 3.1595e-03, 2.6808e-03, 2.3947e-02, 1.0827e-02,\n",
      "        5.6093e-03, 2.1885e-03, 1.9193e-02, 1.0927e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0124, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1258, device='cuda:0')\n",
      "p.batch_l2: tensor([3.6904e-07, 2.2153e-04, 2.6377e-04, 1.5525e-04, 1.4762e-04, 9.9337e-05,\n",
      "        2.2838e-04, 9.7453e-06, 2.2916e-05, 2.1307e-04, 3.2621e-04, 1.5806e-04,\n",
      "        4.0418e-04, 2.2980e-04, 1.5308e-04, 1.2233e-04, 1.2561e-04, 1.3958e-04,\n",
      "        6.8418e-06, 3.1039e-05, 3.2885e-05, 1.0648e-04, 1.4623e-04, 2.1201e-04,\n",
      "        2.9852e-05, 1.8423e-04, 1.3525e-04, 2.5194e-04, 4.8463e-05, 2.1961e-04,\n",
      "        2.1896e-04, 8.2138e-05, 6.5407e-05, 3.2017e-04, 1.2065e-04, 1.3553e-04,\n",
      "        5.1737e-05, 2.1531e-07, 5.2021e-05, 1.3404e-04, 2.1550e-04, 2.2711e-04,\n",
      "        2.0934e-04, 2.2173e-04, 2.4114e-06, 1.9788e-04, 3.6411e-05, 2.0376e-05,\n",
      "        6.7313e-05, 2.2983e-05, 9.6435e-05, 7.0336e-05, 2.5928e-04, 3.1197e-04,\n",
      "        2.6022e-04, 2.1294e-04, 1.3089e-05, 3.3679e-05, 2.7516e-04, 4.4647e-05,\n",
      "        2.2158e-04, 3.6295e-05, 2.0979e-04, 1.9280e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0006, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0149, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.5000, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([1.1095e-02, 3.9929e-03, 6.9610e-03, 3.7649e-02, 2.7574e-04, 9.4679e-03,\n",
      "        1.0679e-02, 4.1010e-03, 8.9555e-02, 2.7927e-02, 4.0170e-03, 5.7315e-02,\n",
      "        1.2458e-01, 5.3455e-02, 8.1939e-03, 1.2023e-02, 1.1075e-03, 8.8417e-03,\n",
      "        2.4314e-03, 1.8117e-02, 4.4963e-04, 3.9416e-02, 1.2652e-03, 4.1624e-03,\n",
      "        4.9747e-02, 5.8433e-02, 1.7149e-01, 3.9895e-05, 1.0722e-01, 2.0630e-03,\n",
      "        8.0569e-03, 8.2352e-03, 1.1587e-02, 7.5595e-03, 2.0506e-02, 1.3334e-02,\n",
      "        4.8186e-02, 2.1521e-02, 1.3292e-02, 2.0979e-02, 7.4374e-02, 3.0840e-04,\n",
      "        6.0261e-02, 1.1536e-02, 8.7244e-03, 8.7099e-06, 1.0446e-01, 1.2765e-02,\n",
      "        1.0860e-02, 1.3506e-02, 4.5219e-03, 2.9239e-02, 1.1369e-02, 4.6023e-02,\n",
      "        4.7521e-04, 2.9385e-02, 1.1852e-02, 5.9224e-02, 1.0505e-02, 2.1364e-02,\n",
      "        3.1406e-02, 1.7268e-02, 1.0792e-01, 2.7489e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1053, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0632, device='cuda:0')\n",
      "p.batch_l2: tensor([3.3486e-04, 5.2584e-05, 6.0355e-05, 1.5239e-03, 4.2102e-06, 1.3038e-04,\n",
      "        1.3809e-04, 1.3896e-04, 1.1936e-03, 3.1375e-04, 9.1654e-05, 8.1212e-04,\n",
      "        1.9437e-03, 1.3759e-03, 1.5450e-04, 1.7226e-04, 1.7723e-05, 7.6957e-05,\n",
      "        2.8698e-05, 1.4331e-04, 3.9280e-06, 1.6900e-03, 9.6697e-05, 7.1312e-05,\n",
      "        3.3169e-04, 1.5246e-03, 1.6322e-03, 4.2833e-07, 1.3792e-03, 1.2632e-05,\n",
      "        7.6525e-05, 1.5284e-04, 2.1573e-04, 1.2806e-04, 2.6396e-04, 5.7849e-04,\n",
      "        6.0887e-04, 2.6499e-04, 2.1381e-04, 4.8422e-04, 1.2303e-03, 3.9756e-06,\n",
      "        1.7035e-03, 1.1751e-04, 1.6256e-04, 5.7579e-08, 1.1817e-03, 2.5074e-04,\n",
      "        6.0188e-04, 9.5461e-05, 8.4240e-05, 6.0767e-04, 9.5383e-05, 5.4249e-04,\n",
      "        3.3561e-06, 5.1319e-04, 1.9206e-04, 1.4978e-03, 2.4278e-04, 4.7651e-04,\n",
      "        5.1302e-04, 1.9121e-04, 1.5236e-03, 6.5115e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0183, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0073, device='cuda:0')\n",
      "p.batch_l2: tensor([1.8184e-02, 8.1137e-03, 1.1729e-02, 5.0682e-02, 8.1293e-04, 1.0757e-02,\n",
      "        1.8369e-02, 5.3041e-03, 1.4655e-01, 6.2381e-02, 5.0695e-03, 7.3669e-02,\n",
      "        1.3600e-01, 1.1737e-01, 1.4043e-02, 9.6382e-03, 1.4874e-03, 1.7000e-02,\n",
      "        3.5843e-03, 2.7392e-02, 5.1135e-04, 6.1609e-02, 2.7062e-03, 4.6533e-03,\n",
      "        7.8713e-02, 1.1330e-01, 2.2283e-01, 5.8118e-05, 1.1556e-01, 3.5514e-03,\n",
      "        1.3362e-02, 1.5324e-02, 1.6646e-02, 8.2560e-03, 2.2083e-02, 1.9636e-02,\n",
      "        6.1022e-02, 3.3625e-02, 1.3010e-02, 4.6274e-02, 1.2750e-01, 1.1147e-03,\n",
      "        9.1661e-02, 2.1257e-02, 1.7018e-02, 1.8777e-05, 2.1464e-01, 2.2788e-02,\n",
      "        1.9024e-02, 2.8127e-02, 1.1016e-02, 4.5839e-02, 2.1839e-02, 6.9049e-02,\n",
      "        8.4440e-04, 4.3835e-02, 2.5228e-02, 7.9145e-02, 2.8328e-02, 3.0445e-02,\n",
      "        4.1518e-02, 3.0840e-02, 1.3641e-01, 4.6381e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1348, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0901, device='cuda:0')\n",
      "p.batch_l2: tensor([8.7313e-05, 1.7771e-05, 1.8241e-05, 2.1888e-04, 1.4089e-06, 2.0492e-05,\n",
      "        3.7681e-05, 2.6729e-05, 2.5759e-04, 6.0357e-05, 9.3560e-06, 1.2866e-04,\n",
      "        2.2304e-04, 3.3027e-04, 2.6369e-05, 2.5286e-05, 2.6504e-06, 2.5172e-05,\n",
      "        8.3636e-06, 5.1335e-05, 9.5038e-07, 1.6586e-04, 1.3826e-05, 2.2202e-05,\n",
      "        1.2751e-04, 2.7139e-04, 2.7970e-04, 9.4106e-08, 1.8869e-04, 4.2049e-06,\n",
      "        2.8727e-05, 3.8655e-05, 3.4846e-05, 1.8278e-05, 5.7770e-05, 7.6013e-05,\n",
      "        1.0170e-04, 6.0547e-05, 2.8390e-05, 9.0892e-05, 2.6445e-04, 1.6945e-06,\n",
      "        2.2311e-04, 3.0800e-05, 2.9587e-05, 2.1038e-08, 2.7464e-04, 4.9342e-05,\n",
      "        7.6614e-05, 6.2652e-05, 2.3245e-05, 1.2727e-04, 3.6767e-05, 7.1237e-05,\n",
      "        1.2535e-06, 8.6647e-05, 4.8678e-05, 2.1700e-04, 5.1152e-05, 7.1393e-05,\n",
      "        1.0118e-04, 5.5207e-05, 2.7801e-04, 1.1224e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0093, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0042, device='cuda:0')\n",
      "p.batch_l2: tensor([7.6188e-03, 2.0640e-03, 7.0000e-03, 1.8791e-02, 1.2992e-03, 8.7461e-03,\n",
      "        1.7362e-02, 2.9916e-03, 8.6992e-02, 6.0479e-02, 5.2515e-03, 7.6628e-02,\n",
      "        1.2039e-01, 3.4918e-02, 1.6076e-02, 8.5792e-03, 2.6214e-03, 1.4250e-02,\n",
      "        1.4454e-03, 2.5281e-02, 3.0280e-04, 3.7704e-02, 1.0723e-03, 3.0670e-03,\n",
      "        4.4995e-02, 5.8022e-02, 1.9281e-01, 7.4526e-05, 1.0836e-01, 3.2801e-03,\n",
      "        1.7473e-02, 1.7563e-02, 1.2066e-02, 1.7054e-02, 1.5873e-02, 1.3944e-02,\n",
      "        5.8296e-02, 3.3245e-02, 1.5835e-02, 1.7463e-02, 6.8594e-02, 2.7363e-04,\n",
      "        6.8118e-02, 1.0050e-02, 2.8330e-02, 1.9469e-05, 6.4979e-02, 1.9802e-02,\n",
      "        9.6719e-03, 2.4090e-02, 1.2560e-02, 2.9224e-02, 1.4898e-02, 4.3300e-02,\n",
      "        5.4165e-04, 2.7792e-02, 1.9638e-02, 6.1098e-02, 3.1707e-02, 2.4942e-02,\n",
      "        2.5412e-02, 1.6913e-02, 7.5525e-02, 4.2386e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0873, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0454, device='cuda:0')\n",
      "p.batch_l2: tensor([2.0519e-05, 3.7779e-06, 9.4180e-06, 5.3818e-05, 6.0370e-07, 6.2482e-06,\n",
      "        1.9525e-05, 8.3217e-06, 1.1605e-04, 3.9061e-05, 5.9663e-06, 7.5048e-05,\n",
      "        9.1541e-05, 5.7097e-05, 2.1629e-05, 1.1129e-05, 1.8375e-06, 1.1010e-05,\n",
      "        2.2644e-06, 3.4396e-05, 3.1552e-07, 6.0610e-05, 2.3684e-06, 7.3169e-06,\n",
      "        6.3159e-05, 4.3612e-05, 9.6818e-05, 4.1357e-08, 8.0188e-05, 4.5915e-06,\n",
      "        1.6811e-05, 1.9602e-05, 1.5206e-05, 1.5961e-05, 3.7126e-05, 2.5321e-05,\n",
      "        3.3128e-05, 4.2656e-05, 1.4104e-05, 3.5444e-05, 6.9079e-05, 3.0784e-07,\n",
      "        5.4919e-05, 1.4528e-05, 1.8332e-05, 9.9914e-09, 4.5780e-05, 2.3823e-05,\n",
      "        1.8562e-05, 2.7404e-05, 8.0079e-06, 4.3339e-05, 1.4013e-05, 4.1587e-05,\n",
      "        4.3505e-07, 3.8022e-05, 1.8244e-05, 6.3916e-05, 1.6687e-05, 2.8864e-05,\n",
      "        2.8706e-05, 2.4066e-05, 7.3839e-05, 6.1101e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0045, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0019, device='cuda:0')\n",
      "p.batch_l2: tensor([2.8662e-03, 3.7177e-03, 6.4482e-03, 2.1700e-03, 7.9820e-04, 7.6335e-03,\n",
      "        3.5843e-03, 1.6142e-03, 5.0161e-02, 1.0140e-02, 6.3884e-03, 2.7858e-02,\n",
      "        4.8037e-02, 2.7108e-02, 3.5983e-03, 7.0734e-03, 1.7205e-03, 3.1976e-02,\n",
      "        1.0479e-03, 9.8638e-03, 2.5813e-04, 2.6821e-02, 9.2525e-04, 2.0095e-03,\n",
      "        2.6028e-02, 3.8699e-02, 1.3905e-01, 3.6015e-05, 5.2770e-02, 1.4962e-02,\n",
      "        1.1388e-02, 1.2002e-02, 3.4610e-03, 7.5741e-03, 6.8606e-03, 5.4043e-03,\n",
      "        1.7912e-02, 7.7431e-03, 1.0393e-02, 1.5051e-02, 1.6502e-02, 6.4827e-04,\n",
      "        1.9376e-02, 2.0006e-02, 5.1368e-03, 1.6971e-05, 1.6749e-02, 5.0271e-03,\n",
      "        3.0155e-03, 1.6676e-02, 1.8028e-03, 1.3570e-02, 3.6064e-03, 4.5831e-02,\n",
      "        3.3081e-04, 1.3119e-02, 1.4812e-02, 1.1591e-02, 2.6523e-03, 2.3092e-02,\n",
      "        7.9297e-03, 1.9614e-02, 2.3479e-02, 4.1991e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0535, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0610, device='cuda:0')\n",
      "p.batch_l2: tensor([8.6685e-05, 3.2013e-05, 1.2648e-04, 1.4731e-04, 1.5759e-06, 4.3985e-05,\n",
      "        1.7633e-04, 3.9685e-05, 3.5315e-04, 1.0557e-04, 4.6512e-05, 2.6912e-04,\n",
      "        2.5331e-04, 2.8846e-04, 1.7474e-04, 7.5402e-05, 1.4856e-05, 2.3828e-04,\n",
      "        9.6816e-06, 1.5730e-04, 1.3060e-06, 3.4934e-04, 1.1804e-05, 3.3078e-05,\n",
      "        2.6012e-04, 2.8260e-04, 4.0694e-04, 1.1986e-07, 3.3025e-04, 2.1756e-04,\n",
      "        1.6661e-04, 2.1613e-04, 2.1504e-04, 2.1806e-04, 1.9751e-04, 1.1837e-04,\n",
      "        2.0576e-04, 2.3712e-04, 2.1199e-04, 2.0092e-04, 2.3091e-04, 2.5046e-06,\n",
      "        1.9321e-04, 1.1644e-04, 1.8426e-04, 3.7275e-08, 2.3156e-04, 1.7945e-04,\n",
      "        7.8270e-05, 9.1606e-05, 2.7561e-05, 2.5199e-04, 3.0906e-05, 2.6621e-04,\n",
      "        1.5240e-06, 1.9423e-04, 2.4290e-04, 2.5227e-04, 9.6430e-05, 1.1518e-04,\n",
      "        2.0294e-04, 2.4738e-04, 2.6202e-04, 2.9601e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0093, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0057, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.6660, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([5.1554e-03, 3.9966e-02, 2.3876e-03, 9.2584e-03, 5.7856e-02, 4.3736e-03,\n",
      "        4.2473e-02, 9.5753e-03, 4.3915e-02, 1.7546e-02, 5.7321e-05, 1.5525e-02,\n",
      "        3.1565e-02, 3.6337e-03, 9.3681e-02, 2.5685e-04, 4.6835e-03, 3.1188e-02,\n",
      "        1.7645e-01, 5.0279e-02, 6.2436e-03, 5.4535e-05, 5.0615e-02, 2.6486e-03,\n",
      "        6.7707e-02, 4.9835e-03, 4.2987e-02, 7.8455e-03, 4.0890e-05, 5.3045e-02,\n",
      "        1.8413e-02, 7.1193e-04, 1.2769e-02, 2.5759e-04, 6.7643e-03, 9.4075e-02,\n",
      "        2.5260e-06, 9.8611e-03, 8.3677e-03, 5.0502e-02, 6.0903e-02, 8.0589e-03,\n",
      "        6.9660e-02, 7.7565e-02, 5.0806e-02, 1.5263e-02, 6.9629e-05, 1.8227e-03,\n",
      "        1.5444e-02, 2.0627e-02, 3.5684e-02, 4.6156e-02, 1.0191e-01, 7.0879e-02,\n",
      "        1.3805e-04, 3.3034e-03, 4.4653e-03, 1.6560e-03, 2.6904e-02, 2.2485e-02,\n",
      "        1.2515e-03, 1.2480e-04, 2.7923e-02, 1.4954e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0718, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1999, device='cuda:0')\n",
      "p.batch_l2: tensor([7.6810e-05, 4.0856e-04, 2.0639e-05, 1.9979e-04, 9.5183e-04, 2.1414e-05,\n",
      "        1.4618e-04, 2.0634e-04, 4.7808e-04, 1.5913e-04, 1.6987e-06, 2.4767e-04,\n",
      "        2.1103e-04, 2.6140e-05, 6.5709e-04, 9.3704e-06, 5.6298e-05, 3.8083e-04,\n",
      "        1.1939e-03, 1.4761e-03, 9.3782e-05, 2.0279e-06, 8.8944e-04, 2.3022e-05,\n",
      "        8.5476e-04, 4.6177e-05, 5.1271e-04, 6.8666e-05, 1.4899e-06, 3.8233e-04,\n",
      "        1.5228e-04, 3.2293e-05, 7.9727e-05, 6.8201e-06, 4.4525e-05, 3.0302e-03,\n",
      "        1.6571e-08, 2.3128e-04, 1.6839e-04, 6.7613e-04, 5.4744e-04, 5.1285e-05,\n",
      "        1.3486e-03, 1.0098e-03, 5.4622e-04, 3.7413e-04, 2.1804e-06, 1.3406e-05,\n",
      "        1.7556e-04, 2.4325e-04, 4.2986e-04, 8.7100e-04, 3.1719e-03, 1.1286e-03,\n",
      "        5.7484e-06, 4.0548e-05, 1.1427e-04, 4.5712e-05, 2.1542e-04, 4.1861e-04,\n",
      "        1.5909e-05, 5.9301e-06, 5.8394e-04, 1.5891e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0088, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0202, device='cuda:0')\n",
      "p.batch_l2: tensor([7.9377e-03, 5.4348e-02, 4.0591e-03, 1.5605e-02, 8.7084e-02, 7.7845e-03,\n",
      "        3.9944e-02, 1.8043e-02, 5.8550e-02, 2.5809e-02, 8.2501e-05, 2.3152e-02,\n",
      "        3.1022e-02, 6.4420e-03, 1.4358e-01, 3.8182e-04, 9.4185e-03, 4.1953e-02,\n",
      "        1.9533e-01, 1.0391e-01, 1.1120e-02, 9.8416e-05, 8.0395e-02, 3.3721e-03,\n",
      "        1.2661e-01, 9.9868e-03, 6.6578e-02, 1.1763e-02, 7.2865e-05, 8.0773e-02,\n",
      "        3.3363e-02, 1.1157e-03, 1.6957e-02, 3.2937e-04, 1.4395e-02, 1.6306e-01,\n",
      "        2.8417e-06, 2.4854e-02, 1.6496e-02, 9.0516e-02, 6.2635e-02, 1.4946e-02,\n",
      "        1.1094e-01, 8.5432e-02, 5.4830e-02, 2.5121e-02, 1.0969e-04, 2.4734e-03,\n",
      "        2.0972e-02, 3.2944e-02, 4.0001e-02, 1.0840e-01, 1.6613e-01, 7.6764e-02,\n",
      "        2.4190e-04, 3.9077e-03, 6.4219e-03, 2.3591e-03, 3.8036e-02, 3.3866e-02,\n",
      "        3.2882e-03, 2.3846e-04, 3.7462e-02, 2.1918e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.0891, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2331, device='cuda:0')\n",
      "p.batch_l2: tensor([1.5517e-05, 6.6026e-05, 6.1410e-06, 2.4425e-05, 1.2573e-04, 1.1977e-05,\n",
      "        5.1832e-05, 3.7344e-05, 1.0327e-04, 3.3992e-05, 3.9991e-07, 3.7147e-05,\n",
      "        3.9162e-05, 9.9279e-06, 1.4531e-04, 1.5362e-06, 1.6409e-05, 1.0422e-04,\n",
      "        2.4604e-04, 2.2295e-04, 2.5658e-05, 4.7405e-07, 1.4282e-04, 5.4390e-06,\n",
      "        1.5385e-04, 1.7368e-05, 1.3614e-04, 2.0432e-05, 3.8180e-07, 1.2251e-04,\n",
      "        6.0389e-05, 4.5810e-06, 2.8236e-05, 1.5652e-06, 2.4080e-05, 4.3749e-04,\n",
      "        2.9259e-09, 3.5177e-05, 2.5086e-05, 1.6911e-04, 8.5129e-05, 1.9459e-05,\n",
      "        3.2206e-04, 9.7606e-05, 9.0612e-05, 9.0666e-05, 5.3607e-07, 4.3574e-06,\n",
      "        4.2990e-05, 5.5133e-05, 6.3555e-05, 1.9625e-04, 4.8780e-04, 1.2208e-04,\n",
      "        1.1708e-06, 6.0996e-06, 2.0882e-05, 8.0213e-06, 4.6121e-05, 6.3375e-05,\n",
      "        4.8076e-06, 1.0462e-06, 7.8611e-05, 4.7613e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0039, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0081, device='cuda:0')\n",
      "p.batch_l2: tensor([7.7055e-03, 7.2698e-02, 4.2323e-03, 1.4898e-02, 6.5629e-02, 1.6212e-02,\n",
      "        3.9961e-02, 2.2999e-02, 3.7582e-02, 2.1642e-02, 7.2647e-05, 4.2177e-02,\n",
      "        2.3976e-02, 4.9502e-03, 1.0721e-01, 2.9955e-04, 1.1947e-02, 3.4306e-02,\n",
      "        1.9134e-01, 7.0883e-02, 1.1927e-02, 9.3426e-05, 4.7307e-02, 3.0144e-03,\n",
      "        1.3492e-01, 9.7010e-03, 3.2229e-02, 1.5617e-02, 6.3620e-05, 5.0478e-02,\n",
      "        1.9715e-02, 1.0485e-03, 2.6057e-02, 2.2936e-04, 6.8347e-03, 1.3856e-01,\n",
      "        4.3032e-06, 5.1880e-02, 1.9892e-02, 7.4379e-02, 3.6523e-02, 1.0982e-02,\n",
      "        9.0107e-02, 1.8471e-01, 8.0795e-02, 1.6503e-02, 8.5749e-05, 3.0789e-03,\n",
      "        4.0783e-02, 1.3763e-02, 2.9186e-02, 9.8326e-02, 1.1352e-01, 4.8399e-02,\n",
      "        1.4314e-04, 2.2773e-03, 3.9382e-03, 2.1858e-03, 5.6621e-02, 4.0855e-02,\n",
      "        3.1215e-03, 1.9156e-04, 2.9038e-02, 1.9440e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0878, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2696, device='cuda:0')\n",
      "p.batch_l2: tensor([9.4447e-06, 6.2460e-05, 5.2105e-06, 8.2267e-06, 7.0223e-05, 1.1598e-05,\n",
      "        4.3695e-05, 1.7269e-05, 3.4558e-05, 2.7188e-05, 9.8195e-08, 3.9407e-05,\n",
      "        3.3743e-05, 4.3173e-06, 8.8357e-05, 3.7154e-07, 8.6589e-06, 6.5427e-05,\n",
      "        1.1780e-04, 6.3878e-05, 1.4859e-05, 1.2910e-07, 5.1065e-05, 2.7977e-06,\n",
      "        5.9768e-05, 8.2244e-06, 6.2274e-05, 1.3340e-05, 1.0014e-07, 7.1549e-05,\n",
      "        2.2642e-05, 1.6759e-06, 1.5799e-05, 3.8690e-07, 6.7422e-06, 1.3632e-04,\n",
      "        1.9501e-09, 3.0808e-05, 1.0859e-05, 3.9784e-05, 3.9729e-05, 1.3214e-05,\n",
      "        8.9979e-05, 1.2718e-04, 1.0182e-04, 3.1638e-05, 1.3712e-07, 2.4423e-06,\n",
      "        2.3472e-05, 1.9312e-05, 2.9279e-05, 6.8357e-05, 1.3368e-04, 8.2188e-05,\n",
      "        2.3434e-07, 1.4829e-06, 5.6067e-06, 3.5883e-06, 4.8897e-05, 3.6072e-05,\n",
      "        2.6685e-06, 3.3025e-07, 2.3595e-05, 1.7847e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0031, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0079, device='cuda:0')\n",
      "p.batch_l2: tensor([5.6858e-03, 3.5311e-02, 4.1676e-03, 5.9291e-03, 3.1035e-02, 1.5566e-02,\n",
      "        2.3235e-02, 1.4670e-02, 1.4321e-02, 1.9549e-02, 1.0212e-04, 2.4597e-02,\n",
      "        1.6650e-02, 2.5656e-03, 4.8143e-02, 2.9488e-04, 6.7910e-03, 1.1110e-02,\n",
      "        4.8047e-02, 1.2823e-01, 1.3421e-02, 1.2015e-04, 1.3803e-02, 8.9522e-04,\n",
      "        7.4866e-02, 2.6171e-02, 3.7727e-02, 2.7613e-02, 7.5029e-05, 1.0578e-02,\n",
      "        1.7459e-02, 9.8029e-04, 1.9445e-02, 2.1289e-04, 6.7481e-03, 5.5604e-02,\n",
      "        1.8885e-05, 9.6391e-03, 6.2823e-03, 6.7384e-02, 2.3104e-02, 9.7104e-03,\n",
      "        5.2178e-02, 9.2508e-02, 1.9938e-02, 1.9703e-02, 1.0164e-04, 7.3553e-04,\n",
      "        1.8680e-02, 6.9863e-03, 2.7524e-02, 1.2368e-01, 6.5466e-02, 3.7237e-02,\n",
      "        1.6993e-04, 2.7018e-03, 2.1409e-03, 1.8137e-03, 1.0147e-02, 4.1644e-02,\n",
      "        6.3016e-03, 2.0160e-04, 2.4615e-02, 2.0539e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0754, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1879, device='cuda:0')\n",
      "p.batch_l2: tensor([4.5105e-05, 1.9334e-04, 3.5704e-05, 1.6159e-05, 2.5377e-04, 5.7286e-05,\n",
      "        1.8345e-04, 2.0160e-04, 1.9262e-04, 2.5673e-04, 5.2054e-07, 1.6617e-04,\n",
      "        2.2404e-04, 1.3365e-05, 3.2289e-04, 1.6985e-06, 1.1711e-04, 2.2848e-04,\n",
      "        3.8411e-04, 4.0036e-04, 1.0669e-04, 6.7087e-07, 1.7174e-04, 7.5184e-06,\n",
      "        3.8200e-04, 1.1222e-04, 3.0107e-04, 8.8231e-05, 4.8026e-07, 2.5736e-04,\n",
      "        2.0902e-04, 7.9244e-06, 8.0644e-05, 1.9635e-06, 6.5834e-05, 3.6014e-04,\n",
      "        2.6652e-08, 1.7238e-04, 3.8817e-05, 3.5918e-04, 2.0681e-04, 1.2531e-04,\n",
      "        3.1075e-04, 3.4088e-04, 2.2643e-04, 2.8019e-04, 6.7612e-07, 6.4204e-06,\n",
      "        1.9387e-04, 1.4891e-04, 2.5642e-04, 4.3675e-04, 4.0602e-04, 3.7146e-04,\n",
      "        1.1111e-06, 8.9931e-06, 2.3607e-05, 1.8156e-05, 2.3861e-04, 1.5442e-04,\n",
      "        2.3462e-05, 1.6684e-06, 2.2483e-04, 8.8090e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0067, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0139, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.7976, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([4.0713e-03, 2.3597e-02, 4.4037e-02, 1.2796e-01, 5.3878e-04, 1.8337e-02,\n",
      "        3.8584e-03, 5.4381e-03, 7.7668e-03, 3.1201e-02, 1.4794e-01, 2.3797e-02,\n",
      "        4.8942e-02, 4.9695e-02, 1.7828e-02, 7.5641e-02, 3.6308e-02, 1.0092e-02,\n",
      "        2.8902e-03, 7.6308e-03, 1.4644e-02, 5.2808e-03, 2.1048e-02, 5.7396e-02,\n",
      "        8.1016e-03, 5.9476e-02, 3.2716e-03, 5.1968e-03, 2.9709e-03, 2.5054e-02,\n",
      "        8.9215e-03, 2.9926e-03, 1.7272e-03, 5.9424e-02, 7.9981e-03, 2.4030e-02,\n",
      "        2.9626e-02, 4.5483e-02, 3.1470e-02, 1.3359e-02, 1.5925e-03, 2.0736e-02,\n",
      "        1.3719e-02, 1.9979e-02, 1.5885e-02, 3.4057e-02, 2.5519e-02, 1.9305e-03,\n",
      "        2.9607e-03, 1.3864e-02, 5.2421e-02, 9.1707e-03, 9.2673e-02, 5.5619e-03,\n",
      "        2.0566e-03, 7.2832e-02, 2.1184e-02, 1.8139e-02, 1.6823e-02, 4.6957e-03,\n",
      "        1.6433e-05, 4.5440e-03, 1.2392e-02, 2.9099e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0638, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1536, device='cuda:0')\n",
      "p.batch_l2: tensor([5.2600e-05, 3.4391e-04, 3.4935e-04, 8.7935e-04, 6.2154e-06, 9.3436e-05,\n",
      "        3.5273e-05, 3.4615e-05, 1.2503e-04, 2.1918e-04, 1.5402e-03, 2.9721e-04,\n",
      "        8.9397e-04, 6.9698e-04, 9.9678e-05, 8.6781e-04, 4.5562e-04, 9.5768e-05,\n",
      "        3.3591e-05, 5.0628e-05, 2.3941e-04, 5.1954e-05, 4.3832e-04, 3.2178e-04,\n",
      "        1.3415e-04, 5.2047e-04, 3.5771e-05, 7.8514e-05, 1.6842e-05, 1.1487e-04,\n",
      "        7.1436e-05, 5.6337e-05, 2.1694e-05, 4.6807e-04, 6.7736e-05, 9.9104e-04,\n",
      "        3.7870e-04, 6.8376e-04, 7.8154e-04, 2.6906e-04, 3.5067e-05, 6.9853e-04,\n",
      "        1.7829e-04, 4.8048e-04, 3.5810e-04, 8.1441e-04, 2.6061e-04, 3.8508e-05,\n",
      "        2.1701e-05, 1.2408e-04, 5.6824e-04, 4.9843e-05, 1.4977e-03, 8.1666e-05,\n",
      "        1.7811e-05, 3.8898e-04, 1.4710e-04, 1.2937e-04, 4.4764e-04, 8.0778e-05,\n",
      "        1.6603e-07, 6.5611e-05, 1.8006e-04, 9.8734e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0073, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0185, device='cuda:0')\n",
      "p.batch_l2: tensor([5.6131e-03, 4.0649e-02, 1.0698e-01, 2.5374e-01, 1.2158e-03, 1.5533e-02,\n",
      "        5.7506e-03, 7.9380e-03, 1.9227e-02, 4.9624e-02, 3.3099e-01, 6.6059e-02,\n",
      "        8.1704e-02, 7.8224e-02, 4.1121e-02, 7.1854e-02, 6.7550e-02, 1.6011e-02,\n",
      "        5.9409e-03, 1.2166e-02, 2.3151e-02, 7.0617e-03, 4.6770e-02, 1.5432e-01,\n",
      "        1.7457e-02, 1.1433e-01, 4.9782e-03, 9.5362e-03, 2.6024e-03, 2.9314e-02,\n",
      "        2.2014e-02, 8.5270e-03, 2.8569e-03, 9.2463e-02, 1.2600e-02, 4.6530e-02,\n",
      "        4.6856e-02, 6.3426e-02, 4.1033e-02, 2.2034e-02, 3.2840e-03, 3.4411e-02,\n",
      "        3.2255e-02, 4.7415e-02, 3.2073e-02, 3.5564e-02, 5.6855e-02, 7.1018e-03,\n",
      "        5.1415e-03, 3.0189e-02, 1.2180e-01, 1.8209e-02, 2.3262e-01, 7.7838e-03,\n",
      "        2.9504e-03, 1.0107e-01, 2.7728e-02, 2.4358e-02, 2.0584e-02, 9.3520e-03,\n",
      "        3.6948e-05, 7.2085e-03, 3.3733e-02, 7.6705e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.0749, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2016, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2032e-05, 6.1302e-05, 1.7534e-04, 3.0974e-04, 1.2857e-06, 2.6926e-05,\n",
      "        6.5302e-06, 1.1573e-05, 2.7424e-05, 6.9684e-05, 5.3241e-04, 1.1311e-04,\n",
      "        1.4066e-04, 2.2500e-04, 5.8675e-05, 1.8558e-04, 9.8955e-05, 2.4246e-05,\n",
      "        1.0468e-05, 2.4194e-05, 3.1419e-05, 1.2757e-05, 1.1840e-04, 1.9041e-04,\n",
      "        3.5529e-05, 1.9645e-04, 1.1657e-05, 2.6665e-05, 4.3274e-06, 2.8812e-05,\n",
      "        2.6751e-05, 1.6671e-05, 4.9220e-06, 1.8407e-04, 1.5858e-05, 1.9769e-04,\n",
      "        1.2254e-04, 1.4841e-04, 1.3794e-04, 6.5039e-05, 9.6574e-06, 1.3290e-04,\n",
      "        7.8949e-05, 9.2776e-05, 6.3223e-05, 1.1328e-04, 9.5930e-05, 1.1205e-05,\n",
      "        1.4121e-05, 4.4033e-05, 1.4745e-04, 3.3962e-05, 4.0294e-04, 1.4731e-05,\n",
      "        5.3663e-06, 1.8789e-04, 4.1435e-05, 4.8880e-05, 4.9427e-05, 2.1005e-05,\n",
      "        4.7677e-08, 1.3885e-05, 5.1860e-05, 1.7540e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0035, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0078, device='cuda:0')\n",
      "p.batch_l2: tensor([6.0402e-03, 4.4985e-02, 8.7514e-02, 6.8051e-01, 1.3898e-03, 3.0049e-02,\n",
      "        7.5372e-03, 8.6636e-03, 3.8180e-02, 1.5232e-01, 4.8679e-01, 7.6691e-02,\n",
      "        2.4502e-01, 9.0328e-02, 8.4718e-02, 4.3768e-02, 2.0452e-01, 2.1830e-02,\n",
      "        1.9915e-02, 1.3094e-02, 4.5954e-02, 8.7291e-03, 4.8210e-02, 2.7029e-01,\n",
      "        3.0320e-02, 2.1717e-01, 8.5326e-03, 6.4021e-03, 6.1871e-03, 7.7122e-02,\n",
      "        3.0166e-02, 1.0881e-02, 3.1985e-03, 1.1393e-01, 1.2312e-02, 2.9944e-02,\n",
      "        4.4173e-02, 4.2890e-02, 2.7617e-02, 3.4935e-02, 7.3933e-03, 1.8881e-02,\n",
      "        1.1416e-01, 6.7795e-02, 5.7813e-02, 6.4417e-02, 1.2336e-01, 1.1593e-02,\n",
      "        9.1301e-03, 7.4304e-02, 1.3614e-01, 1.8237e-02, 3.3181e-01, 2.5279e-02,\n",
      "        1.1352e-02, 1.6998e-01, 2.6600e-02, 5.3126e-02, 3.3019e-02, 1.2931e-02,\n",
      "        7.9298e-05, 5.3796e-03, 3.3320e-02, 8.2981e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0777, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2121, device='cuda:0')\n",
      "p.batch_l2: tensor([9.3097e-06, 5.0555e-05, 5.9285e-05, 2.3468e-04, 4.9932e-07, 3.1356e-05,\n",
      "        6.0747e-06, 9.3177e-06, 1.4722e-05, 6.3436e-05, 1.7087e-04, 4.6295e-05,\n",
      "        1.1806e-04, 7.4732e-05, 3.1242e-05, 8.7625e-05, 8.8026e-05, 1.6152e-05,\n",
      "        6.1030e-06, 1.1950e-05, 4.8840e-05, 5.6072e-06, 4.5362e-05, 7.2714e-05,\n",
      "        1.7548e-05, 6.9040e-05, 5.1979e-06, 1.1036e-05, 6.0091e-06, 4.0219e-05,\n",
      "        2.2283e-05, 5.5400e-06, 4.0673e-06, 6.5873e-05, 6.8611e-06, 6.5785e-05,\n",
      "        4.9906e-05, 5.9786e-05, 5.8481e-05, 2.4067e-05, 5.8964e-06, 3.2698e-05,\n",
      "        3.1268e-05, 4.7511e-05, 2.3885e-05, 7.0363e-05, 3.6777e-05, 4.4362e-06,\n",
      "        1.2957e-05, 3.2111e-05, 7.2744e-05, 1.6925e-05, 1.5457e-04, 1.7977e-05,\n",
      "        5.7036e-06, 7.8784e-05, 2.2624e-05, 2.9028e-05, 3.3726e-05, 9.5643e-06,\n",
      "        1.9163e-08, 4.5957e-06, 1.7492e-05, 4.4483e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0031, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0071, device='cuda:0')\n",
      "p.batch_l2: tensor([2.7208e-03, 1.3941e-02, 2.4355e-02, 3.1549e-01, 1.1307e-03, 6.3291e-03,\n",
      "        3.8104e-03, 5.3880e-02, 4.4712e-02, 4.7126e-02, 1.5098e-01, 3.6107e-02,\n",
      "        6.3872e-02, 5.1452e-02, 4.4382e-02, 5.1099e-03, 5.7124e-02, 2.3283e-02,\n",
      "        4.7865e-03, 4.5355e-02, 1.8784e-02, 4.3491e-02, 8.2125e-03, 9.2183e-02,\n",
      "        1.9584e-02, 7.6899e-02, 1.7289e-03, 1.9038e-02, 2.5247e-03, 2.8937e-02,\n",
      "        1.5535e-02, 2.6554e-03, 3.4218e-03, 6.2335e-02, 7.1656e-03, 5.2004e-03,\n",
      "        1.4239e-02, 9.3552e-03, 1.0500e-02, 3.0906e-02, 2.3240e-03, 5.4695e-03,\n",
      "        7.4003e-02, 1.8911e-02, 4.7841e-02, 2.0962e-02, 5.4926e-02, 2.1639e-03,\n",
      "        8.8316e-03, 2.2932e-02, 3.3618e-02, 4.5730e-02, 1.5149e-01, 2.0102e-02,\n",
      "        2.5479e-02, 1.3315e-01, 3.0059e-02, 3.1301e-02, 1.7320e-02, 2.2380e-02,\n",
      "        2.3295e-05, 2.6426e-03, 2.5643e-02, 6.8858e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0522, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1181, device='cuda:0')\n",
      "p.batch_l2: tensor([4.6742e-05, 1.4822e-04, 3.2004e-04, 4.1575e-04, 4.4619e-06, 1.1901e-04,\n",
      "        3.5413e-05, 2.7265e-04, 2.1715e-04, 2.5790e-04, 4.8043e-04, 2.2387e-04,\n",
      "        3.5955e-04, 3.4486e-04, 3.8105e-04, 2.5625e-04, 3.7308e-04, 2.4106e-04,\n",
      "        1.5838e-05, 2.4048e-04, 1.6816e-04, 2.0697e-04, 2.0813e-04, 3.3485e-04,\n",
      "        9.3527e-05, 4.4260e-04, 1.4032e-05, 2.6751e-04, 2.9787e-05, 2.0370e-04,\n",
      "        1.3702e-04, 1.5985e-05, 2.4258e-05, 3.5532e-04, 5.0181e-05, 2.3354e-04,\n",
      "        1.8064e-04, 2.7550e-04, 2.2908e-04, 1.7982e-04, 2.1817e-05, 1.1692e-04,\n",
      "        3.2491e-04, 2.0988e-04, 2.2606e-04, 2.9744e-04, 3.1278e-04, 1.0957e-05,\n",
      "        2.4672e-04, 8.3366e-05, 1.9363e-04, 2.5470e-04, 4.3597e-04, 1.5790e-04,\n",
      "        1.7158e-04, 4.3220e-04, 2.5986e-04, 1.1052e-04, 1.2536e-04, 1.8655e-04,\n",
      "        4.8539e-08, 2.3870e-05, 1.6753e-04, 3.9734e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0068, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0122, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.5909, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.batch_l2: tensor([1.1394e-02, 5.3044e-03, 8.7495e-04, 2.4289e-03, 1.0083e-04, 5.1635e-02,\n",
      "        1.0484e-02, 3.0303e-02, 2.0424e-02, 1.0939e-01, 6.4910e-02, 6.9143e-03,\n",
      "        6.0170e-03, 1.0377e-02, 4.2353e-02, 2.7196e-03, 1.6064e-02, 4.7629e-02,\n",
      "        1.1982e-02, 9.8534e-03, 2.3834e-03, 9.5943e-03, 4.8246e-02, 1.2974e-02,\n",
      "        5.5042e-03, 2.9087e-02, 3.0611e-02, 8.3184e-02, 1.1716e-01, 7.0769e-02,\n",
      "        9.7389e-03, 4.3589e-02, 1.8799e-02, 5.1641e-02, 2.6255e-02, 1.1414e-02,\n",
      "        1.9295e-02, 2.2998e-02, 5.1422e-03, 5.7780e-02, 3.1679e-02, 5.0118e-02,\n",
      "        6.6519e-03, 1.1686e-01, 2.6675e-02, 7.4724e-02, 4.4452e-03, 4.7439e-02,\n",
      "        2.1624e-02, 5.3776e-03, 3.6207e-03, 6.9784e-02, 2.6176e-03, 3.3637e-02,\n",
      "        2.5640e-02, 2.1992e-02, 4.5497e-02, 4.0649e-02, 2.3724e-02, 1.9445e-05,\n",
      "        2.1430e-02, 4.4872e-03, 4.9519e-02, 1.1560e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1067, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0728, device='cuda:0')\n",
      "p.batch_l2: tensor([2.0678e-04, 1.2505e-04, 3.5992e-06, 2.4966e-05, 7.3481e-07, 1.1790e-03,\n",
      "        3.3724e-04, 2.9959e-04, 3.7908e-04, 1.8181e-03, 1.1782e-03, 1.4953e-04,\n",
      "        1.3586e-04, 2.4627e-04, 1.7246e-04, 1.0390e-04, 1.4286e-04, 2.4528e-04,\n",
      "        2.3148e-04, 1.7041e-04, 8.4444e-05, 6.8983e-05, 5.2657e-04, 3.4144e-04,\n",
      "        9.7673e-05, 2.0277e-04, 4.2812e-04, 1.4516e-03, 1.7650e-03, 7.0449e-04,\n",
      "        1.1882e-04, 7.6412e-04, 1.0413e-04, 8.8579e-04, 3.3233e-04, 1.5523e-04,\n",
      "        2.9347e-04, 2.5638e-04, 5.1103e-05, 9.9595e-04, 1.5107e-04, 7.4475e-04,\n",
      "        1.2813e-04, 1.9052e-03, 3.2154e-04, 6.5112e-04, 7.1431e-05, 3.5275e-04,\n",
      "        4.5301e-04, 1.3171e-04, 1.2201e-04, 5.0390e-04, 6.5220e-05, 5.8352e-04,\n",
      "        5.3738e-04, 3.8742e-04, 4.0975e-04, 3.8033e-04, 9.0505e-05, 2.0304e-07,\n",
      "        5.4303e-04, 1.0531e-04, 6.8439e-04, 1.2908e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0144, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0112, device='cuda:0')\n",
      "p.batch_l2: tensor([2.5779e-02, 7.4685e-03, 7.9389e-04, 3.7402e-03, 1.8417e-04, 9.1435e-02,\n",
      "        2.1569e-02, 4.1698e-02, 3.5662e-02, 1.6483e-01, 1.2382e-01, 7.7614e-03,\n",
      "        1.0735e-02, 1.5779e-02, 5.5840e-02, 4.5042e-03, 2.2767e-02, 4.9313e-02,\n",
      "        1.3470e-02, 2.7635e-02, 4.3200e-03, 1.6777e-02, 8.2756e-02, 2.0499e-02,\n",
      "        8.0005e-03, 3.3805e-02, 5.3101e-02, 1.2784e-01, 1.5065e-01, 7.5163e-02,\n",
      "        1.6613e-02, 8.7272e-02, 3.9711e-02, 9.0577e-02, 3.6598e-02, 1.2062e-02,\n",
      "        3.1045e-02, 3.9836e-02, 6.8405e-03, 9.8589e-02, 4.8903e-02, 1.3989e-01,\n",
      "        1.1676e-02, 2.8399e-01, 4.9584e-02, 7.9812e-02, 8.5907e-03, 6.7706e-02,\n",
      "        3.8675e-02, 1.0788e-02, 5.7242e-03, 1.2773e-01, 6.0469e-03, 5.7587e-02,\n",
      "        5.2436e-02, 3.9108e-02, 7.1513e-02, 4.9155e-02, 2.5749e-02, 4.6430e-05,\n",
      "        5.0114e-02, 9.0978e-03, 1.0624e-01, 2.1820e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1606, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0864, device='cuda:0')\n",
      "p.batch_l2: tensor([8.2438e-05, 2.9501e-05, 1.0782e-06, 6.7359e-06, 2.3294e-07, 1.9124e-04,\n",
      "        6.4130e-05, 8.8289e-05, 1.0385e-04, 3.4044e-04, 3.5387e-04, 2.1252e-05,\n",
      "        4.6304e-05, 6.9737e-05, 9.5227e-05, 2.1157e-05, 4.7087e-05, 7.8948e-05,\n",
      "        3.5854e-05, 5.2581e-05, 1.8211e-05, 2.1627e-05, 1.2631e-04, 7.4219e-05,\n",
      "        2.9456e-05, 4.4159e-05, 1.2663e-04, 3.1441e-04, 3.0546e-04, 1.0542e-04,\n",
      "        3.2228e-05, 1.6918e-04, 6.8782e-05, 2.7277e-04, 1.1623e-04, 4.0495e-05,\n",
      "        6.3315e-05, 3.7488e-05, 1.5206e-05, 2.3619e-04, 5.4072e-05, 2.1534e-04,\n",
      "        5.1348e-05, 7.0267e-04, 1.1604e-04, 1.2427e-04, 1.5260e-05, 1.0683e-04,\n",
      "        8.0132e-05, 4.8785e-05, 2.4127e-05, 1.8155e-04, 3.4496e-05, 1.3583e-04,\n",
      "        1.1356e-04, 9.7367e-05, 1.3754e-04, 9.5579e-05, 3.5482e-05, 9.6579e-08,\n",
      "        1.4732e-04, 3.7615e-05, 1.1335e-04, 4.0910e-07], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0091, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0054, device='cuda:0')\n",
      "p.batch_l2: tensor([2.4714e-02, 9.1872e-03, 6.3338e-04, 2.9365e-03, 1.5638e-04, 9.5614e-02,\n",
      "        2.9816e-02, 3.2032e-02, 2.8959e-02, 1.5916e-01, 8.1624e-02, 1.0439e-02,\n",
      "        1.1089e-02, 1.7902e-02, 7.2869e-02, 6.5960e-03, 2.3476e-02, 3.3506e-02,\n",
      "        9.8019e-03, 1.8151e-02, 3.9608e-03, 2.9914e-02, 8.9152e-02, 1.9609e-02,\n",
      "        1.0065e-02, 7.3395e-02, 3.8243e-02, 1.0709e-01, 1.4037e-01, 5.7611e-02,\n",
      "        8.6345e-03, 9.0700e-02, 4.9196e-02, 9.9029e-02, 3.5890e-02, 1.3373e-02,\n",
      "        5.7922e-02, 4.8387e-02, 1.2766e-02, 1.3222e-01, 5.3324e-02, 8.2760e-02,\n",
      "        7.6084e-03, 2.2212e-01, 4.5657e-02, 1.2050e-01, 8.1934e-03, 7.3484e-02,\n",
      "        4.2794e-02, 6.7952e-03, 3.5011e-03, 1.7264e-01, 6.0073e-03, 5.6973e-02,\n",
      "        2.2527e-02, 4.0443e-02, 1.0261e-01, 6.0506e-02, 3.5526e-02, 8.7174e-05,\n",
      "        4.6605e-02, 7.9710e-03, 9.6481e-02, 1.8360e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.1572, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0958, device='cuda:0')\n",
      "p.batch_l2: tensor([2.7262e-05, 1.0153e-05, 7.2168e-07, 3.0730e-06, 9.6016e-08, 6.5442e-05,\n",
      "        3.7166e-05, 4.4395e-05, 3.1106e-05, 1.5299e-04, 9.0099e-05, 1.3553e-05,\n",
      "        1.5542e-05, 2.6422e-05, 7.1542e-05, 1.1552e-05, 2.2678e-05, 4.1276e-05,\n",
      "        2.3533e-05, 1.1158e-05, 7.1943e-06, 1.2547e-05, 5.2598e-05, 2.7604e-05,\n",
      "        1.2100e-05, 6.3198e-05, 3.2004e-05, 7.0867e-05, 1.2633e-04, 7.1715e-05,\n",
      "        1.3322e-05, 6.9952e-05, 2.5138e-05, 1.1740e-04, 5.3593e-05, 1.7306e-05,\n",
      "        4.0784e-05, 4.2803e-05, 9.0140e-06, 9.3291e-05, 5.9339e-05, 4.9546e-05,\n",
      "        1.2935e-05, 1.3318e-04, 5.2456e-05, 9.4986e-05, 7.7865e-06, 8.7088e-05,\n",
      "        4.7837e-05, 1.1055e-05, 5.4407e-06, 1.0765e-04, 9.8610e-06, 3.4534e-05,\n",
      "        2.8156e-05, 3.2507e-05, 5.9220e-05, 6.0912e-05, 3.6257e-05, 3.4637e-08,\n",
      "        3.8649e-05, 1.1559e-05, 9.1428e-05, 1.2712e-07], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0052, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0032, device='cuda:0')\n",
      "p.batch_l2: tensor([3.1617e-02, 6.1278e-03, 3.8817e-04, 1.6865e-03, 9.7056e-05, 1.8964e-02,\n",
      "        1.7644e-02, 3.4492e-02, 6.7993e-03, 4.3569e-02, 2.9972e-02, 2.3045e-03,\n",
      "        5.5203e-03, 1.1498e-02, 2.6364e-02, 3.5373e-03, 1.0531e-02, 2.1765e-02,\n",
      "        1.0139e-02, 4.7943e-03, 6.7299e-03, 3.2434e-03, 8.1777e-02, 3.1370e-02,\n",
      "        1.0816e-02, 9.8498e-03, 3.4552e-02, 2.6186e-02, 1.9203e-02, 1.6523e-02,\n",
      "        4.0120e-03, 8.5591e-03, 1.7310e-02, 2.8223e-02, 1.3648e-02, 6.9793e-03,\n",
      "        3.6370e-02, 1.2242e-02, 6.1301e-03, 1.1585e-01, 3.9694e-02, 3.1252e-02,\n",
      "        2.8513e-03, 3.2735e-02, 1.7603e-02, 1.5842e-02, 2.9263e-03, 2.2211e-02,\n",
      "        4.2005e-03, 3.7993e-03, 2.2692e-03, 3.0522e-02, 5.1266e-03, 2.8697e-02,\n",
      "        2.4820e-03, 2.2560e-02, 4.3016e-02, 4.0349e-02, 1.9491e-02, 5.5561e-05,\n",
      "        1.4510e-02, 6.0996e-03, 1.7140e-02, 1.7191e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.1778, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0783, device='cuda:0')\n",
      "p.batch_l2: tensor([3.1143e-04, 5.0719e-05, 4.4493e-06, 1.3414e-05, 5.4810e-07, 2.9565e-04,\n",
      "        2.7085e-04, 3.0796e-04, 7.6661e-05, 4.0220e-04, 3.1753e-04, 3.5714e-05,\n",
      "        9.0719e-05, 1.4881e-04, 1.8076e-04, 6.6095e-05, 2.9202e-04, 1.6791e-04,\n",
      "        2.6867e-04, 3.2449e-05, 2.4354e-04, 2.4099e-04, 4.0112e-04, 3.1166e-04,\n",
      "        7.3609e-05, 2.6865e-04, 3.1080e-04, 2.0969e-04, 2.8873e-04, 2.9415e-04,\n",
      "        2.4910e-04, 2.6711e-04, 2.0840e-04, 2.7506e-04, 2.6798e-04, 1.0410e-04,\n",
      "        3.1847e-04, 1.8994e-04, 3.0654e-05, 4.5892e-04, 2.9179e-04, 2.2483e-04,\n",
      "        6.8661e-05, 3.2154e-04, 3.1476e-04, 3.0448e-04, 3.8331e-05, 3.3910e-04,\n",
      "        2.0701e-04, 5.8431e-05, 3.2800e-05, 2.9174e-04, 6.0981e-05, 2.5812e-04,\n",
      "        2.0063e-04, 3.1597e-04, 3.6420e-04, 3.6436e-04, 2.2509e-04, 1.4861e-07,\n",
      "        1.0403e-04, 7.7396e-05, 3.4088e-04, 5.0677e-07], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0176, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0071, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.5636, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([3.1521e-02, 2.3690e-02, 1.2419e-02, 2.6887e-02, 8.1710e-03, 2.4510e-02,\n",
      "        6.9742e-02, 6.1533e-03, 1.4603e-02, 4.1974e-02, 1.9508e-02, 4.0333e-02,\n",
      "        3.9219e-03, 1.6852e-02, 5.4416e-02, 5.3515e-02, 8.2756e-02, 2.0323e-02,\n",
      "        3.5906e-02, 4.8288e-05, 7.8280e-03, 4.7257e-02, 2.4551e-02, 2.3526e-02,\n",
      "        1.2836e-02, 2.4253e-02, 7.2321e-03, 1.6638e-02, 3.6282e-04, 5.0381e-02,\n",
      "        8.3449e-03, 3.6465e-02, 5.5167e-03, 7.4156e-03, 8.9253e-03, 2.1000e-02,\n",
      "        6.6184e-02, 4.7840e-03, 7.8430e-02, 7.0776e-02, 1.5190e-02, 2.4908e-03,\n",
      "        1.2277e-02, 4.9466e-03, 3.4182e-03, 3.9595e-02, 1.3825e-02, 5.2915e-03,\n",
      "        6.7511e-02, 5.2135e-02, 1.1493e-02, 3.3468e-02, 2.8972e-02, 3.5038e-04,\n",
      "        7.4469e-02, 1.8596e-02, 5.2971e-03, 4.1736e-02, 1.4176e-02, 8.5349e-04,\n",
      "        4.5685e-03, 1.4455e-03, 4.2368e-02, 3.0912e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1775, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1539, device='cuda:0')\n",
      "p.batch_l2: tensor([3.9608e-04, 1.3211e-04, 1.8192e-04, 4.7624e-04, 2.6833e-04, 2.6294e-04,\n",
      "        7.3814e-04, 1.7959e-04, 1.5446e-04, 3.3695e-04, 3.2129e-04, 3.3572e-04,\n",
      "        1.4266e-04, 9.9828e-05, 6.6280e-04, 3.7112e-04, 1.5954e-03, 4.4533e-04,\n",
      "        3.7278e-04, 2.3186e-07, 1.7895e-04, 5.3641e-04, 3.9285e-04, 2.2768e-04,\n",
      "        1.5374e-04, 1.9784e-04, 4.2214e-05, 1.1408e-04, 1.9887e-05, 1.2654e-03,\n",
      "        7.1876e-05, 5.4538e-04, 1.1889e-04, 1.6633e-04, 2.2034e-04, 2.2959e-04,\n",
      "        8.4753e-04, 5.7191e-05, 6.7102e-04, 4.8888e-04, 1.5658e-04, 3.0808e-05,\n",
      "        2.8186e-04, 2.3476e-05, 6.7556e-05, 4.6434e-04, 8.7228e-05, 9.8801e-05,\n",
      "        4.8566e-04, 9.1854e-04, 2.8801e-04, 3.4939e-04, 4.0421e-04, 6.7848e-06,\n",
      "        1.2079e-03, 2.3101e-04, 6.0968e-05, 4.7759e-04, 1.8015e-04, 7.6018e-06,\n",
      "        1.1174e-04, 1.0502e-05, 2.7325e-04, 3.2635e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0199, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0115, device='cuda:0')\n",
      "p.batch_l2: tensor([4.7100e-02, 2.8210e-02, 2.6279e-02, 4.0492e-02, 1.5564e-02, 2.7760e-02,\n",
      "        8.2074e-02, 9.6366e-03, 1.8354e-02, 6.1259e-02, 2.9523e-02, 5.2289e-02,\n",
      "        5.4396e-03, 1.9703e-02, 9.9450e-02, 5.9813e-02, 1.0154e-01, 3.6363e-02,\n",
      "        5.7253e-02, 6.7034e-05, 1.3498e-02, 6.3376e-02, 3.7813e-02, 2.9978e-02,\n",
      "        1.9249e-02, 2.4663e-02, 1.3136e-02, 2.0936e-02, 7.0219e-04, 1.3071e-01,\n",
      "        8.1071e-03, 3.8857e-02, 1.0600e-02, 1.1020e-02, 1.2971e-02, 3.9715e-02,\n",
      "        8.6298e-02, 5.6656e-03, 1.1032e-01, 9.0048e-02, 2.6809e-02, 3.5942e-03,\n",
      "        2.0012e-02, 5.5288e-03, 7.8636e-03, 3.7200e-02, 2.3954e-02, 8.8947e-03,\n",
      "        8.1044e-02, 8.0158e-02, 2.7839e-02, 4.9707e-02, 3.6980e-02, 6.2951e-04,\n",
      "        9.0799e-02, 3.1498e-02, 8.8427e-03, 8.1158e-02, 1.8149e-02, 1.2284e-03,\n",
      "        9.0314e-03, 1.8529e-03, 6.1249e-02, 5.6375e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.2170, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1680, device='cuda:0')\n",
      "p.batch_l2: tensor([1.1154e-04, 5.1148e-05, 5.3396e-05, 1.1006e-04, 6.8316e-05, 4.9500e-05,\n",
      "        1.2384e-04, 3.2337e-05, 2.9152e-05, 1.2196e-04, 5.4969e-05, 1.1538e-04,\n",
      "        1.4496e-05, 2.8864e-05, 3.1750e-04, 8.2710e-05, 2.2893e-04, 7.9368e-05,\n",
      "        1.1990e-04, 1.0063e-07, 4.6022e-05, 1.0241e-04, 9.9822e-05, 5.5301e-05,\n",
      "        3.0429e-05, 3.9123e-05, 2.0117e-05, 3.3803e-05, 2.9875e-06, 3.3253e-04,\n",
      "        1.5337e-05, 9.4089e-05, 3.9828e-05, 2.7545e-05, 4.6730e-05, 6.7452e-05,\n",
      "        1.6277e-04, 9.7979e-06, 2.0749e-04, 1.6259e-04, 5.0938e-05, 7.1948e-06,\n",
      "        4.9327e-05, 8.2655e-06, 1.8714e-05, 8.9296e-05, 5.8165e-05, 2.4400e-05,\n",
      "        2.2011e-04, 1.3031e-04, 7.1590e-05, 1.0716e-04, 8.8477e-05, 1.8344e-06,\n",
      "        1.8093e-04, 6.8059e-05, 2.0414e-05, 1.2603e-04, 4.2414e-05, 2.0597e-06,\n",
      "        1.9474e-05, 4.0213e-06, 1.1866e-04, 1.0684e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0106, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0072, device='cuda:0')\n",
      "p.batch_l2: tensor([4.3953e-02, 2.1131e-02, 1.9952e-02, 2.1947e-02, 2.4100e-02, 2.4965e-02,\n",
      "        4.9696e-02, 1.3405e-02, 1.3859e-02, 3.3184e-02, 2.1848e-02, 3.6094e-02,\n",
      "        7.9316e-03, 1.3954e-02, 7.9424e-02, 7.7846e-02, 3.5560e-02, 3.2463e-02,\n",
      "        2.0128e-02, 4.8881e-05, 1.3521e-02, 5.7612e-02, 1.7295e-02, 2.7914e-02,\n",
      "        1.8043e-02, 1.2302e-02, 6.7513e-03, 1.0697e-02, 6.2500e-04, 7.9647e-02,\n",
      "        6.6098e-03, 2.9397e-02, 1.5397e-02, 5.1200e-03, 2.1671e-02, 1.9269e-02,\n",
      "        6.4509e-02, 8.0320e-03, 1.0078e-01, 4.3498e-02, 1.5556e-02, 5.0077e-03,\n",
      "        6.9487e-03, 7.8336e-03, 8.6856e-03, 7.1275e-02, 1.8137e-02, 1.3223e-02,\n",
      "        3.6118e-02, 3.6209e-02, 1.8566e-02, 3.6305e-02, 2.3627e-02, 3.6520e-04,\n",
      "        3.7150e-02, 2.3100e-02, 5.9000e-03, 6.7108e-02, 8.8519e-03, 1.3975e-03,\n",
      "        3.9055e-03, 1.3904e-03, 3.3800e-02, 2.6072e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.2096, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1454, device='cuda:0')\n",
      "p.batch_l2: tensor([4.4450e-05, 2.7803e-05, 2.4358e-05, 2.9322e-05, 2.4836e-05, 3.2717e-05,\n",
      "        5.6118e-05, 1.6706e-05, 2.1859e-05, 5.6868e-05, 1.8202e-05, 4.3811e-05,\n",
      "        7.1398e-06, 1.1796e-05, 9.8230e-05, 8.4208e-05, 4.8830e-05, 3.7107e-05,\n",
      "        2.9741e-05, 4.5051e-08, 1.9192e-05, 6.9362e-05, 2.9869e-05, 3.1077e-05,\n",
      "        1.9903e-05, 1.8294e-05, 6.5314e-06, 1.4517e-05, 9.0805e-07, 8.7482e-05,\n",
      "        8.8255e-06, 4.9751e-05, 1.5311e-05, 7.0006e-06, 2.4240e-05, 2.9967e-05,\n",
      "        8.2787e-05, 8.8304e-06, 8.2315e-05, 6.2012e-05, 1.9250e-05, 5.5751e-06,\n",
      "        8.7982e-06, 5.7835e-06, 8.7590e-06, 6.0619e-05, 2.1111e-05, 1.0913e-05,\n",
      "        5.5296e-05, 6.0910e-05, 1.8260e-05, 6.5195e-05, 3.1918e-05, 4.4641e-07,\n",
      "        4.3192e-05, 2.4114e-05, 6.1815e-06, 7.0044e-05, 1.1255e-05, 1.0147e-06,\n",
      "        4.3178e-06, 1.3924e-06, 4.3520e-05, 3.3547e-07], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0067, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0053, device='cuda:0')\n",
      "p.batch_l2: tensor([4.8178e-03, 1.7064e-03, 1.7486e-02, 2.1907e-03, 2.5409e-03, 1.1259e-03,\n",
      "        1.2480e-03, 3.5814e-03, 6.2917e-03, 7.2007e-03, 2.3345e-02, 7.2085e-03,\n",
      "        4.4238e-03, 2.6561e-03, 4.8512e-03, 5.0444e-03, 4.4391e-03, 8.9708e-03,\n",
      "        4.2143e-03, 6.3146e-05, 2.0504e-03, 4.7666e-03, 2.7064e-03, 5.4853e-03,\n",
      "        5.7537e-03, 3.4279e-03, 1.8423e-03, 4.8576e-03, 4.4773e-04, 2.3150e-02,\n",
      "        7.9320e-03, 1.6985e-02, 2.6258e-03, 3.3035e-03, 4.0350e-03, 3.3275e-03,\n",
      "        1.1688e-02, 1.3374e-03, 1.7099e-02, 1.9060e-03, 8.4664e-03, 5.9174e-03,\n",
      "        3.2899e-03, 8.7428e-03, 7.8294e-03, 8.9632e-03, 1.6600e-03, 3.6385e-03,\n",
      "        2.1363e-03, 2.4483e-03, 3.3937e-03, 4.5804e-03, 1.9720e-03, 3.3369e-04,\n",
      "        2.5399e-03, 6.9771e-03, 4.2503e-03, 2.2659e-03, 1.0123e-02, 4.2704e-03,\n",
      "        1.1368e-03, 1.9439e-03, 6.1328e-03, 1.0125e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0694, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0413, device='cuda:0')\n",
      "p.batch_l2: tensor([1.6807e-04, 1.1892e-04, 2.7198e-04, 1.0615e-04, 1.2499e-04, 1.2600e-04,\n",
      "        1.5690e-04, 8.2585e-05, 2.4691e-04, 1.9920e-04, 3.5393e-04, 1.3808e-04,\n",
      "        1.2639e-04, 3.6212e-05, 2.0633e-04, 2.6122e-04, 1.6258e-04, 2.3979e-04,\n",
      "        1.0473e-04, 2.5252e-07, 1.0020e-04, 2.4843e-04, 1.8971e-04, 1.8043e-04,\n",
      "        2.3436e-04, 1.2267e-04, 2.1230e-04, 2.1387e-04, 4.4622e-06, 2.9666e-04,\n",
      "        1.9110e-04, 2.9974e-04, 8.0819e-05, 2.2865e-04, 1.0998e-04, 2.5810e-04,\n",
      "        2.8016e-04, 1.9992e-04, 2.9361e-04, 1.9052e-04, 2.6236e-04, 2.0722e-04,\n",
      "        4.6945e-05, 2.0476e-04, 2.4898e-04, 2.7175e-04, 9.1748e-05, 1.4979e-04,\n",
      "        2.1399e-04, 1.9263e-04, 2.0939e-04, 2.3767e-04, 1.1720e-04, 2.5622e-06,\n",
      "        1.7961e-04, 2.2759e-04, 1.9924e-04, 2.3921e-04, 2.0844e-04, 3.4469e-05,\n",
      "        2.5004e-05, 2.2249e-05, 1.3902e-04, 1.0000e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0130, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0109, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.8377, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([5.1918e-06, 2.0048e-03, 2.7498e-03, 1.3702e-02, 1.5588e-02, 1.3446e-01,\n",
      "        3.7819e-02, 1.4506e-02, 6.0715e-04, 5.1299e-03, 1.4995e-02, 2.6828e-03,\n",
      "        2.3071e-03, 5.5112e-02, 1.3968e-02, 4.1764e-02, 3.1217e-02, 1.2719e-02,\n",
      "        7.7057e-03, 4.7406e-02, 4.5802e-02, 7.7648e-05, 1.0657e-02, 7.6205e-02,\n",
      "        1.4579e-03, 6.6324e-03, 3.0986e-02, 4.0026e-02, 3.3435e-05, 5.5187e-02,\n",
      "        2.4514e-02, 3.3578e-03, 7.1158e-03, 2.9343e-02, 9.1590e-03, 3.3001e-02,\n",
      "        1.8077e-02, 4.4331e-02, 5.9624e-03, 2.9164e-02, 5.9803e-02, 1.5498e-02,\n",
      "        2.2126e-02, 2.1994e-03, 2.1017e-02, 1.1152e-02, 4.3805e-03, 1.5850e-02,\n",
      "        2.6238e-02, 6.1075e-02, 1.4413e-02, 2.0341e-02, 2.2923e-02, 3.2434e-03,\n",
      "        1.8632e-02, 1.9084e-02, 1.8219e-02, 1.1305e-02, 1.2162e-02, 7.3108e-03,\n",
      "        9.5964e-03, 3.0769e-02, 5.9491e-03, 3.5513e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0023, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0448, device='cuda:0')\n",
      "p.batch_l2: tensor([5.4477e-08, 1.1023e-05, 3.8745e-05, 9.0879e-05, 8.7449e-05, 1.7943e-03,\n",
      "        1.1640e-03, 1.2307e-04, 6.8243e-06, 5.4982e-05, 3.1379e-04, 3.9062e-05,\n",
      "        4.2608e-05, 2.9276e-04, 2.2183e-04, 6.4124e-04, 5.3239e-04, 2.3608e-04,\n",
      "        9.3253e-05, 2.0796e-04, 5.7349e-04, 1.1097e-06, 2.2029e-04, 6.7983e-04,\n",
      "        1.0831e-05, 9.2650e-05, 1.3987e-04, 1.7492e-04, 3.6938e-07, 7.9780e-04,\n",
      "        1.0154e-04, 4.1101e-05, 1.1838e-04, 7.9637e-04, 1.8300e-04, 1.1573e-04,\n",
      "        2.7184e-04, 2.7943e-04, 9.5564e-05, 1.7067e-04, 5.4058e-04, 1.0914e-04,\n",
      "        2.9678e-04, 4.9875e-05, 2.9273e-04, 1.6217e-04, 3.1016e-05, 7.9071e-05,\n",
      "        2.0950e-04, 1.4059e-03, 2.2527e-04, 3.8661e-04, 6.3541e-04, 4.5058e-05,\n",
      "        2.1247e-04, 4.3176e-04, 9.1404e-05, 7.0835e-05, 8.0098e-05, 5.6191e-05,\n",
      "        3.4003e-04, 2.4109e-04, 1.0710e-04, 2.1847e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0002, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0033, device='cuda:0')\n",
      "p.batch_l2: tensor([6.7608e-06, 2.8301e-03, 3.4116e-03, 1.9438e-02, 1.3938e-02, 1.5290e-01,\n",
      "        4.5933e-02, 1.6674e-02, 8.4896e-04, 6.3361e-03, 2.9224e-02, 5.4850e-03,\n",
      "        3.0766e-03, 1.0530e-01, 1.6583e-02, 7.1113e-02, 4.6991e-02, 1.3158e-02,\n",
      "        9.9473e-03, 5.0732e-02, 6.5907e-02, 1.4669e-04, 1.4571e-02, 1.0457e-01,\n",
      "        2.1957e-03, 9.3274e-03, 3.6768e-02, 3.3676e-02, 5.0365e-05, 7.8451e-02,\n",
      "        2.7816e-02, 3.8232e-03, 9.3647e-03, 4.2063e-02, 1.1193e-02, 3.1600e-02,\n",
      "        3.2388e-02, 5.9507e-02, 8.7179e-03, 2.1889e-02, 6.6702e-02, 2.1738e-02,\n",
      "        3.5762e-02, 3.0465e-03, 1.9413e-02, 1.6506e-02, 5.1764e-03, 1.3085e-02,\n",
      "        4.0339e-02, 6.8882e-02, 2.0659e-02, 3.3535e-02, 3.5218e-02, 4.6306e-03,\n",
      "        2.0459e-02, 3.6461e-02, 1.4399e-02, 1.0891e-02, 1.5631e-02, 9.5177e-03,\n",
      "        1.4728e-02, 4.7515e-02, 7.5046e-03, 4.4869e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.0026, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0532, device='cuda:0')\n",
      "p.batch_l2: tensor([1.0825e-08, 6.7811e-06, 6.4148e-06, 4.0259e-05, 2.2432e-05, 3.4117e-04,\n",
      "        1.6164e-04, 2.4343e-05, 1.5889e-06, 1.1317e-05, 6.9723e-05, 1.5076e-05,\n",
      "        7.6307e-06, 1.7056e-04, 3.4166e-05, 2.1008e-04, 9.5000e-05, 2.8436e-05,\n",
      "        1.8402e-05, 6.2075e-05, 1.5952e-04, 2.7561e-07, 4.9994e-05, 2.7294e-04,\n",
      "        5.5487e-06, 2.2859e-05, 5.5264e-05, 3.9204e-05, 1.0022e-07, 1.7725e-04,\n",
      "        3.6256e-05, 6.1228e-06, 1.8084e-05, 7.7211e-05, 2.9335e-05, 4.3738e-05,\n",
      "        7.8935e-05, 1.0741e-04, 1.7991e-05, 2.8492e-05, 1.3890e-04, 2.9928e-05,\n",
      "        8.8044e-05, 7.6695e-06, 3.5752e-05, 4.5810e-05, 1.3309e-05, 3.6827e-05,\n",
      "        8.1971e-05, 2.1718e-04, 6.1053e-05, 1.0784e-04, 9.6955e-05, 9.9992e-06,\n",
      "        3.8695e-05, 1.1741e-04, 1.7789e-05, 2.2566e-05, 1.9340e-05, 1.3179e-05,\n",
      "        5.4237e-05, 7.6206e-05, 2.0858e-05, 6.0028e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0001, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0026, device='cuda:0')\n",
      "p.batch_l2: tensor([9.2025e-06, 4.6445e-03, 4.1942e-03, 1.2209e-02, 2.0877e-02, 1.3361e-01,\n",
      "        5.7507e-02, 2.3152e-02, 6.0115e-04, 9.8056e-03, 1.2461e-02, 3.9473e-03,\n",
      "        4.9407e-03, 5.5808e-02, 1.2390e-02, 6.1331e-02, 2.9398e-02, 1.2234e-02,\n",
      "        8.2966e-03, 5.5144e-02, 4.1824e-02, 8.7037e-05, 1.4717e-02, 9.9925e-02,\n",
      "        2.6178e-03, 1.8623e-02, 4.5872e-02, 5.3289e-02, 4.6801e-05, 7.6178e-02,\n",
      "        3.4073e-02, 3.0203e-03, 1.0076e-02, 4.3924e-02, 9.4553e-03, 3.2312e-02,\n",
      "        1.5508e-02, 7.2687e-02, 7.7624e-03, 2.6741e-02, 4.0104e-02, 2.2479e-02,\n",
      "        2.6823e-02, 3.4815e-03, 3.3376e-02, 1.5755e-02, 8.0516e-03, 2.1280e-02,\n",
      "        3.9215e-02, 7.2411e-02, 3.1271e-02, 1.6453e-02, 5.0471e-02, 5.9693e-03,\n",
      "        2.3592e-02, 2.7657e-02, 2.5492e-02, 7.5664e-03, 1.9297e-02, 6.4946e-03,\n",
      "        1.8270e-02, 4.5481e-02, 8.2749e-03, 5.2240e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0030, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0682, device='cuda:0')\n",
      "p.batch_l2: tensor([5.0430e-09, 4.6174e-06, 4.1058e-06, 1.1708e-05, 1.9283e-05, 9.7429e-05,\n",
      "        5.7134e-05, 1.7903e-05, 5.9822e-07, 7.9975e-06, 1.3494e-05, 4.5596e-06,\n",
      "        5.1014e-06, 5.0950e-05, 1.1511e-05, 5.2331e-05, 3.4693e-05, 1.6315e-05,\n",
      "        8.0070e-06, 5.3134e-05, 3.5921e-05, 6.6647e-08, 1.8578e-05, 7.7551e-05,\n",
      "        2.5379e-06, 1.4136e-05, 3.1917e-05, 5.4983e-05, 3.2898e-08, 6.4309e-05,\n",
      "        2.6919e-05, 2.7108e-06, 8.2239e-06, 4.2513e-05, 1.2967e-05, 2.3360e-05,\n",
      "        1.6893e-05, 5.8035e-05, 6.0847e-06, 3.7601e-05, 4.6205e-05, 2.4671e-05,\n",
      "        3.2408e-05, 3.9360e-06, 2.6803e-05, 1.1454e-05, 7.1105e-06, 1.8210e-05,\n",
      "        2.4723e-05, 6.2686e-05, 4.5524e-05, 2.1955e-05, 3.8845e-05, 4.1764e-06,\n",
      "        1.8341e-05, 2.9577e-05, 2.1605e-05, 1.0427e-05, 1.5613e-05, 5.5839e-06,\n",
      "        2.2994e-05, 3.2611e-05, 8.3536e-06, 3.4373e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(7.1014e-05, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0021, device='cuda:0')\n",
      "p.batch_l2: tensor([6.6105e-06, 1.1001e-02, 1.9488e-03, 5.3654e-03, 1.4695e-02, 2.1673e-02,\n",
      "        6.9033e-03, 1.4187e-02, 6.1331e-04, 2.1691e-03, 4.1513e-03, 2.9567e-03,\n",
      "        2.4214e-03, 1.2420e-02, 1.9327e-02, 5.5457e-03, 1.1461e-02, 1.3554e-02,\n",
      "        2.2792e-03, 4.3637e-03, 1.7967e-02, 1.2390e-04, 2.9717e-03, 1.3059e-02,\n",
      "        1.2040e-03, 3.2226e-03, 1.9352e-02, 3.1689e-02, 5.3665e-05, 3.3164e-02,\n",
      "        1.1107e-02, 1.9323e-03, 2.2794e-02, 7.6468e-03, 3.7703e-03, 5.6793e-03,\n",
      "        3.1056e-03, 3.9789e-03, 6.4501e-03, 2.5305e-02, 1.8741e-02, 2.0678e-02,\n",
      "        7.3119e-03, 4.9204e-03, 3.5657e-02, 4.8172e-03, 5.9133e-03, 1.9119e-03,\n",
      "        6.1911e-02, 4.9187e-03, 5.0465e-03, 3.5231e-03, 7.0834e-03, 3.2041e-03,\n",
      "        3.8868e-02, 1.9723e-03, 5.9131e-03, 3.2602e-03, 1.1201e-02, 3.5564e-03,\n",
      "        1.5171e-03, 1.1660e-02, 1.7896e-03, 3.9828e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0026, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1049, device='cuda:0')\n",
      "p.batch_l2: tensor([2.1068e-08, 2.1173e-04, 2.4639e-05, 5.9666e-05, 2.6272e-04, 2.5776e-04,\n",
      "        2.1657e-04, 1.9701e-04, 6.1201e-06, 4.9071e-05, 8.2695e-05, 2.0810e-04,\n",
      "        2.2038e-04, 2.0318e-04, 3.1663e-04, 2.2574e-04, 2.4058e-04, 2.3341e-04,\n",
      "        4.4278e-05, 1.6671e-04, 2.4583e-04, 6.9796e-07, 9.5723e-05, 2.2335e-04,\n",
      "        8.7359e-06, 8.0292e-05, 2.1827e-04, 3.0740e-04, 2.7557e-07, 3.5295e-04,\n",
      "        2.8585e-04, 2.9575e-05, 2.9213e-04, 2.4735e-04, 2.2227e-04, 1.2088e-04,\n",
      "        2.2909e-04, 2.0816e-04, 2.2120e-04, 3.6073e-04, 2.7491e-04, 2.2832e-04,\n",
      "        1.2719e-04, 1.5489e-04, 4.0109e-04, 1.8570e-04, 2.0940e-04, 2.0337e-04,\n",
      "        3.5015e-04, 2.4748e-04, 1.5948e-04, 2.2200e-04, 1.9217e-04, 4.2707e-05,\n",
      "        3.9702e-04, 1.5216e-04, 2.2693e-04, 2.4003e-04, 2.4583e-04, 1.7810e-04,\n",
      "        1.1444e-04, 2.2059e-04, 6.8109e-05, 3.0459e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0001, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0146, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.5736, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([9.7319e-02, 5.9729e-05, 2.8939e-02, 8.6206e-02, 1.5053e-03, 3.8337e-05,\n",
      "        1.1638e-01, 4.0528e-02, 3.4056e-04, 6.0269e-04, 2.3384e-02, 5.9862e-02,\n",
      "        2.7372e-03, 6.2286e-04, 2.2491e-02, 1.0550e-02, 1.2723e-01, 1.5651e-03,\n",
      "        6.9129e-02, 3.0237e-02, 1.5922e-03, 1.5374e-02, 1.1979e-01, 2.0824e-03,\n",
      "        3.2516e-02, 2.5478e-02, 5.2132e-02, 3.9228e-04, 5.6303e-02, 9.2771e-05,\n",
      "        8.5865e-02, 3.1436e-02, 1.7034e-02, 9.8109e-02, 5.6513e-03, 7.6990e-02,\n",
      "        4.5615e-02, 9.1478e-03, 7.1596e-02, 1.4076e-02, 9.4440e-02, 2.1571e-04,\n",
      "        7.3232e-02, 5.1913e-02, 9.5053e-02, 3.4328e-07, 1.2273e-03, 1.6849e-02,\n",
      "        4.0456e-03, 6.0957e-03, 1.8249e-03, 1.1244e-02, 8.0723e-02, 7.7180e-04,\n",
      "        7.4000e-02, 2.2006e-02, 2.9853e-03, 5.4384e-02, 8.7634e-05, 1.6580e-01,\n",
      "        7.6521e-02, 8.0781e-03, 1.7496e-02, 1.1376e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.3120, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0077, device='cuda:0')\n",
      "p.batch_l2: tensor([5.3306e-04, 3.1390e-06, 4.4647e-04, 4.2746e-04, 2.0034e-05, 6.9268e-07,\n",
      "        1.7756e-03, 8.2523e-04, 1.1807e-05, 1.2918e-05, 6.0825e-04, 1.3398e-03,\n",
      "        4.3154e-05, 3.6562e-06, 1.2413e-04, 2.0589e-04, 1.4450e-03, 2.4185e-05,\n",
      "        1.0967e-03, 2.3617e-04, 1.6024e-05, 2.2847e-04, 7.9198e-04, 6.3401e-05,\n",
      "        5.0513e-04, 3.6353e-04, 4.7034e-04, 4.3614e-06, 9.7869e-04, 1.1349e-06,\n",
      "        1.2497e-03, 2.6956e-04, 1.0421e-04, 6.3756e-04, 4.7002e-05, 5.8870e-04,\n",
      "        3.4073e-04, 2.4682e-04, 9.5382e-04, 4.4579e-04, 1.6363e-03, 2.7327e-06,\n",
      "        1.1269e-03, 5.1275e-04, 1.0265e-03, 3.1527e-09, 3.5602e-05, 2.1851e-04,\n",
      "        2.5470e-05, 9.7021e-05, 3.3151e-05, 2.9885e-05, 8.3830e-04, 4.2248e-06,\n",
      "        3.3165e-03, 2.5972e-04, 5.8011e-05, 6.0221e-04, 6.5727e-07, 2.4986e-03,\n",
      "        9.5138e-04, 4.1338e-05, 3.2494e-04, 9.3579e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0231, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0018, device='cuda:0')\n",
      "p.batch_l2: tensor([1.5210e-01, 1.2123e-04, 4.5105e-02, 1.2894e-01, 2.9028e-03, 7.4768e-05,\n",
      "        1.0108e-01, 8.5867e-02, 5.5966e-04, 9.4277e-04, 3.7186e-02, 9.0902e-02,\n",
      "        4.1639e-03, 6.3667e-04, 2.7045e-02, 1.3630e-02, 2.7182e-01, 1.7545e-03,\n",
      "        6.6401e-02, 3.2984e-02, 2.1646e-03, 2.3020e-02, 2.1677e-01, 2.6279e-03,\n",
      "        4.9176e-02, 4.9391e-02, 7.8803e-02, 5.0519e-04, 9.3217e-02, 1.1133e-04,\n",
      "        9.4389e-02, 4.1450e-02, 3.2794e-02, 1.2104e-01, 4.6442e-03, 5.9987e-02,\n",
      "        6.8203e-02, 1.2430e-02, 7.8946e-02, 2.2045e-02, 9.8120e-02, 3.2688e-04,\n",
      "        8.5084e-02, 5.1943e-02, 1.2030e-01, 4.3445e-07, 2.1299e-03, 1.7265e-02,\n",
      "        6.7773e-03, 1.0915e-02, 3.5855e-03, 7.0224e-03, 1.5329e-01, 1.1176e-03,\n",
      "        1.1202e-01, 2.3612e-02, 5.0031e-03, 7.8526e-02, 1.1591e-04, 1.9847e-01,\n",
      "        1.0005e-01, 8.2273e-03, 3.1942e-02, 1.2832e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.3900, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0110, device='cuda:0')\n",
      "p.batch_l2: tensor([2.1132e-04, 4.5112e-07, 1.1220e-04, 2.5801e-04, 6.9915e-06, 2.1667e-07,\n",
      "        1.6553e-04, 2.3906e-04, 2.3010e-06, 3.1429e-06, 8.9198e-05, 2.0690e-04,\n",
      "        8.8054e-06, 1.1388e-06, 4.6938e-05, 2.8363e-05, 5.4825e-04, 5.9602e-06,\n",
      "        1.4717e-04, 4.9383e-05, 3.7669e-06, 6.3070e-05, 4.0337e-04, 9.1876e-06,\n",
      "        1.0623e-04, 1.3469e-04, 1.4016e-04, 1.2651e-06, 2.2743e-04, 2.1923e-07,\n",
      "        1.8133e-04, 1.0427e-04, 5.3042e-05, 1.7455e-04, 6.0037e-06, 1.2581e-04,\n",
      "        1.1764e-04, 3.3433e-05, 1.7966e-04, 5.4317e-05, 2.1431e-04, 6.8992e-07,\n",
      "        1.7990e-04, 1.1413e-04, 2.2595e-04, 6.9480e-10, 7.3379e-06, 2.8407e-05,\n",
      "        1.1774e-05, 2.7529e-05, 1.0918e-05, 1.0815e-05, 2.4403e-04, 2.2265e-06,\n",
      "        3.7242e-04, 5.5704e-05, 1.9020e-05, 1.3828e-04, 1.9573e-07, 3.9776e-04,\n",
      "        2.6150e-04, 2.1109e-05, 1.0880e-04, 2.2366e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0145, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0007, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.batch_l2: tensor([2.0390e-01, 7.5807e-05, 2.9673e-02, 9.0335e-02, 2.3903e-03, 7.4442e-05,\n",
      "        1.0796e-01, 4.6245e-02, 4.4461e-04, 6.5851e-04, 2.0066e-02, 9.6696e-02,\n",
      "        2.4766e-03, 9.9028e-04, 1.4844e-02, 1.4582e-02, 1.3248e-01, 1.4559e-03,\n",
      "        7.0371e-02, 3.7781e-02, 1.3798e-03, 1.5147e-02, 1.3557e-01, 2.1535e-03,\n",
      "        4.1160e-02, 4.1274e-02, 7.1333e-02, 2.5397e-04, 4.1945e-02, 7.1174e-05,\n",
      "        5.4977e-02, 4.6654e-02, 1.7926e-02, 6.4881e-02, 6.8607e-03, 4.4614e-02,\n",
      "        6.9702e-02, 1.6511e-02, 4.9069e-02, 1.2372e-02, 5.1240e-02, 3.2309e-04,\n",
      "        5.7329e-02, 2.9638e-02, 8.5086e-02, 2.3341e-07, 1.4747e-03, 1.6051e-02,\n",
      "        3.6228e-03, 7.8632e-03, 3.1023e-03, 5.4253e-03, 1.3584e-01, 6.3322e-04,\n",
      "        6.2759e-02, 2.1584e-02, 2.4204e-03, 3.9752e-02, 9.2823e-05, 1.8010e-01,\n",
      "        4.6105e-02, 1.4248e-02, 3.1244e-02, 8.3031e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.4516, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0087, device='cuda:0')\n",
      "p.batch_l2: tensor([1.5077e-04, 9.9689e-08, 3.3643e-05, 8.9908e-05, 1.8430e-06, 7.1416e-08,\n",
      "        7.9750e-05, 5.3663e-05, 3.9960e-07, 6.2820e-07, 3.2338e-05, 9.0366e-05,\n",
      "        2.3830e-06, 4.5602e-07, 2.3609e-05, 9.9041e-06, 1.4078e-04, 1.5283e-06,\n",
      "        5.8849e-05, 3.4173e-05, 1.6304e-06, 2.1583e-05, 8.4600e-05, 2.2146e-06,\n",
      "        4.4074e-05, 3.8833e-05, 5.6394e-05, 3.1851e-07, 5.5405e-05, 7.1681e-08,\n",
      "        5.6605e-05, 3.7513e-05, 1.5189e-05, 6.0626e-05, 5.9432e-06, 7.5764e-05,\n",
      "        5.4525e-05, 1.4151e-05, 7.6806e-05, 1.4592e-05, 8.9555e-05, 2.0911e-07,\n",
      "        6.7104e-05, 1.7358e-05, 9.5300e-05, 2.2231e-10, 1.5489e-06, 1.3218e-05,\n",
      "        4.4382e-06, 8.2670e-06, 2.2420e-06, 5.1083e-06, 1.0904e-04, 4.0275e-07,\n",
      "        9.8069e-05, 2.0110e-05, 3.8666e-06, 4.9890e-05, 7.1517e-08, 1.7426e-04,\n",
      "        6.9032e-05, 9.2143e-06, 4.5856e-05, 9.6361e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0123, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0003, device='cuda:0')\n",
      "p.batch_l2: tensor([2.8204e-02, 7.2313e-05, 7.1610e-03, 2.2877e-02, 1.1860e-03, 5.7344e-05,\n",
      "        6.2879e-02, 5.5987e-03, 2.3823e-04, 3.9470e-04, 1.2611e-02, 2.4471e-02,\n",
      "        1.8943e-02, 9.6503e-04, 2.0901e-02, 4.1474e-02, 3.7390e-02, 8.4267e-04,\n",
      "        5.2626e-02, 4.9913e-02, 1.1292e-03, 1.7683e-02, 1.9459e-02, 8.3642e-04,\n",
      "        1.3043e-02, 2.5733e-02, 5.2251e-02, 4.0720e-04, 6.5968e-03, 1.0140e-04,\n",
      "        5.0276e-02, 2.6748e-02, 6.9468e-03, 4.6655e-02, 1.0073e-02, 1.8823e-02,\n",
      "        6.3006e-02, 1.3125e-02, 1.1253e-02, 3.6711e-02, 2.1625e-02, 6.4956e-04,\n",
      "        1.2698e-02, 9.6454e-02, 3.2003e-02, 5.4235e-07, 9.8527e-04, 4.5853e-02,\n",
      "        2.3162e-03, 1.7197e-02, 8.0402e-04, 3.6202e-03, 7.3940e-02, 4.0637e-04,\n",
      "        1.6942e-02, 5.7921e-03, 3.7989e-03, 1.3588e-02, 1.8532e-04, 3.4881e-02,\n",
      "        1.2966e-02, 2.8693e-02, 2.9060e-02, 2.9114e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.1679, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0085, device='cuda:0')\n",
      "p.batch_l2: tensor([3.4151e-04, 5.0263e-07, 1.9246e-04, 2.8308e-04, 8.4680e-06, 3.1894e-07,\n",
      "        3.8921e-04, 2.2867e-04, 2.2333e-06, 3.4884e-06, 1.4507e-04, 3.1198e-04,\n",
      "        1.3797e-04, 2.4980e-06, 2.6614e-04, 3.1496e-04, 3.1551e-04, 6.8658e-06,\n",
      "        3.4745e-04, 3.0828e-04, 8.1204e-06, 2.4892e-04, 3.0865e-04, 9.2526e-06,\n",
      "        1.2894e-04, 2.4989e-04, 1.8435e-04, 2.1596e-06, 1.9447e-04, 3.4374e-07,\n",
      "        3.0897e-04, 2.9604e-04, 7.6383e-05, 3.2070e-04, 2.2789e-04, 2.7186e-04,\n",
      "        3.5742e-04, 1.8501e-04, 2.6063e-04, 3.3183e-04, 2.6614e-04, 1.9451e-06,\n",
      "        2.2895e-04, 3.6282e-04, 3.0730e-04, 1.2053e-09, 7.8529e-06, 3.7337e-04,\n",
      "        1.7646e-05, 2.2491e-04, 1.0914e-05, 2.3242e-05, 4.0999e-04, 1.4632e-06,\n",
      "        2.8215e-04, 1.1655e-04, 2.0898e-04, 2.3464e-04, 4.8263e-07, 3.4024e-04,\n",
      "        2.6281e-04, 2.3923e-04, 3.1902e-04, 3.8839e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0185, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0007, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.5612, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([0.0135, 0.0522, 0.0082, 0.0208, 0.0263, 0.0254, 0.0183, 0.0650, 0.0124,\n",
      "        0.0078, 0.0152, 0.0672, 0.0526, 0.0849, 0.0199, 0.0083, 0.0040, 0.0037,\n",
      "        0.0248, 0.0067, 0.0812, 0.0353, 0.1025, 0.0796, 0.0467, 0.0008, 0.0910,\n",
      "        0.0144, 0.0113, 0.0179, 0.0228, 0.0124, 0.0044, 0.0088, 0.0018, 0.0153,\n",
      "        0.0091, 0.0119, 0.0052, 0.0392, 0.1060, 0.0278, 0.0059, 0.0040, 0.0469,\n",
      "        0.0384, 0.0010, 0.0582, 0.0073, 0.0271, 0.1485, 0.0326, 0.0071, 0.0293,\n",
      "        0.0078, 0.0090, 0.0509, 0.0255, 0.0657, 0.0060, 0.0221, 0.0175, 0.0734,\n",
      "        0.0382], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1164, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2286, device='cuda:0')\n",
      "p.batch_l2: tensor([2.1150e-04, 7.4921e-04, 8.7644e-05, 1.7581e-04, 2.3924e-04, 2.9736e-04,\n",
      "        2.3926e-04, 4.1484e-04, 4.7530e-05, 6.7347e-05, 7.0645e-05, 3.8407e-04,\n",
      "        9.0166e-04, 8.5437e-04, 1.1752e-04, 1.1070e-04, 5.6744e-05, 7.2866e-05,\n",
      "        2.6191e-04, 8.5370e-05, 9.3498e-04, 2.3028e-04, 9.6647e-04, 1.6837e-03,\n",
      "        6.7313e-04, 6.3733e-06, 1.4729e-03, 8.9159e-05, 1.4017e-04, 1.2922e-04,\n",
      "        2.8046e-04, 5.8454e-05, 5.3504e-05, 6.4202e-05, 4.9304e-05, 4.6588e-04,\n",
      "        1.2818e-04, 4.4648e-04, 8.5081e-05, 1.6654e-04, 9.3284e-04, 1.9299e-04,\n",
      "        4.6104e-05, 5.3450e-05, 7.1497e-04, 3.7819e-04, 1.8591e-05, 4.4336e-04,\n",
      "        5.1364e-05, 7.9408e-04, 5.8073e-04, 2.2287e-04, 6.0506e-05, 4.0156e-04,\n",
      "        8.2955e-05, 1.1285e-04, 5.3890e-04, 2.1882e-04, 8.6061e-04, 5.7219e-05,\n",
      "        2.4274e-04, 1.1286e-04, 1.0591e-03, 2.3854e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0145, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0274, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0215, 0.0724, 0.0101, 0.0296, 0.0273, 0.0305, 0.0249, 0.0548, 0.0110,\n",
      "        0.0126, 0.0199, 0.0726, 0.0809, 0.1004, 0.0271, 0.0108, 0.0076, 0.0056,\n",
      "        0.0367, 0.0128, 0.1074, 0.0451, 0.1318, 0.1453, 0.0799, 0.0008, 0.1194,\n",
      "        0.0164, 0.0141, 0.0159, 0.0358, 0.0121, 0.0056, 0.0153, 0.0037, 0.0329,\n",
      "        0.0153, 0.0175, 0.0070, 0.1188, 0.2686, 0.0533, 0.0076, 0.0042, 0.0594,\n",
      "        0.0649, 0.0018, 0.0800, 0.0104, 0.0435, 0.1543, 0.0313, 0.0072, 0.0399,\n",
      "        0.0097, 0.0126, 0.0910, 0.0326, 0.1294, 0.0061, 0.0193, 0.0187, 0.1052,\n",
      "        0.0524], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1466, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2691, device='cuda:0')\n",
      "p.batch_l2: tensor([4.7916e-05, 1.5017e-04, 1.8013e-05, 4.5864e-05, 3.5343e-05, 5.3068e-05,\n",
      "        6.9623e-05, 4.8492e-05, 1.0464e-05, 1.8275e-05, 3.1729e-05, 9.6296e-05,\n",
      "        1.6605e-04, 1.9659e-04, 3.3476e-05, 2.1795e-05, 1.6460e-05, 1.9432e-05,\n",
      "        5.9459e-05, 1.9642e-05, 3.0489e-04, 6.9457e-05, 2.0937e-04, 3.6241e-04,\n",
      "        1.9308e-04, 1.5798e-06, 2.1636e-04, 2.1096e-05, 1.9241e-05, 2.3622e-05,\n",
      "        5.6901e-05, 2.1086e-05, 1.9097e-05, 2.8451e-05, 9.4580e-06, 1.0686e-04,\n",
      "        2.5210e-05, 7.1112e-05, 2.0729e-05, 2.0555e-04, 4.6383e-04, 1.1276e-04,\n",
      "        1.2486e-05, 9.7460e-06, 1.3646e-04, 1.3015e-04, 4.9213e-06, 1.0242e-04,\n",
      "        1.3295e-05, 1.7449e-04, 2.2723e-04, 4.7013e-05, 8.0298e-06, 6.2120e-05,\n",
      "        1.7372e-05, 2.3169e-05, 1.8798e-04, 4.1812e-05, 2.9031e-04, 1.2320e-05,\n",
      "        4.7335e-05, 3.1837e-05, 2.1510e-04, 6.5200e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0069, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0123, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0294, 0.0938, 0.0199, 0.0228, 0.0403, 0.0265, 0.0163, 0.0757, 0.0109,\n",
      "        0.0109, 0.0110, 0.0921, 0.1322, 0.0580, 0.0170, 0.0150, 0.0093, 0.0054,\n",
      "        0.0312, 0.0132, 0.1094, 0.0539, 0.1119, 0.1315, 0.0534, 0.0008, 0.0780,\n",
      "        0.0226, 0.0170, 0.0113, 0.0315, 0.0122, 0.0053, 0.0117, 0.0033, 0.0186,\n",
      "        0.0337, 0.0215, 0.0091, 0.0840, 0.2033, 0.0439, 0.0089, 0.0050, 0.0624,\n",
      "        0.0619, 0.0025, 0.0909, 0.0157, 0.0485, 0.0781, 0.0465, 0.0106, 0.0251,\n",
      "        0.0059, 0.0171, 0.0604, 0.0179, 0.0799, 0.0090, 0.0172, 0.0229, 0.0905,\n",
      "        0.0355], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.1715, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.3063, device='cuda:0')\n",
      "p.batch_l2: tensor([1.9513e-05, 1.0541e-04, 1.4172e-05, 1.9077e-05, 3.6359e-05, 2.2046e-05,\n",
      "        1.9578e-05, 9.6447e-05, 1.1176e-05, 1.1171e-05, 1.5037e-05, 6.8811e-05,\n",
      "        1.4244e-04, 6.6097e-05, 1.7169e-05, 2.1917e-05, 7.1055e-06, 5.9213e-06,\n",
      "        4.0496e-05, 1.1417e-05, 1.0542e-04, 5.4281e-05, 1.0842e-04, 1.1682e-04,\n",
      "        4.7949e-05, 9.2163e-07, 8.3343e-05, 1.4614e-05, 9.7434e-06, 1.7825e-05,\n",
      "        2.2625e-05, 1.7388e-05, 5.9144e-06, 1.0864e-05, 3.5078e-06, 2.1973e-05,\n",
      "        2.6424e-05, 1.7967e-05, 1.0563e-05, 5.6031e-05, 1.4451e-04, 3.1472e-05,\n",
      "        8.4975e-06, 4.7917e-06, 5.5019e-05, 4.2755e-05, 2.4816e-06, 1.0487e-04,\n",
      "        1.2395e-05, 4.0676e-05, 8.0682e-05, 6.2662e-05, 1.1389e-05, 2.7134e-05,\n",
      "        9.4321e-06, 1.4039e-05, 6.5131e-05, 2.9020e-05, 1.0808e-04, 7.9026e-06,\n",
      "        2.6398e-05, 2.4142e-05, 9.9891e-05, 4.2282e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0044, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0103, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0473, 0.0328, 0.0104, 0.0159, 0.0302, 0.0565, 0.0319, 0.0461, 0.0243,\n",
      "        0.0034, 0.0230, 0.0404, 0.0289, 0.0320, 0.0045, 0.0180, 0.0037, 0.0032,\n",
      "        0.0278, 0.0170, 0.0147, 0.0063, 0.0351, 0.0707, 0.0550, 0.0007, 0.0064,\n",
      "        0.0169, 0.0629, 0.0031, 0.0226, 0.0067, 0.0055, 0.0068, 0.0072, 0.0065,\n",
      "        0.0248, 0.0084, 0.0155, 0.0306, 0.0331, 0.0102, 0.0041, 0.0038, 0.0141,\n",
      "        0.0293, 0.0020, 0.0354, 0.0181, 0.0163, 0.0071, 0.0141, 0.0097, 0.0173,\n",
      "        0.0155, 0.0511, 0.0203, 0.0057, 0.0196, 0.0109, 0.0094, 0.0118, 0.0250,\n",
      "        0.0139], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.2176, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1810, device='cuda:0')\n",
      "p.batch_l2: tensor([3.4594e-04, 2.2968e-04, 2.3121e-04, 2.9822e-04, 3.0906e-04, 2.0382e-04,\n",
      "        2.8070e-04, 2.1035e-04, 1.7384e-04, 6.0937e-05, 1.9831e-04, 3.3379e-04,\n",
      "        3.1756e-04, 3.4493e-04, 2.3812e-04, 1.5581e-04, 5.1600e-05, 2.3314e-05,\n",
      "        2.6085e-04, 2.6983e-04, 3.0218e-04, 2.4182e-04, 2.9473e-04, 3.8080e-04,\n",
      "        3.5512e-04, 4.1164e-06, 2.5672e-04, 2.6226e-04, 3.0623e-04, 2.3554e-04,\n",
      "        2.0067e-04, 4.7458e-05, 2.7948e-05, 2.6497e-04, 1.1067e-04, 7.0186e-05,\n",
      "        1.4292e-04, 6.2920e-05, 1.1644e-04, 2.1985e-04, 3.3970e-04, 8.2396e-05,\n",
      "        2.1012e-04, 2.9896e-05, 1.9041e-04, 1.5120e-04, 2.3501e-05, 2.8771e-04,\n",
      "        2.5729e-04, 1.3909e-04, 2.2793e-04, 2.8561e-04, 6.2957e-05, 2.8305e-04,\n",
      "        2.5122e-04, 3.2375e-04, 3.1504e-04, 1.7380e-04, 2.8784e-04, 1.0309e-04,\n",
      "        9.8766e-05, 7.1098e-05, 2.7781e-04, 2.8913e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0186, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0152, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.5414, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([2.9141e-02, 1.7373e-02, 1.2753e-03, 3.3673e-02, 1.0099e-02, 2.5075e-02,\n",
      "        3.0237e-02, 1.9505e-02, 2.6654e-02, 1.7573e-02, 6.3824e-08, 1.1885e-02,\n",
      "        9.3350e-03, 5.7967e-02, 3.9619e-02, 5.2889e-02, 3.0965e-03, 9.3619e-04,\n",
      "        4.3639e-03, 5.8161e-02, 2.4012e-02, 2.5933e-02, 4.6483e-02, 2.8105e-02,\n",
      "        2.2290e-03, 2.7051e-03, 1.7460e-02, 1.5954e-08, 1.5835e-02, 2.8252e-02,\n",
      "        5.2244e-02, 2.6176e-03, 1.5300e-03, 4.1743e-02, 1.4685e-02, 8.9463e-03,\n",
      "        1.3246e-02, 4.1470e-02, 7.6931e-03, 4.6472e-02, 1.0644e-01, 5.1164e-02,\n",
      "        1.9995e-02, 7.4002e-03, 1.3685e-02, 2.3495e-02, 1.2561e-02, 2.8842e-02,\n",
      "        7.1272e-05, 4.0833e-03, 1.3365e-01, 1.3431e-03, 5.8024e-02, 2.0561e-01,\n",
      "        2.7814e-02, 3.3499e-02, 8.9403e-03, 1.4570e-03, 2.9494e-02, 1.4507e-02,\n",
      "        1.4245e-05, 3.6039e-02, 1.2885e-02, 3.5527e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1707, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1318, device='cuda:0')\n",
      "p.batch_l2: tensor([3.7656e-04, 7.0675e-05, 1.0962e-05, 3.2719e-04, 1.2859e-04, 1.8504e-04,\n",
      "        4.6849e-04, 1.3488e-04, 3.9721e-04, 1.9949e-04, 4.4228e-10, 1.9533e-04,\n",
      "        8.1578e-05, 5.1739e-04, 2.8063e-04, 5.2124e-04, 2.6835e-05, 5.5918e-06,\n",
      "        9.0439e-05, 3.7324e-04, 4.9948e-04, 3.4759e-04, 4.6532e-04, 4.9407e-04,\n",
      "        5.6593e-05, 8.0933e-05, 1.2511e-04, 9.9391e-11, 1.0905e-04, 3.9186e-04,\n",
      "        3.3787e-04, 1.7608e-05, 1.4801e-05, 5.4030e-04, 1.3652e-04, 9.5761e-05,\n",
      "        1.3067e-04, 1.5828e-03, 6.3937e-05, 4.5921e-04, 5.9138e-04, 4.8391e-04,\n",
      "        1.3280e-04, 8.1658e-05, 1.0779e-04, 4.1645e-04, 2.4194e-04, 2.1455e-04,\n",
      "        5.5108e-07, 4.2464e-05, 1.2890e-03, 1.8843e-05, 8.4333e-04, 1.4255e-03,\n",
      "        1.8522e-04, 4.0478e-04, 1.9013e-04, 3.3329e-05, 5.2570e-04, 4.4639e-04,\n",
      "        1.3373e-07, 2.6266e-04, 1.0828e-04, 8.1823e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0194, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0084, device='cuda:0')\n",
      "p.batch_l2: tensor([3.8120e-02, 1.3677e-02, 1.3853e-03, 8.9393e-02, 1.3429e-02, 2.1230e-02,\n",
      "        4.5953e-02, 2.8782e-02, 3.7179e-02, 3.3945e-02, 9.1486e-08, 1.2854e-02,\n",
      "        6.2960e-03, 4.8031e-02, 4.8723e-02, 5.2943e-02, 2.9062e-03, 1.5409e-03,\n",
      "        4.7142e-03, 9.0012e-02, 3.6623e-02, 2.8078e-02, 7.7563e-02, 3.6298e-02,\n",
      "        3.6463e-03, 4.1986e-03, 1.9449e-02, 2.6257e-08, 3.0354e-02, 4.0741e-02,\n",
      "        7.2724e-02, 3.3745e-03, 1.8609e-03, 5.3419e-02, 1.8678e-02, 1.0056e-02,\n",
      "        1.2360e-02, 7.2890e-02, 8.1810e-03, 5.9979e-02, 1.1140e-01, 4.6629e-02,\n",
      "        1.8698e-02, 8.4668e-03, 2.2984e-02, 2.8801e-02, 1.2089e-02, 2.2785e-02,\n",
      "        8.5942e-05, 3.4070e-03, 2.1071e-01, 1.5942e-03, 1.1694e-01, 1.8272e-01,\n",
      "        4.2357e-02, 3.5796e-02, 1.2923e-02, 3.1638e-03, 2.6825e-02, 2.0566e-02,\n",
      "        1.9039e-05, 4.9801e-02, 1.5562e-02, 4.5628e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1952, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1169, device='cuda:0')\n",
      "p.batch_l2: tensor([9.6447e-05, 3.0856e-05, 2.5654e-06, 2.1228e-04, 5.4194e-05, 3.0663e-05,\n",
      "        1.3817e-04, 4.2134e-05, 8.2460e-05, 6.3805e-05, 1.8193e-10, 2.8956e-05,\n",
      "        1.4938e-05, 1.0314e-04, 1.1173e-04, 1.5601e-04, 6.2542e-06, 2.7808e-06,\n",
      "        1.0762e-05, 2.5072e-04, 7.8062e-05, 4.7757e-05, 2.2913e-04, 9.3642e-05,\n",
      "        6.4094e-06, 1.1766e-05, 3.2987e-05, 5.0153e-11, 5.4303e-05, 1.0501e-04,\n",
      "        1.6673e-04, 3.8678e-06, 4.6574e-06, 9.1629e-05, 3.7128e-05, 2.1097e-05,\n",
      "        2.0796e-05, 2.7763e-04, 1.0482e-05, 1.3271e-04, 2.5480e-04, 1.1719e-04,\n",
      "        4.7978e-05, 1.2401e-05, 4.3785e-05, 1.0601e-04, 3.1401e-05, 6.1064e-05,\n",
      "        1.7851e-07, 4.8496e-06, 5.1356e-04, 2.8404e-06, 3.2538e-04, 3.2643e-04,\n",
      "        1.0306e-04, 9.0354e-05, 2.9387e-05, 7.0134e-06, 6.2757e-05, 8.6721e-05,\n",
      "        4.3378e-08, 6.1129e-05, 3.2464e-05, 1.0173e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0098, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0056, device='cuda:0')\n",
      "p.batch_l2: tensor([2.5798e-02, 1.4812e-02, 1.7055e-03, 8.7340e-02, 7.6902e-03, 4.3929e-02,\n",
      "        6.9705e-02, 1.9425e-02, 3.7133e-02, 2.3998e-02, 7.9231e-08, 1.6039e-02,\n",
      "        8.8981e-03, 3.9241e-02, 3.1218e-02, 4.4783e-02, 3.8506e-03, 1.0030e-03,\n",
      "        7.2178e-03, 6.2679e-02, 2.9935e-02, 1.9759e-02, 4.6765e-02, 1.9975e-02,\n",
      "        1.0055e-02, 6.2033e-03, 1.2535e-02, 1.6088e-08, 4.3342e-02, 2.1264e-02,\n",
      "        5.6207e-02, 6.8174e-03, 7.4972e-04, 7.1772e-02, 1.4702e-02, 7.6960e-03,\n",
      "        2.0874e-02, 3.6087e-02, 1.2957e-02, 5.1209e-02, 1.2075e-01, 7.6915e-02,\n",
      "        2.0493e-02, 1.5978e-02, 2.6102e-02, 1.4499e-02, 1.6018e-02, 1.6641e-02,\n",
      "        8.2272e-05, 3.1112e-03, 1.6630e-01, 1.0935e-03, 1.2246e-01, 1.5821e-01,\n",
      "        4.2442e-02, 4.3121e-02, 1.5872e-02, 1.9105e-03, 2.2721e-02, 1.5864e-02,\n",
      "        1.6482e-05, 6.0097e-02, 1.0059e-02, 3.0011e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.1606, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1217, device='cuda:0')\n",
      "p.batch_l2: tensor([4.3749e-05, 1.9637e-05, 1.9255e-06, 6.8314e-05, 2.1154e-05, 4.0311e-05,\n",
      "        6.9999e-05, 1.8479e-05, 3.8482e-05, 2.1773e-05, 5.2396e-11, 1.5304e-05,\n",
      "        7.9797e-06, 5.0319e-05, 4.7667e-05, 6.1332e-05, 3.6954e-06, 1.4378e-06,\n",
      "        1.2576e-05, 9.4867e-05, 3.3047e-05, 2.9804e-05, 1.0252e-04, 3.3239e-05,\n",
      "        5.3796e-06, 6.0083e-06, 1.9245e-05, 1.1872e-11, 3.4956e-05, 2.8715e-05,\n",
      "        9.4722e-05, 6.2294e-06, 1.0169e-06, 4.0522e-05, 1.3015e-05, 1.2344e-05,\n",
      "        1.7761e-05, 4.5736e-05, 8.6441e-06, 7.2469e-05, 1.2248e-04, 7.4576e-05,\n",
      "        2.8828e-05, 6.5364e-06, 2.1959e-05, 2.7248e-05, 2.7117e-05, 2.9383e-05,\n",
      "        7.3291e-08, 4.6148e-06, 1.7121e-04, 1.4385e-06, 7.4965e-05, 1.4913e-04,\n",
      "        3.9242e-05, 5.1406e-05, 1.3583e-05, 1.9515e-06, 5.7331e-05, 3.9032e-05,\n",
      "        1.6884e-08, 6.9519e-05, 1.4787e-05, 4.0453e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0066, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0044, device='cuda:0')\n",
      "p.batch_l2: tensor([2.4851e-02, 5.3242e-03, 1.4543e-03, 1.1574e-02, 6.6595e-04, 6.2744e-03,\n",
      "        8.8617e-03, 9.3449e-03, 1.0502e-02, 2.7061e-03, 7.5495e-08, 8.2891e-05,\n",
      "        1.0767e-02, 2.8521e-03, 1.5479e-03, 4.5213e-02, 3.9694e-03, 4.0641e-04,\n",
      "        9.1300e-03, 3.1227e-02, 6.6855e-03, 4.5324e-03, 4.3001e-03, 1.7208e-03,\n",
      "        5.0965e-03, 1.0307e-02, 3.0494e-03, 2.5311e-08, 6.8190e-03, 3.0826e-03,\n",
      "        3.3235e-03, 6.8062e-03, 2.7628e-04, 1.3172e-02, 3.2800e-03, 1.8273e-02,\n",
      "        4.7592e-03, 3.3720e-03, 6.8753e-03, 2.3684e-03, 1.2989e-02, 9.0663e-03,\n",
      "        7.3085e-04, 1.1849e-02, 9.9612e-03, 3.8002e-03, 1.0456e-03, 8.0655e-03,\n",
      "        3.2923e-05, 5.5486e-03, 3.1980e-02, 1.6645e-03, 1.2045e-02, 5.0356e-02,\n",
      "        1.0970e-02, 2.7112e-02, 6.8317e-03, 1.8368e-03, 1.9484e-03, 1.5785e-03,\n",
      "        1.2961e-05, 1.9023e-02, 1.6963e-02, 9.7835e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.1576, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0730, device='cuda:0')\n",
      "p.batch_l2: tensor([2.6421e-04, 5.8362e-05, 1.7408e-05, 2.8800e-04, 2.3332e-04, 2.4504e-04,\n",
      "        2.9121e-04, 2.1455e-04, 2.5355e-04, 2.4451e-04, 2.2616e-10, 2.1622e-04,\n",
      "        2.1328e-04, 2.3304e-04, 2.2675e-04, 4.0173e-04, 1.8569e-04, 6.1967e-06,\n",
      "        1.8696e-04, 3.4113e-04, 1.4765e-04, 1.2361e-04, 2.5737e-04, 1.5637e-04,\n",
      "        1.7443e-04, 2.4869e-04, 1.0653e-04, 5.5470e-11, 2.6770e-04, 2.4131e-04,\n",
      "        2.6760e-04, 1.8162e-04, 3.6747e-06, 2.7946e-04, 3.8643e-05, 2.3850e-04,\n",
      "        2.1950e-04, 1.8770e-04, 1.5676e-04, 2.5364e-04, 3.1505e-04, 2.7882e-04,\n",
      "        2.0159e-04, 1.0694e-04, 2.2108e-04, 1.3418e-04, 1.6479e-04, 2.0840e-04,\n",
      "        2.6652e-07, 1.9139e-04, 4.3710e-04, 1.8262e-05, 2.8406e-04, 4.6518e-04,\n",
      "        2.7674e-04, 2.5661e-04, 2.0018e-04, 1.6795e-05, 2.2851e-04, 1.7292e-04,\n",
      "        7.8056e-08, 1.6524e-04, 2.2428e-04, 1.9597e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0163, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0076, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.4862, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([0.0246, 0.0220, 0.0910, 0.0866, 0.0263, 0.0359, 0.0136, 0.0514, 0.0065,\n",
      "        0.0293, 0.0379, 0.0076, 0.0025, 0.0478, 0.0006, 0.0258, 0.0290, 0.0644,\n",
      "        0.0164, 0.0013, 0.0464, 0.0041, 0.0440, 0.0163, 0.0160, 0.0688, 0.0269,\n",
      "        0.0004, 0.0097, 0.0231, 0.0070, 0.0043, 0.0323, 0.0025, 0.0473, 0.0095,\n",
      "        0.0994, 0.0137, 0.0085, 0.0329, 0.0129, 0.0091, 0.0023, 0.0066, 0.0071,\n",
      "        0.0683, 0.0113, 0.0040, 0.0208, 0.0433, 0.0130, 0.0655, 0.0061, 0.0134,\n",
      "        0.0445, 0.0337, 0.0288, 0.0197, 0.0077, 0.0271, 0.0084, 0.0203, 0.0090,\n",
      "        0.0203], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1569, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1484, device='cuda:0')\n",
      "p.batch_l2: tensor([2.8365e-04, 2.0343e-04, 7.0024e-04, 9.7716e-04, 3.1993e-04, 3.7811e-04,\n",
      "        3.9920e-04, 8.7226e-04, 2.6584e-04, 6.2111e-04, 4.1106e-04, 3.2960e-04,\n",
      "        1.2786e-04, 2.7336e-04, 4.3821e-06, 1.8159e-04, 3.5629e-04, 6.5714e-04,\n",
      "        2.7866e-04, 2.7851e-05, 2.3765e-04, 2.8139e-05, 5.4074e-04, 1.9681e-04,\n",
      "        1.0856e-04, 6.1512e-04, 1.5507e-04, 4.3240e-06, 7.3579e-05, 2.2152e-04,\n",
      "        4.6152e-05, 2.6965e-05, 2.6144e-04, 1.2952e-05, 5.5317e-04, 1.5841e-04,\n",
      "        1.4278e-03, 1.2956e-04, 1.0733e-04, 2.4674e-04, 1.0656e-04, 1.8513e-04,\n",
      "        2.5028e-05, 1.7017e-04, 5.7259e-05, 1.4898e-03, 1.4103e-04, 3.7004e-05,\n",
      "        3.2009e-04, 3.4777e-04, 2.6878e-04, 9.8086e-04, 8.1905e-05, 1.3800e-04,\n",
      "        3.6941e-04, 1.5024e-03, 2.3029e-04, 2.5287e-04, 1.5790e-04, 7.8117e-04,\n",
      "        1.0043e-04, 1.4946e-04, 2.2416e-04, 5.4334e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0168, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0143, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0391, 0.0250, 0.0763, 0.1080, 0.0296, 0.0360, 0.0232, 0.0792, 0.0092,\n",
      "        0.0347, 0.0466, 0.0168, 0.0055, 0.0456, 0.0006, 0.0349, 0.0428, 0.0618,\n",
      "        0.0310, 0.0016, 0.0347, 0.0047, 0.0451, 0.0268, 0.0139, 0.0669, 0.0319,\n",
      "        0.0007, 0.0216, 0.0173, 0.0084, 0.0055, 0.0289, 0.0028, 0.0759, 0.0148,\n",
      "        0.1456, 0.0176, 0.0134, 0.0349, 0.0246, 0.0133, 0.0023, 0.0091, 0.0084,\n",
      "        0.1286, 0.0147, 0.0047, 0.0332, 0.0318, 0.0176, 0.1237, 0.0063, 0.0170,\n",
      "        0.0512, 0.0595, 0.0508, 0.0128, 0.0132, 0.0484, 0.0192, 0.0247, 0.0111,\n",
      "        0.0307], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1978, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1580, device='cuda:0')\n",
      "p.batch_l2: tensor([9.5930e-05, 3.2293e-05, 1.5389e-04, 1.2597e-04, 5.5388e-05, 7.7074e-05,\n",
      "        7.6820e-05, 1.7955e-04, 3.3658e-05, 7.9838e-05, 9.8861e-05, 5.3956e-05,\n",
      "        2.0599e-05, 6.6277e-05, 1.2807e-06, 6.8380e-05, 8.2812e-05, 1.5745e-04,\n",
      "        9.4100e-05, 4.9649e-06, 5.6908e-05, 7.1560e-06, 7.8735e-05, 8.1754e-05,\n",
      "        2.5952e-05, 1.4740e-04, 4.9908e-05, 9.9370e-07, 3.2111e-05, 4.1797e-05,\n",
      "        1.7566e-05, 9.0193e-06, 5.7586e-05, 4.8097e-06, 1.6171e-04, 3.3551e-05,\n",
      "        2.3522e-04, 3.4734e-05, 2.8970e-05, 5.4655e-05, 5.5977e-05, 3.7978e-05,\n",
      "        5.5085e-06, 2.9214e-05, 1.4772e-05, 3.1720e-04, 3.0237e-05, 9.8796e-06,\n",
      "        7.5738e-05, 6.6384e-05, 4.7825e-05, 2.4158e-04, 1.2260e-05, 3.5235e-05,\n",
      "        7.5246e-05, 2.2217e-04, 9.4053e-05, 2.3254e-05, 2.8136e-05, 2.1428e-04,\n",
      "        4.2132e-05, 4.3580e-05, 4.4168e-05, 9.1051e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0098, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0057, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0153, 0.0206, 0.0484, 0.0252, 0.0143, 0.0209, 0.0093, 0.0195, 0.0063,\n",
      "        0.0218, 0.0138, 0.0133, 0.0026, 0.0432, 0.0007, 0.0243, 0.0238, 0.0669,\n",
      "        0.0144, 0.0012, 0.0475, 0.0053, 0.0189, 0.0156, 0.0133, 0.0319, 0.0158,\n",
      "        0.0003, 0.0131, 0.0116, 0.0051, 0.0067, 0.0125, 0.0010, 0.0280, 0.0059,\n",
      "        0.0858, 0.0084, 0.0054, 0.0231, 0.0144, 0.0110, 0.0018, 0.0074, 0.0078,\n",
      "        0.0495, 0.0078, 0.0015, 0.0150, 0.0258, 0.0046, 0.0431, 0.0077, 0.0103,\n",
      "        0.0361, 0.0347, 0.0209, 0.0098, 0.0094, 0.0314, 0.0096, 0.0118, 0.0103,\n",
      "        0.0178], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.1239, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1434, device='cuda:0')\n",
      "p.batch_l2: tensor([4.2959e-05, 3.6299e-05, 9.1130e-05, 6.4433e-05, 2.3294e-05, 2.8298e-05,\n",
      "        2.0859e-05, 3.7532e-05, 9.7390e-06, 4.0643e-05, 3.0903e-05, 1.4642e-05,\n",
      "        5.6743e-06, 7.3773e-05, 9.0676e-07, 3.7575e-05, 3.6078e-05, 1.1194e-04,\n",
      "        3.0896e-05, 1.3937e-06, 5.1012e-05, 7.5320e-06, 3.3663e-05, 1.8273e-05,\n",
      "        2.5686e-05, 4.8471e-05, 2.8239e-05, 4.8621e-07, 1.8880e-05, 3.2116e-05,\n",
      "        1.0037e-05, 9.5109e-06, 2.5676e-05, 1.9899e-06, 5.5060e-05, 9.4630e-06,\n",
      "        1.2319e-04, 1.4385e-05, 9.3495e-06, 2.8658e-05, 1.2916e-05, 1.6398e-05,\n",
      "        3.4562e-06, 1.2089e-05, 1.1879e-05, 8.0070e-05, 1.3120e-05, 3.4830e-06,\n",
      "        1.8421e-05, 5.6685e-05, 1.2288e-05, 7.4888e-05, 1.6170e-05, 1.3502e-05,\n",
      "        4.5211e-05, 6.1527e-05, 3.0180e-05, 3.3609e-05, 9.5992e-06, 5.6178e-05,\n",
      "        9.3571e-06, 1.6587e-05, 1.5086e-05, 5.1002e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0066, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0060, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0091, 0.0020, 0.0057, 0.0047, 0.0059, 0.0356, 0.0022, 0.0072, 0.0028,\n",
      "        0.0024, 0.0072, 0.0037, 0.0010, 0.0091, 0.0009, 0.0104, 0.0025, 0.0046,\n",
      "        0.0042, 0.0005, 0.0082, 0.0143, 0.0008, 0.0140, 0.0048, 0.0442, 0.0030,\n",
      "        0.0003, 0.0078, 0.0047, 0.0002, 0.0014, 0.0052, 0.0006, 0.0120, 0.0045,\n",
      "        0.0253, 0.0130, 0.0021, 0.0026, 0.0024, 0.0045, 0.0014, 0.0020, 0.0107,\n",
      "        0.0236, 0.0012, 0.0011, 0.0093, 0.0066, 0.0007, 0.0038, 0.0046, 0.0047,\n",
      "        0.0185, 0.0045, 0.0035, 0.0017, 0.0040, 0.0058, 0.0086, 0.0184, 0.0025,\n",
      "        0.0079], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0955, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0450, device='cuda:0')\n",
      "p.batch_l2: tensor([2.8790e-04, 2.4608e-04, 2.5893e-04, 2.6714e-04, 8.9171e-05, 3.2715e-04,\n",
      "        2.4465e-04, 2.6250e-04, 3.9237e-05, 2.2653e-04, 1.4433e-04, 4.6917e-05,\n",
      "        1.6049e-05, 2.6052e-04, 5.6902e-06, 2.2516e-04, 1.6724e-04, 2.7718e-04,\n",
      "        1.7638e-04, 5.4414e-06, 2.7587e-04, 1.1965e-04, 2.4558e-04, 2.6890e-04,\n",
      "        1.2276e-04, 3.4247e-04, 1.0022e-04, 2.8516e-06, 5.9320e-05, 1.6392e-04,\n",
      "        1.9548e-04, 1.9619e-04, 7.2393e-05, 9.1677e-06, 2.8316e-04, 5.6027e-05,\n",
      "        3.0789e-04, 2.1604e-04, 4.8176e-05, 1.7267e-04, 4.9714e-05, 2.1515e-04,\n",
      "        2.0500e-05, 3.7887e-05, 2.6460e-04, 2.5333e-04, 1.8987e-04, 1.6040e-05,\n",
      "        1.9807e-04, 2.1543e-04, 2.3546e-04, 2.5646e-04, 1.0613e-04, 1.7585e-04,\n",
      "        2.2198e-04, 2.0192e-04, 1.6959e-04, 1.5530e-04, 1.0059e-04, 1.6048e-04,\n",
      "        1.6089e-04, 1.7266e-04, 4.8796e-05, 2.3536e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0170, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0157, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.4579, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.batch_l2: tensor([7.7848e-02, 1.1092e-01, 4.8946e-02, 6.5613e-02, 2.0300e-04, 1.0054e-02,\n",
      "        3.2271e-02, 1.0447e-02, 4.5113e-02, 7.1345e-02, 5.2239e-02, 4.3785e-04,\n",
      "        2.7274e-03, 2.3618e-02, 1.1333e-01, 1.7341e-01, 7.2713e-02, 5.3002e-02,\n",
      "        2.1560e-03, 2.9518e-03, 5.2703e-02, 5.5708e-04, 3.0972e-03, 7.2148e-02,\n",
      "        4.7890e-02, 4.6984e-02, 1.1076e-03, 3.2745e-02, 9.5706e-02, 1.5255e-02,\n",
      "        3.7504e-02, 4.9093e-02, 8.3660e-03, 1.4790e-02, 8.2007e-04, 2.9334e-02,\n",
      "        6.3067e-02, 4.6581e-02, 1.5536e-01, 6.1077e-02, 1.7361e-03, 7.9676e-02,\n",
      "        5.7867e-03, 1.1526e-02, 4.3187e-02, 5.8155e-02, 1.2139e-03, 2.1445e-02,\n",
      "        2.9780e-02, 3.7664e-03, 1.2019e-04, 3.5834e-02, 7.2757e-02, 1.5598e-01,\n",
      "        2.1519e-02, 2.2073e-02, 7.4097e-03, 2.6203e-03, 4.3304e-02, 1.8240e-02,\n",
      "        1.2294e-02, 1.9145e-02, 4.1719e-04, 2.0768e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.2790, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.3330, device='cuda:0')\n",
      "p.batch_l2: tensor([1.0229e-03, 1.9017e-03, 6.8923e-04, 7.5062e-04, 1.8491e-06, 2.8195e-04,\n",
      "        1.8069e-04, 1.7772e-04, 3.8397e-04, 6.1441e-04, 1.4060e-03, 2.7106e-06,\n",
      "        7.7746e-05, 3.2427e-04, 1.4016e-03, 1.5583e-03, 5.7752e-04, 4.6689e-04,\n",
      "        1.4865e-05, 4.2955e-05, 5.7983e-04, 1.1564e-05, 2.7037e-05, 1.8236e-03,\n",
      "        6.4080e-04, 6.0103e-04, 8.7653e-06, 1.7558e-04, 9.4931e-04, 2.4597e-04,\n",
      "        1.3152e-04, 3.5484e-04, 7.5708e-05, 5.0514e-04, 1.1482e-05, 4.2044e-04,\n",
      "        7.1014e-04, 6.2052e-04, 1.8763e-03, 1.3952e-03, 3.4871e-05, 1.1072e-03,\n",
      "        3.9057e-05, 9.1003e-05, 9.6541e-04, 4.6439e-04, 3.0447e-05, 2.4175e-04,\n",
      "        7.1473e-04, 4.4792e-05, 3.6552e-06, 1.8574e-04, 6.5173e-04, 1.4105e-03,\n",
      "        2.5446e-04, 3.2541e-04, 1.1048e-04, 6.8602e-05, 6.7836e-04, 6.2370e-04,\n",
      "        9.3955e-05, 6.8265e-04, 3.9397e-06, 2.6763e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0320, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0436, device='cuda:0')\n",
      "p.batch_l2: tensor([1.6713e-01, 1.7669e-01, 7.5768e-02, 7.7389e-02, 1.7383e-04, 1.4978e-02,\n",
      "        4.6190e-02, 1.5607e-02, 3.5345e-02, 6.7480e-02, 5.9463e-02, 6.4686e-04,\n",
      "        3.3974e-03, 3.4031e-02, 2.1649e-01, 2.9821e-01, 6.4495e-02, 5.3944e-02,\n",
      "        2.8846e-03, 4.4635e-03, 6.9260e-02, 9.9136e-04, 3.2002e-03, 9.7292e-02,\n",
      "        6.8073e-02, 8.0977e-02, 1.0699e-03, 4.1739e-02, 9.7041e-02, 2.1766e-02,\n",
      "        3.6057e-02, 7.1197e-02, 8.9602e-03, 2.6246e-02, 7.0574e-04, 3.5526e-02,\n",
      "        1.1706e-01, 5.5243e-02, 1.5953e-01, 1.0034e-01, 2.2848e-03, 1.4136e-01,\n",
      "        6.4933e-03, 1.2385e-02, 6.8218e-02, 5.9264e-02, 2.1470e-03, 3.4725e-02,\n",
      "        5.4095e-02, 4.0360e-03, 1.8728e-04, 3.9700e-02, 1.2643e-01, 1.9247e-01,\n",
      "        2.2686e-02, 3.2156e-02, 7.8700e-03, 3.0257e-03, 5.9581e-02, 3.1357e-02,\n",
      "        1.7939e-02, 3.4913e-02, 3.7072e-04, 2.4423e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.4088, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.4203, device='cuda:0')\n",
      "p.batch_l2: tensor([2.9315e-04, 5.1595e-04, 1.6711e-04, 1.4634e-04, 3.7117e-07, 3.1114e-05,\n",
      "        9.1743e-05, 4.3672e-05, 6.4177e-05, 1.3408e-04, 1.4742e-04, 1.2749e-06,\n",
      "        1.0913e-05, 6.0069e-05, 4.7772e-04, 6.5158e-04, 1.1968e-04, 1.4622e-04,\n",
      "        5.9303e-06, 1.1631e-05, 1.4806e-04, 3.6368e-06, 5.7083e-06, 2.8040e-04,\n",
      "        1.7538e-04, 1.8427e-04, 2.0418e-06, 6.6318e-05, 1.9054e-04, 5.0524e-05,\n",
      "        6.7999e-05, 1.3396e-04, 1.4600e-05, 7.4245e-05, 2.5105e-06, 8.8289e-05,\n",
      "        2.9587e-04, 1.3852e-04, 3.9572e-04, 2.3557e-04, 9.2118e-06, 4.4869e-04,\n",
      "        1.3735e-05, 2.4957e-05, 1.4266e-04, 1.0216e-04, 9.4592e-06, 8.5409e-05,\n",
      "        1.4515e-04, 5.0780e-06, 6.0392e-07, 6.5657e-05, 2.5588e-04, 3.6674e-04,\n",
      "        4.3414e-05, 8.1781e-05, 1.6811e-05, 9.0304e-06, 1.4476e-04, 8.9176e-05,\n",
      "        3.0822e-05, 9.8662e-05, 4.7109e-07, 5.2027e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0171, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0227, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0889, 0.0688, 0.0263, 0.0485, 0.0002, 0.0090, 0.0239, 0.0082, 0.0244,\n",
      "        0.0476, 0.0394, 0.0003, 0.0038, 0.0201, 0.0454, 0.1582, 0.0415, 0.0228,\n",
      "        0.0011, 0.0051, 0.0470, 0.0006, 0.0018, 0.0398, 0.0292, 0.0499, 0.0008,\n",
      "        0.0153, 0.0314, 0.0173, 0.0252, 0.0328, 0.0074, 0.0174, 0.0007, 0.0207,\n",
      "        0.0568, 0.0268, 0.0708, 0.0769, 0.0018, 0.0497, 0.0042, 0.0052, 0.0370,\n",
      "        0.0200, 0.0014, 0.0093, 0.0264, 0.0048, 0.0002, 0.0145, 0.0472, 0.0978,\n",
      "        0.0219, 0.0190, 0.0091, 0.0038, 0.0376, 0.0271, 0.0068, 0.0292, 0.0004,\n",
      "        0.0277], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.2981, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2623, device='cuda:0')\n",
      "p.batch_l2: tensor([9.6059e-05, 1.3370e-04, 3.3890e-05, 5.1583e-05, 1.7060e-07, 1.2762e-05,\n",
      "        3.3393e-05, 1.4512e-05, 5.6690e-05, 4.9667e-05, 5.2202e-05, 3.2147e-07,\n",
      "        4.3668e-06, 2.0081e-05, 7.8779e-05, 1.6256e-04, 4.3970e-05, 5.6617e-05,\n",
      "        1.5605e-06, 4.6467e-06, 4.5510e-05, 6.0345e-07, 2.8314e-06, 6.5734e-05,\n",
      "        4.7803e-05, 6.5439e-05, 8.6328e-07, 1.9117e-05, 5.9543e-05, 2.2594e-05,\n",
      "        4.5541e-05, 4.9874e-05, 6.2937e-06, 2.2435e-05, 6.8852e-07, 2.9337e-05,\n",
      "        6.2549e-05, 3.8554e-05, 9.9370e-05, 1.3076e-04, 2.0295e-06, 1.0875e-04,\n",
      "        5.3035e-06, 9.3267e-06, 5.0935e-05, 4.4654e-05, 1.9277e-06, 2.0653e-05,\n",
      "        4.4979e-05, 3.7914e-06, 2.9871e-07, 2.6639e-05, 5.3071e-05, 1.1724e-04,\n",
      "        2.7882e-05, 2.8750e-05, 9.3104e-06, 5.1509e-06, 5.1336e-05, 3.0754e-05,\n",
      "        9.1281e-06, 4.5628e-05, 3.2323e-07, 4.5700e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0098, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0116, device='cuda:0')\n",
      "p.batch_l2: tensor([0.0421, 0.0075, 0.0147, 0.0519, 0.0002, 0.0054, 0.0089, 0.0091, 0.0129,\n",
      "        0.0039, 0.0097, 0.0002, 0.0014, 0.0021, 0.0064, 0.0261, 0.0255, 0.0066,\n",
      "        0.0013, 0.0029, 0.0129, 0.0002, 0.0021, 0.0289, 0.0153, 0.0065, 0.0014,\n",
      "        0.0174, 0.0118, 0.0029, 0.0186, 0.0207, 0.0041, 0.0076, 0.0003, 0.0053,\n",
      "        0.0145, 0.0206, 0.0234, 0.0117, 0.0006, 0.0110, 0.0058, 0.0060, 0.0556,\n",
      "        0.0078, 0.0005, 0.0150, 0.0052, 0.0020, 0.0001, 0.0032, 0.0650, 0.0453,\n",
      "        0.0094, 0.0020, 0.0050, 0.0013, 0.0334, 0.0007, 0.0059, 0.0103, 0.0003,\n",
      "        0.0183], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.2053, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0866, device='cuda:0')\n",
      "p.batch_l2: tensor([3.1694e-04, 2.7051e-04, 2.8770e-04, 2.9628e-04, 7.7287e-07, 2.3636e-04,\n",
      "        2.5699e-04, 1.9252e-04, 2.5963e-04, 2.1646e-04, 1.2495e-04, 1.1338e-06,\n",
      "        1.2998e-05, 1.6574e-04, 2.6607e-04, 2.9937e-04, 1.4515e-04, 1.7949e-04,\n",
      "        5.8166e-06, 1.6141e-04, 2.5404e-04, 2.3321e-06, 2.8881e-05, 3.1552e-04,\n",
      "        2.6843e-04, 1.6181e-04, 4.9612e-06, 7.6053e-05, 2.8082e-04, 1.9598e-04,\n",
      "        1.9880e-04, 2.5495e-04, 1.2146e-04, 2.3765e-04, 2.5606e-06, 1.6123e-04,\n",
      "        2.8018e-04, 2.3183e-04, 2.7690e-04, 2.5273e-04, 7.6265e-06, 2.7421e-04,\n",
      "        5.2489e-05, 7.5422e-05, 3.0280e-04, 1.8244e-04, 6.9453e-06, 2.3872e-04,\n",
      "        2.1259e-04, 1.3110e-05, 9.8519e-07, 8.3475e-05, 3.7565e-04, 3.2870e-04,\n",
      "        1.3885e-04, 1.7692e-04, 2.3815e-04, 1.6584e-05, 1.6353e-04, 2.2750e-04,\n",
      "        4.7464e-05, 2.6079e-04, 1.9632e-06, 2.8954e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0178, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0164, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.7925, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([1.0338e-02, 1.4481e-03, 2.5071e-02, 5.8334e-03, 3.2208e-02, 1.8308e-02,\n",
      "        6.5462e-04, 7.6408e-03, 1.4360e-02, 8.0829e-03, 6.8842e-03, 2.3400e-03,\n",
      "        4.2314e-03, 4.3573e-03, 6.6741e-02, 9.2591e-03, 9.0538e-02, 7.7077e-03,\n",
      "        1.7368e-01, 2.8884e-02, 1.7963e-03, 7.7480e-03, 3.8952e-02, 1.2057e-02,\n",
      "        1.1350e-02, 6.9264e-03, 7.6770e-03, 3.9770e-03, 2.0287e-03, 7.0509e-02,\n",
      "        4.2000e-03, 1.4505e-04, 1.4254e-02, 5.9504e-02, 1.9510e-02, 1.9421e-03,\n",
      "        7.1840e-02, 1.4452e-05, 1.2382e-01, 1.9484e-02, 3.9791e-02, 1.0945e-01,\n",
      "        1.3084e-02, 4.5946e-02, 1.2172e-01, 5.2140e-03, 1.1108e-02, 2.5280e-02,\n",
      "        2.2489e-02, 1.5197e-02, 6.0664e-03, 4.0352e-02, 2.0301e-02, 1.6991e-02,\n",
      "        3.3561e-02, 1.2498e-02, 1.2825e-02, 4.0242e-02, 1.5930e-02, 7.5309e-03,\n",
      "        2.1363e-03, 1.3314e-02, 2.5860e-02, 6.1164e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.1017, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0381, device='cuda:0')\n",
      "p.batch_l2: tensor([6.2918e-05, 1.6933e-05, 5.4198e-04, 2.9487e-05, 9.7569e-04, 4.1170e-04,\n",
      "        8.2527e-06, 8.0108e-05, 1.5927e-04, 1.2414e-04, 1.0999e-04, 2.2328e-05,\n",
      "        8.8765e-05, 6.3453e-05, 6.3997e-04, 1.2357e-04, 1.3668e-03, 5.1647e-05,\n",
      "        1.7886e-03, 1.5259e-03, 2.1686e-05, 8.5345e-05, 1.2020e-03, 4.9660e-04,\n",
      "        1.0484e-04, 4.8375e-05, 8.8954e-05, 5.2756e-05, 1.7335e-05, 1.5790e-03,\n",
      "        6.6624e-05, 1.2596e-06, 2.8586e-04, 5.2778e-04, 1.3985e-04, 1.4877e-05,\n",
      "        4.2299e-04, 1.8432e-07, 6.4012e-04, 1.9431e-04, 4.7213e-04, 1.1180e-03,\n",
      "        1.4649e-04, 1.0746e-03, 7.8757e-04, 8.4232e-05, 7.5526e-05, 8.2003e-04,\n",
      "        2.3917e-04, 8.0359e-04, 9.2401e-05, 3.5338e-04, 9.0200e-05, 9.1872e-05,\n",
      "        4.3057e-04, 1.3634e-04, 1.2688e-04, 5.0861e-04, 4.0970e-04, 1.2966e-04,\n",
      "        2.9638e-05, 1.1695e-04, 9.7407e-04, 1.2643e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0079, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0041, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2671e-02, 2.5451e-03, 3.5130e-02, 5.8248e-03, 4.7630e-02, 4.0148e-02,\n",
      "        7.1159e-04, 1.4585e-02, 1.2594e-02, 6.4080e-03, 8.0401e-03, 2.3531e-03,\n",
      "        6.1583e-03, 6.1635e-03, 7.1508e-02, 9.5285e-03, 1.2427e-01, 8.5435e-03,\n",
      "        1.3698e-01, 7.0167e-02, 2.5201e-03, 1.1737e-02, 4.7782e-02, 2.6618e-02,\n",
      "        1.8301e-02, 6.4139e-03, 8.7518e-03, 5.1661e-03, 2.4669e-03, 9.4274e-02,\n",
      "        3.8824e-03, 1.8066e-04, 1.9694e-02, 8.1450e-02, 1.5427e-02, 1.6965e-03,\n",
      "        7.2533e-02, 2.3429e-05, 1.2312e-01, 2.3209e-02, 2.6929e-02, 1.0191e-01,\n",
      "        1.2515e-02, 8.6687e-02, 1.2030e-01, 5.4825e-03, 9.9843e-03, 3.1817e-02,\n",
      "        1.9391e-02, 2.6951e-02, 9.4059e-03, 2.4054e-02, 2.0474e-02, 2.1001e-02,\n",
      "        4.0344e-02, 1.1094e-02, 1.2401e-02, 3.0202e-02, 2.3251e-02, 1.2690e-02,\n",
      "        2.3338e-03, 1.5773e-02, 4.3501e-02, 8.5805e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1126, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0504, device='cuda:0')\n",
      "p.batch_l2: tensor([2.3210e-05, 5.7301e-06, 9.4184e-05, 8.5486e-06, 1.5972e-04, 8.6838e-05,\n",
      "        1.7396e-06, 4.3971e-05, 3.9617e-05, 1.6787e-05, 1.8964e-05, 3.5631e-06,\n",
      "        1.2579e-05, 1.6773e-05, 1.4082e-04, 1.8542e-05, 3.1378e-04, 1.6679e-05,\n",
      "        3.3738e-04, 3.0428e-04, 6.7637e-06, 2.1136e-05, 1.7107e-04, 1.2396e-04,\n",
      "        3.1886e-05, 9.9478e-06, 2.4252e-05, 1.4076e-05, 3.6908e-06, 2.7488e-04,\n",
      "        7.8706e-06, 4.4710e-07, 4.2821e-05, 1.6843e-04, 2.9663e-05, 3.5470e-06,\n",
      "        1.3067e-04, 4.5100e-08, 2.1036e-04, 5.1752e-05, 7.6954e-05, 2.3011e-04,\n",
      "        4.8513e-05, 2.6022e-04, 2.2975e-04, 1.2338e-05, 1.4747e-05, 7.7194e-05,\n",
      "        4.4495e-05, 1.1748e-04, 2.1280e-05, 5.9051e-05, 3.3455e-05, 4.1170e-05,\n",
      "        8.6016e-05, 3.4417e-05, 2.5715e-05, 1.0374e-04, 1.0031e-04, 3.3692e-05,\n",
      "        5.0796e-06, 3.7447e-05, 1.6278e-04, 3.1733e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0048, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0024, device='cuda:0')\n",
      "p.batch_l2: tensor([1.5918e-02, 1.8857e-03, 5.7570e-02, 3.3961e-03, 2.8327e-02, 5.2704e-02,\n",
      "        1.1267e-03, 1.9592e-02, 8.7581e-03, 1.2650e-02, 1.1830e-02, 2.1915e-03,\n",
      "        3.8931e-03, 6.7134e-03, 4.3187e-02, 1.7945e-02, 5.4812e-02, 1.2051e-02,\n",
      "        1.2018e-01, 3.0058e-02, 3.4250e-03, 1.7785e-02, 2.8059e-02, 1.1424e-02,\n",
      "        2.9771e-02, 7.9060e-03, 6.2012e-03, 5.0564e-03, 4.8464e-03, 4.7636e-02,\n",
      "        6.6483e-03, 1.0720e-04, 1.6469e-02, 6.1859e-02, 1.7619e-02, 1.2288e-03,\n",
      "        4.8782e-02, 2.0954e-05, 1.0033e-01, 2.6817e-02, 2.9578e-02, 9.4363e-02,\n",
      "        7.5927e-03, 5.1875e-02, 1.5399e-01, 8.8799e-03, 1.3149e-02, 7.2107e-02,\n",
      "        1.5913e-02, 1.2642e-02, 1.3159e-02, 2.3485e-02, 3.9223e-02, 2.3816e-02,\n",
      "        2.4909e-02, 1.4947e-02, 1.6167e-02, 2.4364e-02, 1.1581e-02, 1.4389e-02,\n",
      "        2.4526e-03, 6.1106e-02, 1.5081e-02, 4.9827e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.1262, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0434, device='cuda:0')\n",
      "p.batch_l2: tensor([1.1991e-05, 1.6123e-06, 4.5260e-05, 3.3511e-06, 3.1374e-05, 3.7901e-05,\n",
      "        1.4640e-06, 2.4310e-05, 1.4688e-05, 1.3754e-05, 1.0569e-05, 2.2063e-06,\n",
      "        5.8577e-06, 5.3451e-06, 5.8852e-05, 1.2799e-05, 8.6856e-05, 9.5717e-06,\n",
      "        1.0515e-04, 5.4977e-05, 2.5669e-06, 1.0331e-05, 4.3967e-05, 1.5730e-05,\n",
      "        1.3922e-05, 8.3194e-06, 8.6689e-06, 4.2367e-06, 3.3146e-06, 7.7360e-05,\n",
      "        5.8299e-06, 1.6533e-07, 1.7358e-05, 4.9779e-05, 1.3241e-05, 2.3551e-06,\n",
      "        4.7885e-05, 1.9860e-08, 9.4112e-05, 1.6753e-05, 3.2789e-05, 1.0071e-04,\n",
      "        1.0469e-05, 8.2822e-05, 1.2557e-04, 8.1282e-06, 9.7826e-06, 4.4523e-05,\n",
      "        1.7651e-05, 2.5777e-05, 6.5370e-06, 2.7179e-05, 1.7500e-05, 1.9257e-05,\n",
      "        2.7004e-05, 2.6425e-05, 1.7920e-05, 3.3205e-05, 1.7098e-05, 1.0610e-05,\n",
      "        3.2286e-06, 5.4106e-05, 3.0507e-05, 8.2730e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0035, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0013, device='cuda:0')\n",
      "p.batch_l2: tensor([1.6234e-02, 9.0168e-04, 2.5316e-03, 1.7485e-03, 6.5448e-03, 1.1529e-03,\n",
      "        6.8824e-04, 1.4838e-02, 3.9023e-03, 1.0896e-02, 7.1715e-03, 7.3428e-03,\n",
      "        5.5292e-03, 5.3759e-03, 3.5160e-02, 1.9443e-02, 1.0753e-02, 6.0410e-03,\n",
      "        2.0990e-02, 4.4231e-03, 6.5171e-04, 1.2574e-02, 2.9055e-03, 3.9554e-03,\n",
      "        1.1708e-02, 2.3614e-03, 2.6250e-03, 8.7392e-03, 5.0689e-03, 2.1401e-02,\n",
      "        1.0061e-02, 9.6642e-05, 3.6763e-03, 2.6729e-02, 2.2980e-03, 6.0351e-04,\n",
      "        1.9445e-02, 2.8493e-05, 2.3266e-02, 1.0913e-02, 1.0546e-02, 4.6552e-02,\n",
      "        3.3706e-03, 1.1287e-02, 5.1131e-02, 8.6668e-03, 1.4839e-02, 4.4028e-03,\n",
      "        4.6338e-03, 2.2845e-03, 1.6991e-02, 1.0220e-02, 6.3864e-03, 1.0342e-02,\n",
      "        8.3962e-03, 2.2800e-02, 9.4952e-03, 1.0701e-02, 2.2930e-03, 1.4008e-02,\n",
      "        7.5248e-03, 1.7037e-02, 5.4806e-03, 4.1779e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.1274, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0300, device='cuda:0')\n",
      "p.batch_l2: tensor([2.1968e-04, 1.0140e-05, 2.1024e-04, 1.8415e-05, 2.3350e-04, 1.4065e-04,\n",
      "        3.7700e-06, 1.6830e-04, 1.4641e-04, 1.2707e-04, 6.9225e-05, 1.5333e-04,\n",
      "        2.2435e-04, 7.8432e-05, 3.3323e-04, 2.1953e-04, 2.7769e-04, 1.3834e-04,\n",
      "        2.8206e-04, 2.1263e-04, 9.7679e-06, 1.6415e-04, 2.3376e-04, 1.9005e-04,\n",
      "        1.7681e-04, 1.8870e-05, 2.7843e-05, 7.7872e-05, 5.0022e-05, 1.6563e-04,\n",
      "        1.0942e-04, 4.8789e-07, 1.5443e-04, 3.4160e-04, 4.6212e-05, 6.8083e-06,\n",
      "        1.6350e-04, 1.3557e-07, 3.0668e-04, 2.3171e-04, 1.6132e-04, 3.3696e-04,\n",
      "        1.6385e-04, 2.3457e-04, 3.0366e-04, 1.2634e-04, 1.0167e-04, 1.2424e-04,\n",
      "        4.3673e-05, 1.9173e-04, 1.9069e-04, 6.7865e-05, 1.8298e-04, 1.9220e-04,\n",
      "        1.0135e-04, 2.3938e-04, 1.6072e-04, 2.3784e-04, 2.0233e-04, 1.0845e-04,\n",
      "        7.1971e-05, 1.8200e-04, 2.2403e-04, 2.0395e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0148, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0032, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.7243, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([8.9230e-04, 1.2520e-03, 9.1719e-03, 6.1976e-03, 4.9215e-02, 1.2322e-02,\n",
      "        1.1880e-02, 1.4825e-02, 3.6355e-03, 1.6312e-03, 3.6478e-02, 7.6617e-02,\n",
      "        2.1209e-02, 1.0942e-01, 3.1487e-02, 1.4680e-02, 1.2831e-03, 1.5972e-03,\n",
      "        5.1466e-02, 3.5253e-05, 7.9924e-02, 1.7727e-03, 7.5355e-03, 5.8275e-04,\n",
      "        4.6938e-04, 1.2044e-01, 1.0708e-02, 1.8921e-02, 1.1738e-02, 5.3384e-02,\n",
      "        1.0576e-02, 6.0257e-02, 2.0405e-02, 4.5822e-03, 1.6519e-02, 8.6364e-03,\n",
      "        2.4480e-03, 6.7180e-03, 6.7498e-03, 1.0440e-02, 1.7731e-03, 4.5819e-02,\n",
      "        7.4627e-02, 1.7890e-02, 2.1619e-02, 9.5154e-03, 3.2243e-03, 4.7209e-02,\n",
      "        2.1262e-02, 1.4097e-02, 2.7116e-06, 4.2074e-04, 5.1403e-02, 5.1865e-03,\n",
      "        6.2986e-02, 3.2221e-02, 1.3742e-02, 1.0019e-01, 1.5434e-03, 4.1250e-02,\n",
      "        4.3010e-02, 2.1183e-02, 3.4905e-02, 3.1604e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.0299, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0354, device='cuda:0')\n",
      "p.batch_l2: tensor([7.3930e-06, 4.1067e-05, 1.7947e-04, 4.8909e-05, 9.9506e-04, 1.3201e-04,\n",
      "        1.5370e-04, 1.3087e-04, 8.6874e-05, 1.6671e-05, 5.7825e-04, 8.2623e-04,\n",
      "        3.2943e-04, 1.1127e-03, 2.2549e-04, 9.2773e-05, 1.0465e-05, 2.7928e-05,\n",
      "        9.3982e-04, 3.9338e-07, 7.7448e-04, 6.1144e-05, 2.7132e-04, 7.1844e-06,\n",
      "        4.0245e-06, 1.0400e-03, 5.8053e-05, 2.0713e-04, 1.3544e-04, 1.0853e-03,\n",
      "        1.2847e-04, 4.7696e-04, 4.1048e-04, 9.5937e-05, 3.6615e-04, 1.0268e-04,\n",
      "        4.3223e-05, 1.2085e-04, 1.5783e-04, 1.5133e-04, 1.3215e-05, 4.5842e-04,\n",
      "        1.2353e-03, 2.6934e-04, 6.9424e-05, 9.5792e-05, 1.0154e-04, 1.3057e-03,\n",
      "        2.9124e-04, 2.2885e-04, 2.3228e-08, 1.0130e-05, 1.0243e-03, 7.1759e-05,\n",
      "        8.6175e-04, 6.2404e-04, 1.7222e-04, 1.3254e-03, 1.6682e-05, 2.9345e-04,\n",
      "        6.1905e-04, 1.6282e-04, 3.2075e-04, 2.9448e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0027, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0064, device='cuda:0')\n",
      "p.batch_l2: tensor([1.0465e-03, 1.6812e-03, 1.2821e-02, 7.3836e-03, 6.8868e-02, 2.8618e-02,\n",
      "        1.3152e-02, 2.1096e-02, 5.6436e-03, 2.0158e-03, 3.1798e-02, 6.8791e-02,\n",
      "        2.9424e-02, 1.3623e-01, 3.6669e-02, 1.4304e-02, 1.1388e-03, 2.1545e-03,\n",
      "        5.1020e-02, 3.9458e-05, 6.5746e-02, 3.5911e-03, 1.5107e-02, 7.3355e-04,\n",
      "        7.6401e-04, 1.2406e-01, 1.2355e-02, 1.6854e-02, 1.0836e-02, 7.0227e-02,\n",
      "        1.2426e-02, 8.2820e-02, 2.0855e-02, 5.1496e-03, 2.4041e-02, 1.1085e-02,\n",
      "        5.0497e-03, 8.1951e-03, 8.6157e-03, 1.1256e-02, 1.8701e-03, 5.8118e-02,\n",
      "        6.8531e-02, 1.5826e-02, 1.5260e-02, 8.3016e-03, 6.1640e-03, 7.3557e-02,\n",
      "        2.9060e-02, 1.2490e-02, 5.2459e-06, 6.9077e-04, 5.7313e-02, 6.3037e-03,\n",
      "        6.0418e-02, 3.0457e-02, 1.9949e-02, 8.9236e-02, 1.2139e-03, 4.6949e-02,\n",
      "        4.3480e-02, 2.0843e-02, 3.7166e-02, 3.7519e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.0323, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0410, device='cuda:0')\n",
      "p.batch_l2: tensor([2.4476e-06, 6.5244e-06, 3.0383e-05, 1.9242e-05, 1.4026e-04, 6.6249e-05,\n",
      "        2.3127e-05, 4.5910e-05, 1.9059e-05, 4.5513e-06, 7.9347e-05, 1.1374e-04,\n",
      "        7.4614e-05, 3.2874e-04, 7.4832e-05, 2.7902e-05, 2.6570e-06, 5.1419e-06,\n",
      "        1.7773e-04, 7.0956e-08, 1.4586e-04, 1.5825e-05, 4.0045e-05, 1.4229e-06,\n",
      "        1.4512e-06, 1.7179e-04, 2.7797e-05, 2.8587e-05, 1.9891e-05, 1.6013e-04,\n",
      "        2.0029e-05, 9.6625e-05, 4.0406e-05, 2.2080e-05, 6.9144e-05, 2.9377e-05,\n",
      "        1.2298e-05, 1.7306e-05, 3.0429e-05, 2.1234e-05, 5.4335e-06, 1.2361e-04,\n",
      "        1.5697e-04, 2.0720e-05, 2.2035e-05, 3.4114e-05, 2.5042e-05, 1.6687e-04,\n",
      "        6.2557e-05, 2.2251e-05, 8.1627e-09, 2.1411e-06, 1.5617e-04, 1.8142e-05,\n",
      "        1.3934e-04, 8.6077e-05, 4.2240e-05, 1.9520e-04, 2.3226e-06, 5.2805e-05,\n",
      "        1.4004e-04, 2.8984e-05, 8.0914e-05, 9.3322e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0016, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0026, device='cuda:0')\n",
      "p.batch_l2: tensor([1.9662e-03, 1.0690e-03, 8.3760e-03, 7.3842e-03, 1.0996e-01, 3.1403e-02,\n",
      "        1.7987e-02, 1.9209e-02, 5.4402e-03, 3.4964e-03, 4.2036e-02, 6.5317e-02,\n",
      "        3.0441e-02, 6.4373e-02, 4.3148e-02, 1.2396e-02, 1.1495e-03, 1.9531e-03,\n",
      "        5.1537e-02, 3.8618e-05, 5.6459e-02, 3.4359e-03, 1.4236e-02, 6.2751e-04,\n",
      "        1.4311e-03, 8.2454e-02, 2.6049e-02, 2.9676e-02, 1.5296e-02, 8.5808e-02,\n",
      "        2.8003e-02, 9.6429e-02, 3.3881e-02, 2.9032e-03, 1.7990e-02, 9.3006e-03,\n",
      "        6.5425e-03, 1.5536e-02, 1.3589e-02, 1.4163e-02, 2.2577e-03, 5.8298e-02,\n",
      "        6.0330e-02, 1.7605e-02, 1.3392e-02, 5.0621e-03, 3.4292e-03, 7.8026e-02,\n",
      "        4.9452e-02, 1.1879e-02, 8.9996e-06, 1.0485e-03, 5.1634e-02, 7.7025e-03,\n",
      "        5.9304e-02, 4.6422e-02, 3.4674e-02, 8.7203e-02, 8.9091e-04, 2.8305e-02,\n",
      "        4.3360e-02, 2.3278e-02, 6.4108e-02, 5.6376e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.0443, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0327, device='cuda:0')\n",
      "p.batch_l2: tensor([1.1191e-06, 1.7201e-06, 1.6277e-05, 1.4291e-05, 7.0102e-05, 1.6348e-05,\n",
      "        1.6161e-05, 1.4668e-05, 3.9840e-06, 1.5244e-06, 4.0951e-05, 6.3295e-05,\n",
      "        4.5071e-05, 9.8703e-05, 3.1767e-05, 1.3998e-05, 1.0682e-06, 1.8533e-06,\n",
      "        6.4832e-05, 2.4162e-08, 8.7527e-05, 4.5425e-06, 1.2178e-05, 4.2809e-07,\n",
      "        6.9559e-07, 8.9292e-05, 1.2000e-05, 1.8939e-05, 1.6415e-05, 4.7780e-05,\n",
      "        1.4570e-05, 5.3696e-05, 3.3207e-05, 4.7185e-06, 2.3937e-05, 6.4576e-06,\n",
      "        3.4639e-06, 8.7776e-06, 1.6146e-05, 1.1038e-05, 2.2736e-06, 6.7884e-05,\n",
      "        7.5165e-05, 1.9088e-05, 1.2065e-05, 6.9617e-06, 5.7800e-06, 5.9083e-05,\n",
      "        6.3167e-05, 1.4509e-05, 3.3901e-09, 5.9102e-07, 5.6932e-05, 3.8883e-06,\n",
      "        7.8941e-05, 5.3334e-05, 2.1796e-05, 7.9037e-05, 7.9461e-07, 2.6029e-05,\n",
      "        4.7890e-05, 2.2205e-05, 6.3943e-05, 5.6060e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0011, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0013, device='cuda:0')\n",
      "p.batch_l2: tensor([2.5337e-03, 7.6903e-03, 7.6395e-03, 8.1314e-03, 7.2695e-02, 2.5400e-02,\n",
      "        1.4873e-02, 1.0865e-02, 5.8221e-03, 5.1611e-03, 1.8078e-02, 2.5531e-02,\n",
      "        1.6626e-02, 6.9590e-02, 1.2036e-02, 3.6649e-03, 1.5681e-03, 6.5666e-03,\n",
      "        2.7368e-02, 4.9780e-05, 1.5993e-02, 5.8762e-03, 2.7810e-02, 4.1844e-04,\n",
      "        2.0637e-04, 2.4108e-02, 7.4894e-03, 3.1346e-02, 2.0878e-02, 2.4071e-02,\n",
      "        1.7674e-02, 2.4980e-02, 8.1469e-03, 8.5625e-03, 1.8903e-02, 4.6891e-03,\n",
      "        7.8285e-04, 3.4769e-02, 2.0239e-02, 3.6977e-03, 2.0506e-03, 1.6430e-02,\n",
      "        2.5048e-02, 1.4383e-02, 2.1805e-02, 7.7968e-03, 2.8623e-03, 1.1789e-02,\n",
      "        2.1534e-02, 4.5399e-03, 2.9577e-06, 1.1185e-03, 1.5496e-02, 3.0149e-02,\n",
      "        3.7595e-02, 2.4156e-02, 5.7117e-03, 5.0981e-02, 1.0100e-03, 2.0559e-02,\n",
      "        1.4082e-02, 1.2740e-02, 1.1034e-02, 1.6762e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0503, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0877, device='cuda:0')\n",
      "p.batch_l2: tensor([8.7504e-06, 7.0411e-05, 2.4719e-04, 2.2431e-04, 3.5073e-04, 9.5527e-05,\n",
      "        2.3603e-04, 1.1224e-04, 1.0471e-04, 2.3730e-05, 1.6324e-04, 2.6284e-04,\n",
      "        2.9312e-04, 3.6613e-04, 9.5357e-05, 4.1883e-05, 6.2558e-06, 6.6480e-05,\n",
      "        2.8649e-04, 1.4130e-07, 2.9176e-04, 5.8621e-05, 3.0505e-04, 2.8087e-06,\n",
      "        2.2734e-06, 3.1021e-04, 1.7073e-04, 2.8451e-04, 2.8646e-04, 2.8494e-04,\n",
      "        2.2506e-04, 3.0179e-04, 8.0453e-05, 1.1998e-04, 2.9360e-04, 3.1413e-05,\n",
      "        1.0968e-05, 3.0118e-04, 1.7248e-04, 2.8629e-05, 1.1223e-05, 2.8703e-04,\n",
      "        2.3524e-04, 2.6231e-04, 1.9178e-04, 1.0417e-04, 3.7808e-05, 2.1748e-04,\n",
      "        2.6111e-04, 1.2076e-04, 7.9518e-09, 4.6065e-06, 2.3506e-04, 1.0334e-04,\n",
      "        3.1873e-04, 2.2891e-04, 7.4332e-05, 3.0869e-04, 6.7777e-06, 2.6166e-04,\n",
      "        1.8866e-04, 1.0640e-04, 1.9101e-04, 2.1677e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0030, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0084, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.5753, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([4.3253e-02, 1.5788e-02, 1.4657e-02, 3.0870e-02, 1.5026e-02, 1.1161e-01,\n",
      "        1.5565e-02, 3.1763e-02, 1.0007e-02, 8.8748e-04, 1.7833e-03, 5.7152e-02,\n",
      "        6.7634e-03, 4.0313e-02, 6.6782e-02, 3.7742e-02, 7.5525e-02, 1.9506e-02,\n",
      "        2.4701e-05, 4.6304e-05, 4.3616e-03, 1.0465e-02, 6.8495e-02, 1.6691e-03,\n",
      "        1.2768e-02, 2.7330e-05, 3.0937e-02, 7.8643e-03, 8.4145e-04, 2.4924e-02,\n",
      "        3.3494e-03, 4.1328e-05, 3.4162e-05, 4.7377e-02, 9.7792e-02, 5.9092e-03,\n",
      "        1.0605e-02, 4.0488e-03, 3.3817e-03, 6.3280e-02, 6.2758e-03, 7.0585e-02,\n",
      "        4.5573e-03, 2.1428e-02, 4.3058e-02, 1.6461e-02, 2.2257e-02, 1.1140e-02,\n",
      "        1.2204e-02, 1.1462e-03, 2.3119e-02, 1.7496e-02, 5.8392e-06, 2.1723e-02,\n",
      "        2.1972e-02, 5.5028e-02, 5.1703e-02, 2.3829e-03, 6.8314e-02, 2.9713e-02,\n",
      "        3.0240e-02, 6.0834e-03, 5.4066e-03, 8.6268e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.2080, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1256, device='cuda:0')\n",
      "p.batch_l2: tensor([2.3863e-04, 2.3747e-04, 3.0774e-04, 1.0053e-03, 1.5383e-04, 7.7496e-04,\n",
      "        1.7304e-04, 1.7668e-04, 3.1652e-04, 1.1622e-05, 6.2782e-06, 3.6236e-04,\n",
      "        2.5395e-04, 5.7353e-04, 1.2266e-03, 5.7990e-04, 4.8253e-04, 1.0289e-04,\n",
      "        3.5493e-07, 5.3000e-07, 9.5315e-05, 2.6050e-04, 1.0791e-03, 1.8500e-05,\n",
      "        1.2750e-04, 3.7189e-07, 3.1137e-04, 2.1056e-04, 7.1360e-06, 1.6793e-04,\n",
      "        3.5250e-05, 2.8896e-07, 2.6354e-07, 3.7880e-04, 1.5016e-03, 3.6210e-05,\n",
      "        1.3960e-04, 3.8964e-05, 4.1679e-05, 3.3689e-04, 5.8844e-05, 1.0667e-03,\n",
      "        9.5269e-05, 1.7698e-04, 2.4468e-04, 3.3340e-04, 5.9020e-04, 7.6579e-05,\n",
      "        7.7747e-05, 1.0724e-05, 1.9301e-04, 1.2053e-04, 1.0493e-07, 1.6111e-04,\n",
      "        2.6978e-04, 5.8981e-04, 2.7852e-04, 1.6535e-05, 7.4972e-04, 5.8009e-04,\n",
      "        3.2461e-04, 4.1628e-05, 1.6937e-04, 1.3524e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0154, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0154, device='cuda:0')\n",
      "p.batch_l2: tensor([2.4536e-02, 1.4917e-02, 2.0121e-02, 5.4474e-02, 1.9280e-02, 1.0207e-01,\n",
      "        2.2779e-02, 3.2285e-02, 1.6350e-02, 9.4842e-04, 2.7470e-03, 5.5300e-02,\n",
      "        7.7710e-03, 3.7060e-02, 6.4610e-02, 4.0619e-02, 5.1699e-02, 1.8840e-02,\n",
      "        3.5184e-05, 6.4847e-05, 6.1200e-03, 1.0190e-02, 8.6180e-02, 2.1323e-03,\n",
      "        1.7537e-02, 4.0198e-05, 1.9022e-02, 1.2456e-02, 8.1981e-04, 4.0339e-02,\n",
      "        4.6374e-03, 3.8434e-05, 3.8309e-05, 5.5662e-02, 7.7516e-02, 5.0363e-03,\n",
      "        1.2776e-02, 2.2473e-03, 4.6266e-03, 4.9384e-02, 5.5914e-03, 1.0727e-01,\n",
      "        5.5979e-03, 2.5692e-02, 3.6600e-02, 2.4722e-02, 3.9668e-02, 1.0944e-02,\n",
      "        1.2950e-02, 1.6377e-03, 2.3050e-02, 2.1235e-02, 9.7167e-06, 2.5054e-02,\n",
      "        1.9078e-02, 6.1812e-02, 2.9600e-02, 3.5561e-03, 7.9862e-02, 3.2702e-02,\n",
      "        2.7675e-02, 5.0551e-03, 6.5717e-03, 1.3352e-02], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.1566, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1221, device='cuda:0')\n",
      "p.batch_l2: tensor([5.2773e-05, 3.2747e-05, 7.8114e-05, 1.4592e-04, 5.0638e-05, 1.9112e-04,\n",
      "        4.1860e-05, 5.6328e-05, 6.1860e-05, 2.4405e-06, 4.6284e-06, 1.3982e-04,\n",
      "        3.3058e-05, 1.0068e-04, 1.4794e-04, 9.7877e-05, 7.8864e-05, 2.9522e-05,\n",
      "        9.1474e-08, 1.4225e-07, 2.0784e-05, 3.6964e-05, 3.1089e-04, 4.2728e-06,\n",
      "        4.6987e-05, 7.1711e-08, 3.9829e-05, 4.3554e-05, 1.4847e-06, 8.4117e-05,\n",
      "        1.2036e-05, 6.2438e-08, 6.0417e-08, 8.9266e-05, 1.9650e-04, 9.6488e-06,\n",
      "        4.2256e-05, 4.7193e-06, 1.5996e-05, 7.5446e-05, 1.2727e-05, 2.2399e-04,\n",
      "        1.8002e-05, 5.9960e-05, 7.5776e-05, 8.9393e-05, 1.1046e-04, 2.0000e-05,\n",
      "        3.1783e-05, 2.3568e-06, 4.2343e-05, 3.5256e-05, 2.2193e-08, 4.3005e-05,\n",
      "        6.2921e-05, 1.2932e-04, 6.3413e-05, 9.1069e-06, 1.6150e-04, 1.0174e-04,\n",
      "        4.2518e-05, 7.0079e-06, 2.2425e-05, 3.3554e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.grad_batch-norm: tensor(0.0073, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0057, device='cuda:0')\n",
      "p.batch_l2: tensor([4.0215e-02, 1.1973e-02, 3.8654e-03, 4.3790e-02, 6.7591e-02, 1.3404e-01,\n",
      "        2.1873e-02, 6.5487e-02, 1.1731e-02, 7.1623e-04, 2.5375e-03, 3.7013e-02,\n",
      "        6.8986e-03, 4.4180e-02, 5.0952e-02, 2.5610e-02, 1.0573e-01, 1.3287e-02,\n",
      "        5.8595e-05, 1.4262e-04, 2.9158e-03, 5.9498e-03, 6.0406e-02, 1.3333e-03,\n",
      "        1.5214e-02, 7.1491e-05, 2.3492e-02, 4.7395e-03, 1.1975e-03, 3.6429e-02,\n",
      "        4.6829e-03, 5.5580e-05, 5.7764e-05, 1.2243e-01, 7.8983e-02, 7.7149e-03,\n",
      "        1.0669e-02, 1.5532e-03, 4.0228e-03, 2.1200e-01, 1.3767e-02, 1.2483e-01,\n",
      "        2.7358e-03, 2.2891e-02, 6.4166e-02, 1.6476e-02, 2.6535e-02, 2.1454e-02,\n",
      "        9.3879e-03, 3.1400e-03, 2.2942e-02, 4.0409e-02, 2.4084e-05, 4.0139e-02,\n",
      "        1.0588e-02, 5.0773e-02, 4.0505e-02, 4.0083e-03, 8.8671e-02, 1.8459e-02,\n",
      "        2.1542e-02, 5.3951e-03, 1.1151e-02, 7.0504e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.2005, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1094, device='cuda:0')\n",
      "p.batch_l2: tensor([3.7059e-05, 1.5722e-05, 6.9183e-06, 4.6243e-05, 3.3636e-05, 1.3636e-04,\n",
      "        3.0444e-05, 4.4126e-05, 1.5928e-05, 1.1505e-06, 1.8223e-06, 3.6047e-05,\n",
      "        8.3089e-06, 3.9783e-05, 5.1889e-05, 2.5445e-05, 9.5478e-05, 1.4662e-05,\n",
      "        2.1138e-08, 6.3526e-08, 6.8267e-06, 1.0994e-05, 1.2108e-04, 1.4503e-06,\n",
      "        1.6748e-05, 3.6912e-08, 2.9272e-05, 6.7652e-06, 8.3668e-07, 2.2927e-05,\n",
      "        4.3670e-06, 3.6679e-08, 2.3356e-08, 5.6108e-05, 6.1390e-05, 7.9148e-06,\n",
      "        1.9602e-05, 3.0852e-06, 3.9385e-06, 7.7335e-05, 1.2976e-05, 1.0004e-04,\n",
      "        5.3922e-06, 3.0503e-05, 5.2656e-05, 2.2932e-05, 2.5212e-05, 2.0387e-05,\n",
      "        1.2953e-05, 1.8334e-06, 2.2282e-05, 2.0141e-05, 9.9672e-09, 3.3112e-05,\n",
      "        1.4298e-05, 7.6599e-05, 4.8494e-05, 3.3934e-06, 8.8509e-05, 3.2697e-05,\n",
      "        2.4049e-05, 5.8540e-06, 1.0300e-05, 8.3662e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0061, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0040, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2688e-03, 1.1210e-02, 9.1539e-03, 2.8454e-02, 2.7686e-03, 6.3431e-03,\n",
      "        1.6780e-02, 8.2994e-03, 3.4020e-03, 3.8649e-04, 9.3473e-03, 1.3150e-02,\n",
      "        4.2963e-03, 2.9125e-03, 2.7104e-02, 7.2365e-03, 3.2180e-02, 4.2832e-03,\n",
      "        7.8311e-05, 7.8062e-05, 2.3168e-03, 4.0111e-03, 2.1260e-02, 1.4703e-02,\n",
      "        5.7993e-03, 1.0230e-04, 8.2500e-03, 6.4044e-03, 8.0046e-04, 2.7470e-02,\n",
      "        1.1646e-02, 2.7894e-05, 5.9516e-05, 8.6568e-03, 1.5275e-02, 3.1040e-03,\n",
      "        3.7163e-03, 7.4710e-04, 7.3771e-03, 3.4539e-02, 4.9551e-03, 1.6271e-02,\n",
      "        4.0131e-03, 1.3004e-02, 2.0952e-02, 5.5423e-03, 2.7476e-02, 1.4161e-02,\n",
      "        6.2125e-03, 2.5254e-03, 2.3903e-02, 1.2556e-02, 1.6040e-05, 1.6359e-02,\n",
      "        5.2901e-03, 1.3436e-02, 1.5258e-02, 1.3852e-03, 1.4681e-02, 1.3751e-03,\n",
      "        2.2644e-02, 1.4839e-02, 1.1720e-02, 2.5305e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.0356, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.1059, device='cuda:0')\n",
      "p.batch_l2: tensor([1.4947e-04, 2.2257e-04, 1.4184e-04, 3.0010e-04, 1.3048e-04, 2.3929e-04,\n",
      "        2.4754e-04, 1.2297e-04, 7.9630e-05, 4.6521e-06, 2.3759e-04, 1.4507e-04,\n",
      "        6.7041e-05, 2.3451e-04, 2.9696e-04, 2.3637e-04, 2.9893e-04, 2.1032e-04,\n",
      "        1.6954e-07, 2.4371e-07, 2.4728e-05, 1.1766e-04, 3.3993e-04, 1.7488e-04,\n",
      "        2.5127e-04, 2.7995e-07, 1.1205e-04, 9.0493e-05, 4.4114e-06, 3.0325e-04,\n",
      "        1.1924e-04, 1.7075e-07, 1.6444e-07, 1.8450e-04, 2.5865e-04, 2.3370e-05,\n",
      "        6.2883e-05, 1.1665e-05, 4.6143e-05, 2.1020e-04, 4.3795e-05, 3.2338e-04,\n",
      "        6.9058e-05, 9.6040e-05, 2.5115e-04, 1.1945e-04, 2.7153e-04, 2.3343e-04,\n",
      "        4.1431e-05, 7.7834e-06, 1.5529e-04, 2.0842e-04, 2.9129e-08, 2.0270e-04,\n",
      "        1.0928e-04, 2.2186e-04, 1.0860e-04, 1.0385e-05, 2.8400e-04, 2.2935e-04,\n",
      "        2.4807e-04, 1.0851e-04, 2.0594e-04, 1.6792e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0122, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0149, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.2803, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n",
      "p.batch_l2: tensor([1.5105e-01, 5.8496e-02, 1.1549e-06, 2.5942e-01, 1.9068e-02, 3.4794e-02,\n",
      "        1.4040e-02, 1.6145e-02, 1.4688e-02, 5.8974e-02, 1.0287e-02, 1.0731e-01,\n",
      "        1.1101e-05, 1.2305e-01, 1.1494e-01, 1.0174e-01, 3.4516e-02, 1.2478e-02,\n",
      "        1.8471e-02, 1.3042e-01, 2.1241e-04, 4.7216e-02, 1.6566e-06, 9.7421e-02,\n",
      "        5.7425e-03, 2.1056e-02, 7.3041e-02, 2.0895e-02, 1.7061e-02, 2.8774e-02,\n",
      "        5.8843e-06, 6.0506e-02, 3.7955e-02, 7.9083e-03, 4.6286e-03, 3.9924e-02,\n",
      "        1.1134e-04, 4.9490e-03, 6.1213e-06, 4.4339e-02, 3.5698e-02, 7.7356e-03,\n",
      "        4.2878e-01, 4.0520e-02, 8.6425e-04, 6.5304e-03, 8.3970e-02, 8.0711e-03,\n",
      "        2.4455e-02, 1.2886e-01, 1.8059e-01, 2.4395e-02, 2.2390e-01, 1.2492e-02,\n",
      "        4.4665e-02, 3.8669e-03, 6.5298e-02, 9.5780e-02, 3.5971e-02, 1.4533e-01,\n",
      "        9.7217e-02, 8.6142e-02, 4.1645e-02, 3.2675e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16, 1, 8, 8])\n",
      "p.grad_batch-norm: tensor(0.3887, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2419, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2729e-03, 5.2178e-04, 1.8928e-08, 3.0648e-03, 2.2355e-04, 3.7296e-04,\n",
      "        1.7980e-04, 3.3130e-04, 4.5539e-04, 1.0865e-03, 9.4038e-05, 2.8758e-03,\n",
      "        2.0071e-07, 2.0023e-03, 7.8982e-04, 2.4905e-03, 2.2505e-04, 1.8870e-04,\n",
      "        4.2971e-04, 1.3995e-03, 1.0960e-06, 4.8268e-04, 1.2964e-08, 1.0637e-03,\n",
      "        1.0539e-04, 2.3204e-04, 9.0114e-04, 3.1912e-04, 3.8289e-04, 6.5974e-04,\n",
      "        6.7583e-08, 4.5825e-04, 2.3835e-04, 1.8570e-04, 5.3497e-05, 4.3189e-04,\n",
      "        4.3427e-07, 5.5460e-05, 7.3501e-08, 3.8516e-04, 6.9957e-04, 9.9850e-05,\n",
      "        5.1335e-03, 3.8032e-04, 1.4651e-05, 1.5221e-04, 1.5311e-03, 2.3738e-04,\n",
      "        2.6995e-04, 2.6030e-03, 1.0382e-03, 4.2128e-04, 3.6732e-03, 1.0388e-04,\n",
      "        3.6373e-04, 1.1474e-04, 9.3910e-04, 2.2745e-03, 2.4094e-04, 1.6187e-03,\n",
      "        1.1190e-03, 1.1235e-03, 5.7971e-04, 1.2165e-04], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 16])\n",
      "p.grad_batch-norm: tensor(0.0357, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0228, device='cuda:0')\n",
      "p.batch_l2: tensor([1.8341e-01, 1.2219e-01, 1.4100e-06, 3.6882e-01, 2.4933e-02, 5.0143e-02,\n",
      "        1.7744e-02, 1.8377e-02, 1.7302e-02, 9.0680e-02, 1.2364e-02, 1.5723e-01,\n",
      "        1.7479e-05, 1.4799e-01, 1.0218e-01, 2.0779e-01, 3.7366e-02, 1.4795e-02,\n",
      "        4.0950e-02, 1.8257e-01, 1.3209e-04, 7.6536e-02, 1.6219e-06, 1.4524e-01,\n",
      "        7.4812e-03, 2.0986e-02, 9.5817e-02, 2.6486e-02, 2.2380e-02, 3.8807e-02,\n",
      "        4.8742e-06, 1.0101e-01, 3.6630e-02, 7.7480e-03, 4.4488e-03, 4.7354e-02,\n",
      "        1.2409e-04, 5.5541e-03, 6.4655e-06, 3.2246e-02, 5.2212e-02, 8.0419e-03,\n",
      "        3.6369e-01, 5.2250e-02, 1.1207e-03, 7.6590e-03, 8.9591e-02, 1.4972e-02,\n",
      "        2.2027e-02, 1.6986e-01, 2.2146e-01, 4.0934e-02, 2.7325e-01, 2.9545e-02,\n",
      "        5.7647e-02, 5.5650e-03, 1.0115e-01, 1.1602e-01, 3.7616e-02, 2.1499e-01,\n",
      "        1.0603e-01, 1.0383e-01, 6.7870e-02, 5.2792e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 16, 4, 4])\n",
      "p.grad_batch-norm: tensor(0.4283, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.3496, device='cuda:0')\n",
      "p.batch_l2: tensor([4.5186e-04, 2.1897e-04, 3.5598e-09, 7.9128e-04, 6.6460e-05, 1.6245e-04,\n",
      "        4.4175e-05, 3.9543e-05, 7.5740e-05, 2.3795e-04, 2.1764e-05, 5.6544e-04,\n",
      "        6.0587e-08, 3.1595e-04, 1.3239e-04, 4.4563e-04, 4.7540e-05, 3.1371e-05,\n",
      "        5.7382e-05, 4.1223e-04, 1.2259e-07, 1.5432e-04, 3.5825e-09, 2.4702e-04,\n",
      "        1.8486e-05, 4.5252e-05, 1.7712e-04, 5.8561e-05, 4.4820e-05, 1.1117e-04,\n",
      "        1.0307e-08, 2.0086e-04, 5.4944e-05, 2.5267e-05, 1.6598e-05, 6.5643e-05,\n",
      "        2.8105e-07, 1.2729e-05, 1.2876e-08, 8.2702e-05, 1.0260e-04, 1.7943e-05,\n",
      "        7.8326e-04, 8.9249e-05, 3.2889e-06, 2.0627e-05, 2.8104e-04, 2.8703e-05,\n",
      "        4.9352e-05, 4.2310e-04, 3.9551e-04, 1.2471e-04, 5.3783e-04, 5.5290e-05,\n",
      "        1.1909e-04, 2.2050e-05, 2.2431e-04, 2.5314e-04, 9.5181e-05, 4.9888e-04,\n",
      "        2.3541e-04, 2.3493e-04, 1.3245e-04, 1.9631e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0213, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0148, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2107e-01, 1.1227e-01, 5.9142e-07, 2.6285e-01, 2.2541e-02, 2.2630e-02,\n",
      "        1.6485e-02, 1.5509e-02, 9.7666e-03, 1.4133e-01, 1.0241e-02, 9.8403e-02,\n",
      "        8.6606e-06, 1.0039e-01, 1.2214e-01, 2.4564e-01, 4.0618e-02, 2.3044e-02,\n",
      "        4.1615e-02, 1.6467e-01, 3.2235e-04, 1.7854e-01, 1.3206e-06, 1.0842e-01,\n",
      "        1.0362e-02, 1.2692e-02, 1.1968e-01, 2.7555e-02, 2.8295e-02, 2.5223e-02,\n",
      "        3.3842e-06, 1.0499e-01, 6.7093e-02, 6.0045e-03, 3.2464e-03, 4.6923e-02,\n",
      "        9.1631e-05, 5.7700e-03, 1.1436e-05, 3.8330e-02, 5.4546e-02, 1.2870e-02,\n",
      "        2.1162e-01, 7.5153e-02, 1.4647e-03, 7.5325e-03, 7.9483e-02, 1.6621e-02,\n",
      "        2.3328e-02, 1.3716e-01, 1.6887e-01, 3.7640e-02, 2.9336e-01, 2.7276e-02,\n",
      "        4.6892e-02, 5.8605e-03, 5.3256e-02, 8.0774e-02, 3.8985e-02, 2.7385e-01,\n",
      "        6.3329e-02, 9.9516e-02, 6.1780e-02, 4.3095e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32, 512])\n",
      "p.grad_batch-norm: tensor(0.3479, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.3351, device='cuda:0')\n",
      "p.batch_l2: tensor([1.2809e-04, 5.6997e-05, 7.7285e-10, 2.3211e-04, 2.2625e-05, 3.7903e-05,\n",
      "        1.8559e-05, 1.7305e-05, 1.4100e-05, 1.0286e-04, 8.9743e-06, 1.9123e-04,\n",
      "        1.2868e-08, 5.9142e-05, 1.1248e-04, 1.2680e-04, 2.5048e-05, 1.3784e-05,\n",
      "        2.3142e-05, 1.2707e-04, 1.6197e-07, 8.0475e-05, 1.0545e-09, 1.1793e-04,\n",
      "        5.8634e-06, 1.5655e-05, 9.3861e-05, 2.1358e-05, 1.8612e-05, 3.6723e-05,\n",
      "        2.7960e-09, 6.6450e-05, 2.2863e-05, 1.0732e-05, 4.0780e-06, 3.2094e-05,\n",
      "        9.2532e-08, 3.3384e-06, 5.1744e-09, 5.0997e-05, 3.1263e-05, 1.2588e-05,\n",
      "        1.7531e-04, 3.7038e-05, 9.4225e-07, 7.7938e-06, 8.2995e-05, 8.3226e-06,\n",
      "        1.9772e-05, 1.1537e-04, 1.0383e-04, 3.1260e-05, 1.8331e-04, 1.2438e-05,\n",
      "        3.6189e-05, 8.8637e-06, 5.3023e-05, 6.2242e-05, 4.2496e-05, 1.3413e-04,\n",
      "        7.3146e-05, 1.0475e-04, 3.9152e-05, 6.1329e-06], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 32])\n",
      "p.grad_batch-norm: tensor(0.0113, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0075, device='cuda:0')\n",
      "p.batch_l2: tensor([6.8415e-02, 6.3545e-02, 4.2995e-07, 7.4257e-02, 3.4228e-03, 1.3006e-02,\n",
      "        2.6754e-02, 2.3563e-02, 8.1370e-03, 7.1900e-02, 4.8170e-03, 1.8810e-02,\n",
      "        7.2259e-06, 6.9829e-02, 7.8215e-03, 3.0699e-01, 3.4657e-02, 1.6314e-02,\n",
      "        3.6019e-02, 8.5772e-02, 1.6425e-04, 8.2232e-02, 8.4500e-07, 5.7907e-02,\n",
      "        4.1176e-02, 5.2303e-03, 1.2913e-02, 1.6363e-02, 1.9151e-02, 3.4368e-03,\n",
      "        1.7405e-06, 8.4296e-02, 3.6875e-02, 8.6850e-03, 3.8516e-03, 1.9509e-02,\n",
      "        8.1759e-05, 3.3860e-03, 3.2622e-06, 1.5155e-02, 5.0277e-02, 7.3452e-03,\n",
      "        9.2676e-02, 3.5998e-02, 2.6981e-04, 2.6555e-03, 3.7205e-02, 3.5786e-03,\n",
      "        1.6723e-02, 9.5782e-02, 9.5630e-02, 5.4654e-03, 1.2314e-01, 1.6344e-02,\n",
      "        7.8789e-03, 3.6978e-03, 3.2410e-02, 4.8566e-02, 1.2848e-02, 2.5556e-01,\n",
      "        1.8084e-02, 2.1530e-02, 4.4195e-02, 4.8067e-03], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10, 32])\n",
      "p.grad_batch-norm: tensor(0.2616, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.2521, device='cuda:0')\n",
      "p.batch_l2: tensor([4.1733e-04, 2.7491e-04, 1.9659e-09, 4.4382e-04, 1.2168e-04, 3.0339e-04,\n",
      "        2.5073e-04, 2.9132e-04, 8.7563e-05, 3.9349e-04, 8.1249e-05, 3.2484e-04,\n",
      "        3.4653e-08, 3.2721e-04, 2.6802e-04, 4.7297e-04, 2.2047e-04, 1.9529e-04,\n",
      "        3.1447e-04, 3.9563e-04, 3.9426e-07, 4.1241e-04, 2.3186e-09, 4.1273e-04,\n",
      "        2.5128e-04, 1.0879e-04, 3.1641e-04, 1.9018e-04, 3.0152e-04, 2.0560e-04,\n",
      "        5.8190e-09, 3.2644e-04, 3.1977e-04, 6.3313e-05, 3.6073e-05, 6.7125e-05,\n",
      "        2.5138e-07, 1.5247e-05, 1.6622e-08, 2.4354e-04, 3.0471e-04, 6.0032e-05,\n",
      "        4.4077e-04, 1.2921e-04, 2.7203e-06, 8.2088e-05, 2.5866e-04, 1.1614e-04,\n",
      "        5.3403e-05, 3.9982e-04, 3.6730e-04, 1.4068e-04, 4.8389e-04, 3.6005e-05,\n",
      "        2.2831e-04, 5.2521e-05, 1.7018e-04, 3.2743e-04, 2.0505e-04, 4.5949e-04,\n",
      "        2.3449e-04, 3.5112e-04, 3.2315e-04, 4.9954e-05], device='cuda:0')\n",
      "p.grad_batch-shape: torch.Size([64, 10])\n",
      "p.grad_batch-norm: tensor(0.0204, device='cuda:0')\n",
      "p.grad_batch-norm: tensor(0.0166, device='cuda:0')\n",
      "l2_norms_all_params: torch.Size([8, 64])\n",
      "total_norms: torch.Size([64])\n",
      "clipped_grads: torch.Size([64, 16, 1, 8, 8])\n",
      "clipped_grads: torch.Size([64, 16])\n",
      "clipped_grads: torch.Size([64, 32, 16, 4, 4])\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 32, 512])\n",
      "noise: tensor(25.4579, device='cuda:0')\n",
      "clipped_grads: torch.Size([64, 32])\n",
      "clipped_grads: torch.Size([64, 10, 32])\n",
      "clipped_grads: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "grad_norm = []\n",
    "noise_norm = []\n",
    "\n",
    "optimizer = DP_SGD(model.parameters(), grad_norm, noise_norm, lr=0.1, max_norm=0.1, stddev=2.0)\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"epoch:\", epoch)\n",
    "    for batch_idx, (x, y) in enumerate(mnist_dataloader):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"noise_norm:\", noise_norm)\n",
    "        outputs = model(x)\n",
    "        loss = loss_function(outputs, y)\n",
    "\n",
    "        with backpack(BatchGrad(), BatchL2Grad()):\n",
    "            loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        losses.append(loss.detach().item())\n",
    "        accuracies.append(accuracy(outputs, y))\n",
    "\n",
    "        if (batch_idx % PRINT_EVERY) == 0:\n",
    "            print(\n",
    "                \"Epoch %3.d/%d Iteration %3.d \" % (epoch, NUM_EPOCHS, batch_idx)\n",
    "                + \"Minibatch Loss %.3f  \" % losses[-1]\n",
    "                + \"Accuracy %.3f\" % accuracies[-1]\n",
    "            )\n",
    "\n",
    "        if MAX_ITER is not None and batch_idx > MAX_ITER:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = torch.randn(10000,1,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_1 = grad.expand(10000,10000).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_1[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9761.1689, 9761.1689, 9761.1689,  ..., 9761.1689, 9761.1689,\n",
       "         9761.1689],\n",
       "        [9761.1689, 9761.1689, 9761.1689,  ..., 9761.1689, 9761.1689,\n",
       "         9761.1689],\n",
       "        [9761.1689, 9761.1689, 9761.1689,  ..., 9761.1689, 9761.1689,\n",
       "         9761.1689],\n",
       "        ...,\n",
       "        [9761.1689, 9761.1689, 9761.1689,  ..., 9761.1689, 9761.1689,\n",
       "         9761.1689],\n",
       "        [9761.1689, 9761.1689, 9761.1689,  ..., 9761.1689, 9761.1689,\n",
       "         9761.1689],\n",
       "        [9761.1689, 9761.1689, 9761.1689,  ..., 9761.1689, 9761.1689,\n",
       "         9761.1689]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(grad_1 ,grad_1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_1= torch.ones(1,10000)\n",
    "grad_2= torch.ones(1,10000)+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(grad - torch.mean(grad,dim=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0092])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(grad,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(88.1666)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.matmul(grad,grad_2.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(grad,dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9., 9., 9.,  ..., 9., 9., 9.],\n",
       "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
       "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
       "        ...,\n",
       "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
       "        [9., 9., 9.,  ..., 9., 9., 9.],\n",
       "        [9., 9., 9.,  ..., 9., 9., 9.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(grad.T,grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u,e,v = torch.linalg.svd(torch.matmul(grad.T-torch.mean(grad,dim=1),grad_1),full_matrices=True)\n",
    "u,e,v = torch.linalg.svd(0*grad_1.T,full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,e,v = torch.linalg.svd(grad,full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31.3267])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1,e1,v1 = torch.linalg.svd(torch.matmul(grad[0,:].reshape(-1,1),grad[0,:].reshape(1,-1)),full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1297e+03, 1.0854e+03, 1.0545e+03, 1.0459e+03, 1.0262e+03, 9.8540e+02,\n",
       "        9.5924e+02, 9.2682e+02, 8.8534e+02, 8.4996e+02, 4.3788e-04, 2.8055e-04,\n",
       "        2.3513e-04, 1.9746e-04, 1.3537e-04, 1.2707e-04, 1.2450e-04, 1.1272e-04,\n",
       "        1.0477e-04, 1.0103e-04, 8.3788e-05, 8.2241e-05, 7.0967e-05, 6.7113e-05,\n",
       "        6.3447e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05,\n",
       "        6.2441e-05, 6.2441e-05, 6.2441e-05, 6.2441e-05, 4.5314e-05, 4.4167e-05,\n",
       "        3.8589e-05, 3.6697e-05, 1.8747e-05, 4.6399e-06])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1000])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34.8521)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.matmul(torch.matmul(u[:,0:1],u[:,0:1].T),grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n",
      "tensor(33.6114)\n"
     ]
    }
   ],
   "source": [
    "sum_1 = 0\n",
    "for i in range(10):\n",
    "    print(torch.norm(torch.matmul(torch.matmul(u[:,0:1],u[:,0:1].T),grad.T[:,i])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0530e-01,  7.6692e-03,  9.9719e-03, -8.5070e-02, -2.0869e-02,\n",
       "        -7.0017e-02,  1.6949e-01, -9.7118e-02, -2.0678e-01,  3.9112e-02,\n",
       "         1.0105e-01,  9.9604e-02, -2.3406e-01, -2.7081e-02, -9.9069e-03,\n",
       "        -4.9222e-02,  1.3824e-01, -6.2047e-02,  2.8869e-01, -1.4544e-01,\n",
       "         1.9592e-02,  2.1915e-01,  2.6815e-01,  7.3943e-02, -1.3010e-01,\n",
       "         7.1754e-02, -6.7268e-02, -1.7541e-01,  6.1326e-03, -9.2325e-02,\n",
       "         2.2296e-01,  5.3372e-02,  4.8533e-02,  4.1103e-02, -1.6926e-01,\n",
       "         4.0703e-02,  1.1291e-01, -1.1200e-01,  3.7640e-02, -1.8864e-02,\n",
       "        -1.0695e-01, -8.4429e-02, -3.8227e-02,  1.5085e-03, -1.4342e-01,\n",
       "        -6.8454e-02, -4.2904e-02,  6.2296e-03, -7.4124e-02, -4.8945e-02,\n",
       "        -3.7292e-02, -1.1107e-01,  3.7356e-02,  1.4186e-01, -2.0900e-02,\n",
       "         7.0036e-02, -5.5026e-02, -2.5038e-01, -1.1998e-02, -3.3142e-03,\n",
       "         8.1840e-02,  1.3848e-01,  1.3135e-02, -1.8900e-01, -6.0346e-02,\n",
       "         8.6473e-02, -2.5847e-02, -5.4696e-02, -5.0652e-02, -4.3535e-02,\n",
       "        -1.4666e-01,  1.0957e-01, -1.8719e-01,  6.6771e-04,  6.9988e-02,\n",
       "         1.0372e-01, -6.7952e-02,  6.1010e-02,  2.3078e-01, -1.1481e-01,\n",
       "         9.0009e-02, -7.7826e-02, -8.1237e-02,  4.6449e-02, -1.0442e-02,\n",
       "        -2.7152e-01,  1.5219e-01,  5.9576e-03,  4.3601e-03, -5.8951e-02,\n",
       "        -1.2042e-01, -1.3436e-01,  1.4187e-01,  2.3755e-01, -2.6041e-01,\n",
       "        -2.0783e-02,  5.6991e-03,  5.3604e-02, -1.4185e-01, -5.0754e-02,\n",
       "        -1.0681e-01,  1.0381e-01,  4.4297e-02, -2.1454e-01, -3.1664e-02,\n",
       "         5.7270e-02,  1.8781e-02, -5.3269e-02,  3.2174e-02, -1.1369e-02,\n",
       "        -2.3095e-01,  1.2235e-01,  3.2846e-02,  1.6444e-01, -5.1461e-02,\n",
       "         3.1684e-01, -1.1595e-01, -1.1778e-01,  1.1609e-01,  2.0603e-01,\n",
       "         9.3124e-02, -1.5559e-01, -1.3988e-01, -2.1757e-01,  3.2077e-02,\n",
       "        -1.1790e-01, -1.6590e-02,  5.7917e-02,  1.3102e-01, -2.5820e-02,\n",
       "        -1.6835e-01, -2.2975e-01, -8.3431e-02, -1.2636e-01,  1.3094e-01,\n",
       "         1.0750e-01,  1.1915e-01, -1.6599e-01, -2.2330e-01,  1.8312e-02,\n",
       "         2.7424e-01, -1.7304e-01,  4.7232e-02, -2.0329e-01,  6.7357e-02,\n",
       "         1.3854e-02,  3.7136e-02,  5.4904e-03, -1.0257e-01, -1.4346e-01,\n",
       "         3.8613e-02, -2.4586e-01, -1.2179e-01, -1.0587e-01,  2.1320e-01,\n",
       "         1.2236e-01,  8.7765e-02, -7.6296e-03,  1.7807e-01,  2.1655e-01,\n",
       "        -1.6391e-02,  8.0521e-02,  1.2890e-01, -5.8821e-02, -1.6702e-02,\n",
       "         1.3067e-01,  6.6880e-02,  7.6868e-02,  1.2965e-01, -2.2332e-01,\n",
       "        -3.7534e-01,  1.0646e-01, -1.4653e-01, -2.3546e-02, -1.9619e-02,\n",
       "        -6.0838e-02,  7.7556e-02, -1.0146e-01, -1.5414e-01,  1.4097e-01,\n",
       "         2.7979e-02,  1.4774e-02,  1.5790e-01,  1.1628e-02,  4.5256e-03,\n",
       "        -4.6319e-02, -8.1919e-02,  1.0733e-01,  3.1206e-03, -9.9686e-03,\n",
       "         1.9064e-01,  1.6457e-01,  9.3321e-02, -2.1473e-01,  3.3079e-02,\n",
       "        -5.1692e-02,  1.9910e-01,  2.1421e-01,  7.4902e-02,  1.6904e-01,\n",
       "         4.5596e-02, -2.8919e-02,  1.4178e-01,  1.4720e-01, -3.6524e-02,\n",
       "        -1.0617e-02,  2.0550e-02, -1.4269e-01, -1.5425e-01, -8.0732e-02,\n",
       "         9.3328e-02, -2.5110e-03,  1.6762e-01, -1.4459e-01, -8.6284e-02,\n",
       "         9.5457e-02, -1.1130e-02, -1.3914e-01, -1.9749e-01,  2.4856e-01,\n",
       "        -1.1096e-01, -5.7215e-02, -1.8073e-02,  8.3760e-02,  1.7656e-01,\n",
       "        -7.9717e-02,  5.9889e-02,  8.7056e-02, -3.2915e-02,  1.7474e-02,\n",
       "        -1.1239e-01, -1.6169e-01, -1.7118e-02,  4.9607e-02,  1.7193e-01,\n",
       "         5.8029e-02, -4.4671e-02,  5.6454e-02,  9.5227e-02,  8.3297e-02,\n",
       "         2.1492e-01,  2.6788e-01, -1.2619e-01,  2.8699e-01, -4.3543e-02,\n",
       "        -1.0744e-01,  3.0919e-02,  4.2874e-02,  1.7502e-01,  1.6959e-01,\n",
       "        -6.6023e-02, -1.4803e-01,  1.6831e-02,  2.1963e-03, -1.6745e-01,\n",
       "         2.5135e-01, -1.2046e-01,  1.6384e-01,  1.9277e-02,  4.1205e-02,\n",
       "         1.0614e-01, -1.0328e-01, -1.6385e-01, -1.4868e-02, -2.9380e-02,\n",
       "         5.3002e-02,  1.1883e-01,  1.9375e-01,  1.3470e-02, -1.7497e-01,\n",
       "         3.2628e-02, -6.0620e-02,  3.5332e-02,  4.1777e-02,  3.0703e-02,\n",
       "        -3.1332e-02, -1.0578e-01,  1.1753e-01,  1.5242e-01, -5.1535e-02,\n",
       "        -4.9569e-02, -1.3881e-02, -1.4963e-01, -2.7843e-02,  9.3384e-02,\n",
       "         4.4964e-02, -1.0703e-01,  3.2046e-01, -1.1176e-02, -2.9830e-01,\n",
       "        -6.6565e-02,  4.5085e-02,  9.1441e-02, -3.8746e-01,  1.8937e-01,\n",
       "         5.1132e-02, -8.9564e-03,  6.4527e-02, -1.7879e-01, -1.8052e-01,\n",
       "         9.3464e-02,  3.9727e-02, -1.4487e-01, -1.3377e-01, -7.2808e-02,\n",
       "        -8.7509e-02, -7.6414e-02, -4.1512e-02, -6.8021e-02, -5.9236e-03,\n",
       "         1.1252e-01,  5.0653e-02, -1.5139e-02,  7.1539e-02, -4.5386e-02,\n",
       "         1.0455e-01, -6.4608e-02, -2.7349e-02, -1.7306e-01, -4.2445e-01,\n",
       "        -1.5183e-02,  1.8198e-01,  6.7890e-02,  1.6549e-01, -5.0329e-02,\n",
       "        -3.4946e-03,  1.0570e-01,  2.3710e-02,  8.3996e-02, -1.2050e-01,\n",
       "        -2.8513e-01, -3.8497e-02, -1.5130e-01,  5.8785e-02, -1.7873e-01,\n",
       "        -2.7845e-02,  1.1704e-01,  2.6476e-01,  6.0100e-03,  1.2138e-01,\n",
       "        -1.7859e-01, -2.3625e-02, -6.9626e-02, -1.2509e-01,  2.9937e-02,\n",
       "         4.4672e-04,  4.2800e-02, -9.8247e-02,  1.1948e-01, -1.1704e-01,\n",
       "        -3.1959e-02,  4.3693e-03, -6.4812e-02, -5.1017e-02,  9.0082e-03,\n",
       "         1.7172e-01,  1.0644e-01,  4.0118e-02, -1.7809e-01,  5.8751e-02,\n",
       "        -1.3176e-01,  2.1861e-01,  1.9424e-01, -1.6642e-01,  1.7127e-01,\n",
       "        -1.1957e-01, -8.6289e-03, -6.7081e-02, -1.2869e-02, -4.3704e-02,\n",
       "         7.6592e-02, -1.1280e-01,  9.1925e-02, -9.7813e-02, -1.5555e-01,\n",
       "         2.2540e-02,  5.1677e-02, -8.3016e-02,  4.1434e-02, -1.0725e-01,\n",
       "        -9.1733e-02,  7.6337e-02,  6.8657e-02,  2.0388e-01, -7.6687e-03,\n",
       "        -8.0802e-03,  1.3601e-01, -7.0080e-02, -2.8473e-02,  7.4268e-02,\n",
       "         5.4869e-02,  1.7259e-01,  1.4451e-01,  5.8877e-02, -1.5848e-01,\n",
       "         2.8781e-02, -1.8186e-01,  1.6853e-01, -1.2916e-01, -1.2644e-01,\n",
       "         7.6115e-02,  1.7039e-01,  1.7633e-02,  1.9979e-01,  7.0169e-03,\n",
       "         5.8542e-02,  1.2084e-01, -1.2670e-01,  5.1761e-02, -6.4695e-03,\n",
       "        -8.7605e-02, -2.8423e-02,  4.5128e-02, -7.6845e-02, -2.8714e-02,\n",
       "        -4.9290e-03, -7.8878e-02,  4.9167e-03,  5.8871e-02,  1.5596e-01,\n",
       "        -1.1850e-01,  1.0739e-01, -7.4372e-02, -1.4636e-01, -7.0388e-02,\n",
       "         4.9691e-03, -8.1924e-02, -1.9393e-02, -9.0572e-02, -9.8868e-02,\n",
       "         3.9817e-02,  1.8062e-01, -1.9238e-01, -2.1222e-01,  1.7974e-01,\n",
       "        -1.2405e-01, -3.7390e-02,  1.3230e-02, -9.0399e-02, -1.2947e-01,\n",
       "        -2.3834e-01,  2.0377e-01, -2.8805e-02, -2.2799e-01,  4.7198e-02,\n",
       "         7.5610e-02,  1.1908e-02,  5.8627e-02, -7.7164e-02,  2.0333e-01,\n",
       "        -1.5977e-01,  8.2005e-02,  3.7188e-02,  6.1362e-02,  4.2454e-02,\n",
       "         2.3319e-01,  1.1656e-01,  1.1989e-01,  4.4863e-02,  1.4005e-01,\n",
       "        -8.5668e-02, -1.9216e-01,  7.9247e-02, -1.1037e-01,  2.0688e-01,\n",
       "        -5.8211e-02,  1.4926e-01,  8.9692e-02, -1.0893e-01, -1.3543e-01,\n",
       "        -1.3328e-01,  1.0463e-01,  1.5786e-01, -3.7164e-03,  5.5180e-02,\n",
       "         5.5987e-02,  1.2637e-01,  5.2988e-02,  9.7229e-02, -2.3962e-01,\n",
       "         1.4008e-01,  1.0868e-01, -3.2778e-02,  1.4993e-01, -1.9031e-02,\n",
       "         1.1049e-01,  1.5033e-01,  2.4429e-01, -1.5916e-02, -1.2135e-01,\n",
       "        -1.3696e-03,  1.1028e-01, -1.6271e-01, -9.9982e-02, -4.7171e-02,\n",
       "        -2.8986e-01, -6.8118e-03,  6.0338e-02,  2.4838e-02, -8.5058e-02,\n",
       "        -1.0989e-03,  1.0666e-02, -1.1328e-02,  2.7023e-01,  3.1284e-02,\n",
       "        -2.9816e-01,  6.6527e-02,  9.5374e-02,  8.2336e-02,  1.1501e-01,\n",
       "         4.6284e-03,  8.8736e-02,  3.1544e-02,  5.2054e-02, -4.2717e-02,\n",
       "        -1.0140e-01, -9.3377e-02, -1.2659e-01,  2.3315e-02,  1.0845e-01,\n",
       "        -2.5140e-01,  9.9159e-02,  7.0721e-02,  6.4996e-03,  9.2907e-02,\n",
       "         1.0240e-01, -1.6812e-01, -1.2964e-02,  5.6782e-03, -1.5326e-02,\n",
       "         1.8785e-03, -4.3803e-02,  1.2383e-01, -3.4374e-03,  1.4634e-02,\n",
       "        -9.6528e-03, -4.7181e-02, -2.7250e-01,  3.5489e-02,  1.3949e-01,\n",
       "        -1.5592e-01, -9.9897e-02,  1.0588e-01, -8.8500e-02,  1.6106e-01,\n",
       "        -4.6923e-02, -1.2768e-01, -1.4644e-02,  8.4906e-03,  5.3148e-02,\n",
       "         1.4127e-01, -1.4577e-01,  9.7734e-02, -8.6541e-02, -5.9777e-02,\n",
       "         1.8112e-02,  1.4113e-01,  8.9261e-02, -1.5287e-01,  1.0773e-02,\n",
       "         1.1742e-02, -1.3430e-01, -3.5683e-02,  2.0179e-01,  1.6237e-02,\n",
       "        -7.9453e-02, -6.9159e-02, -1.1435e-01,  1.7067e-01, -1.1888e-01,\n",
       "        -1.3357e-01,  6.7022e-02,  2.4644e-01,  3.7000e-02, -1.0271e-01,\n",
       "        -7.1811e-03,  1.9753e-01, -8.1745e-02, -6.6816e-02, -5.1039e-03,\n",
       "         1.2343e-01,  2.5619e-01, -1.0544e-01,  2.7046e-01, -2.1276e-01,\n",
       "         2.1884e-02,  1.0915e-01,  5.2578e-03, -7.8591e-02, -9.5522e-03,\n",
       "         1.1090e-02, -1.8551e-01, -5.5592e-02,  1.9394e-02,  1.6087e-01,\n",
       "         2.2727e-01,  6.2477e-02, -7.6799e-02,  1.3203e-01,  2.2988e-01,\n",
       "         4.4237e-01,  4.1801e-04,  1.1443e-01, -3.5029e-01,  8.9517e-02,\n",
       "         2.0076e-01, -6.4647e-02, -2.6072e-02,  2.3284e-01,  1.4859e-02,\n",
       "         1.4084e-01,  2.5098e-02,  7.0573e-02,  1.2437e-01, -3.0850e-02,\n",
       "        -1.3984e-02,  2.2750e-01, -1.1069e-01,  2.7369e-02,  1.3098e-01,\n",
       "        -2.2443e-01, -3.4277e-01,  8.3493e-02, -3.4218e-02,  1.6456e-01,\n",
       "         6.8126e-02,  1.9605e-02, -6.8404e-02,  3.2299e-02, -5.8129e-02,\n",
       "         4.6363e-02,  4.2835e-02,  2.5509e-02,  4.8901e-02, -9.1582e-02,\n",
       "        -1.4989e-01,  6.6989e-02,  2.2858e-02, -1.3444e-01,  7.1155e-02,\n",
       "        -5.8689e-02,  2.4043e-01, -1.6426e-01, -8.0038e-03, -4.4169e-02,\n",
       "        -1.9063e-01, -2.0176e-01, -1.2956e-01, -3.8457e-02, -2.4063e-01,\n",
       "         1.4248e-02,  6.9155e-03, -2.8416e-01, -1.6726e-01,  1.2106e-01,\n",
       "        -1.7080e-01, -5.5573e-02, -5.4641e-02,  2.9163e-02,  1.0658e-01,\n",
       "        -6.1031e-02, -3.6005e-01, -2.7050e-02,  3.1993e-01, -2.5739e-01,\n",
       "        -6.5321e-02, -1.5682e-01, -1.6296e-02,  2.8995e-01, -1.5732e-02,\n",
       "        -2.6960e-01, -2.6582e-02,  1.1226e-01, -2.8719e-02,  2.5586e-01,\n",
       "        -4.2379e-02,  1.2194e-01, -1.9242e-01, -7.6666e-02, -4.0640e-02,\n",
       "        -1.5892e-01,  2.6522e-01, -4.6351e-02, -6.6801e-02, -2.0231e-01,\n",
       "        -1.2198e-01, -3.8775e-02, -1.4411e-01, -1.0871e-01,  1.8640e-01,\n",
       "         2.4105e-01, -2.2604e-01, -2.8595e-03, -1.1827e-01,  2.2017e-01,\n",
       "         1.5884e-01, -2.6079e-01,  5.9185e-02,  1.2204e-01, -8.5537e-02,\n",
       "        -2.4694e-01, -9.3905e-02,  1.1221e-01, -1.3293e-01,  1.3379e-01,\n",
       "        -1.0505e-02,  1.5785e-01, -2.8276e-02, -1.9155e-01, -1.0249e-01,\n",
       "         8.8329e-03, -1.8483e-03, -4.9312e-02,  6.3341e-03, -3.4414e-02,\n",
       "         2.2306e-01, -1.6784e-01, -1.0254e-03, -3.5456e-02, -2.1325e-01,\n",
       "         1.3223e-01,  4.0227e-02, -2.3060e-02,  6.0210e-02,  8.2883e-03,\n",
       "        -7.3661e-02, -1.4184e-01,  1.1730e-02,  8.1450e-02, -5.4157e-02,\n",
       "        -1.9696e-03, -3.3612e-02,  1.3922e-01, -8.7980e-02, -1.2237e-02,\n",
       "        -2.3161e-02,  1.7885e-01,  4.6851e-02, -9.8162e-03,  1.8126e-02,\n",
       "         2.0569e-01, -6.4873e-02, -2.4284e-01,  2.0442e-01, -2.0715e-02,\n",
       "         1.2535e-02,  6.7978e-02,  1.4723e-02,  2.6376e-02,  1.0593e-01,\n",
       "         1.4442e-01, -2.8003e-02,  1.6650e-01,  1.0103e-01,  1.7274e-01,\n",
       "         2.7481e-01, -1.6633e-01,  7.0780e-02, -1.5687e-01,  5.4713e-03,\n",
       "        -2.9183e-01, -6.1645e-02, -2.9254e-02, -8.0472e-02, -1.0677e-01,\n",
       "         4.5431e-02,  1.9624e-01,  3.1579e-02,  9.0391e-02, -1.3142e-01,\n",
       "         1.6286e-01,  1.9082e-02,  1.2130e-03,  2.2239e-01, -4.4605e-02,\n",
       "         6.8781e-02,  3.9143e-02,  1.1769e-01, -1.8407e-01,  8.1123e-02,\n",
       "         3.5672e-02,  9.5337e-02, -2.7173e-01, -2.5902e-02, -8.9493e-02,\n",
       "         2.3378e-01,  2.3134e-01, -4.8993e-02,  2.7009e-01, -6.5633e-02,\n",
       "        -1.2628e-01, -1.7605e-01, -1.2684e-01, -9.2516e-02,  1.7924e-02,\n",
       "         3.3157e-02,  2.1589e-01,  2.7500e-01,  2.2471e-01,  1.0805e-01,\n",
       "        -3.6434e-01,  1.2240e-01,  4.7526e-02, -1.9046e-01,  5.0251e-02,\n",
       "         4.3194e-03,  3.6568e-02,  1.7654e-01, -1.7036e-01,  1.1502e-01,\n",
       "         2.3829e-01,  7.4641e-02, -1.9554e-01, -3.5617e-02,  6.8692e-03,\n",
       "         1.7008e-01, -1.5526e-01, -7.3455e-02,  5.2866e-02,  2.7735e-02,\n",
       "         1.7968e-01,  1.6983e-01, -2.2919e-01, -1.0616e-01, -2.5649e-01,\n",
       "         1.6346e-01, -7.1215e-04,  2.8907e-02,  2.0848e-01,  8.2008e-02,\n",
       "        -1.2924e-01, -3.2664e-01,  9.1326e-02,  5.3583e-02,  4.3193e-02,\n",
       "        -1.7234e-01, -1.4044e-01,  1.1906e-01,  1.6840e-02,  1.2384e-02,\n",
       "        -4.3399e-02, -1.6899e-01,  1.7659e-01,  9.7684e-02,  3.7556e-02,\n",
       "        -1.0876e-01, -7.2371e-02, -2.0186e-01, -3.2095e-02, -9.4295e-02,\n",
       "        -1.9151e-01,  1.1554e-01, -1.3341e-02,  6.8128e-02, -5.0224e-02,\n",
       "         2.3021e-01, -5.7028e-02,  2.0570e-01,  1.3766e-01, -1.8519e-01,\n",
       "         2.9015e-02, -2.1418e-01,  4.2754e-02,  1.8957e-01,  1.7508e-01,\n",
       "        -6.6381e-02, -4.0525e-02,  1.0335e-01,  1.2612e-01,  8.9945e-02,\n",
       "        -8.1951e-02,  2.9272e-02, -3.6990e-02,  2.9713e-02,  2.5395e-01,\n",
       "        -2.5745e-01, -1.1874e-01,  6.5730e-02,  1.8787e-03,  1.2100e-01,\n",
       "        -3.8338e-02,  1.0589e-01, -6.6943e-02,  1.2603e-02,  1.6256e-01,\n",
       "         7.4927e-02, -2.4945e-01,  4.4097e-02,  3.2069e-02,  1.8056e-02,\n",
       "         1.6444e-01, -2.7274e-02,  1.9404e-01, -9.6583e-02, -8.1938e-02,\n",
       "        -1.0982e-03,  1.2860e-01, -2.3605e-01,  5.8191e-03, -4.1891e-02,\n",
       "        -4.1617e-02, -1.2719e-01,  1.3224e-01, -2.2721e-01,  9.4077e-02,\n",
       "         7.2517e-02,  2.5150e-01, -4.9063e-03, -2.5396e-02,  1.7563e-01,\n",
       "         2.9326e-03,  1.5949e-02, -2.7035e-01,  1.2514e-01, -1.2456e-01,\n",
       "         3.0258e-02, -3.0543e-01,  2.0107e-01, -5.4550e-02,  1.7725e-01,\n",
       "        -6.0079e-02,  1.1946e-01, -3.8318e-01, -2.2733e-01, -1.9941e-02,\n",
       "         9.3726e-02,  4.8426e-02,  3.6225e-02,  1.6851e-01, -2.4958e-02,\n",
       "         2.2534e-01, -2.9145e-02,  4.7056e-03, -1.1596e-01,  5.4725e-02,\n",
       "        -1.0978e-01, -3.5793e-02, -6.4693e-02, -3.0534e-02,  1.5845e-01,\n",
       "        -1.0033e-01, -1.0796e-01,  1.6932e-01, -2.6756e-02,  2.2329e-01,\n",
       "        -2.0916e-03, -5.1201e-02, -6.6768e-02, -2.9868e-03,  6.3496e-02,\n",
       "        -2.3559e-02, -1.3448e-01, -2.2494e-01,  1.3738e-01, -1.0195e-01,\n",
       "        -2.9506e-01,  1.0403e-01, -8.1162e-02, -1.7478e-02,  8.9402e-02,\n",
       "         5.2958e-02, -9.5969e-02,  1.7515e-01, -1.4446e-01, -1.0599e-01,\n",
       "         4.6589e-02,  2.2452e-01, -1.4745e-01, -1.2811e-01,  1.8857e-01,\n",
       "        -1.4851e-01,  1.0216e-02,  3.6468e-02, -6.5981e-02,  1.1181e-02,\n",
       "         2.3629e-01,  1.9859e-02, -4.0266e-02, -4.6347e-02, -2.1840e-01,\n",
       "         1.1168e-01,  7.5262e-02, -1.3652e-01,  2.8199e-01,  7.4363e-02,\n",
       "        -8.9677e-02, -1.5235e-01, -1.0900e-01, -1.7028e-01, -1.6499e-01,\n",
       "         6.1952e-02,  1.5029e-01, -2.9617e-02,  9.5946e-02, -8.0859e-02,\n",
       "         2.0275e-02,  7.8395e-02,  2.1787e-01, -8.3525e-02,  7.0460e-02])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.matmul(u[:,0:1],u[:,0:1].T),grad.T[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8887, -0.0223, -0.0290,  ..., -0.6342,  0.2431, -0.2051],\n",
       "        [-0.3053,  0.0077,  0.0100,  ...,  0.2179, -0.0835,  0.0705],\n",
       "        [ 0.4388, -0.0110, -0.0143,  ..., -0.3131,  0.1200, -0.1013],\n",
       "        ...,\n",
       "        [ 0.4606, -0.0116, -0.0150,  ..., -0.3287,  0.1260, -0.1063],\n",
       "        [ 0.2651, -0.0067, -0.0087,  ..., -0.1892,  0.0725, -0.0612],\n",
       "        [ 0.5392, -0.0135, -0.0176,  ..., -0.3848,  0.1475, -0.1244]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.matmul(u[:,0:1],u[:,0:1].T),grad.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.8037)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.matmul(torch.matmul(u1[:,0:1],u1[:,0:1].T),grad[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk,ek,vk = torch.linalg.svd(torch.matmul(torch.matmul(u[:,0:1],u[:,0:1].T),grad[0,:].reshape(-1,1)),full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = torch.randn(1000,10000,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,e,v = torch.linalg.svd(torch.matmul(grad.T,grad),full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.3827)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.matmul(torch.matmul(u[:,0:1],u[:,0:1].T),grad[0,:]) + torch.mean(grad,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.matmul(torch.matmul(u[:,0:1],u[:,0:1].T),grad[0,:]) + torch.mean(grad,dim=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_one = np.ones((10,1))\n",
    "vec_zero = np.zeros((10,1))\n",
    "vec = np.concatenate((vec_one, vec_zero))\n",
    "d = 10\n",
    "ratio = 0.2\n",
    "d_spar = int(d*ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "vec = np.concatenate((vec_one[0:int(d*ratio),:], vec_zero[0:int(d*(1-ratio)),:]))\n",
    "idx = np.arange(d)\n",
    "np.random.shuffle(idx)\n",
    "print(vec[idx])\n",
    "vec = torch.from_numpy(vec)\n",
    "g = torch.randn(10,20)\n",
    "k = torch.mul(g,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5819e-01, -6.5063e-01, -2.0349e+00, -1.3852e-01, -3.7762e-01,\n",
       "         -9.6799e-02,  1.2074e+00, -1.1302e-02, -2.2296e+00, -3.9961e-01,\n",
       "          8.8514e-01,  3.4035e-01, -1.1760e+00,  8.4743e-02,  9.0022e-02,\n",
       "         -9.3739e-01, -1.2130e+00,  1.4451e+00,  6.3842e-01, -1.4925e-01],\n",
       "        [ 6.2461e-02, -1.7712e-01, -1.6414e+00,  2.4514e-01, -2.7001e-01,\n",
       "         -1.5674e-03, -1.9921e-01, -1.1502e+00, -9.3212e-01,  1.2633e+00,\n",
       "         -9.1727e-01, -2.4226e+00, -5.9763e-01,  6.3829e-01, -6.0692e-02,\n",
       "         -2.7511e-01,  4.3782e-01,  5.6128e-01, -4.5004e-01, -4.0466e-01],\n",
       "        [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
       "        [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "         -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,\n",
       "         -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "        [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "        [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahaichao/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_p = np.random.random(size=(1000, 1))\n",
    "Vk, _ = np.linalg.qr(random_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(Vk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk = torch.randn((1000,1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = torch.randn((1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = torch.rand((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1849, 0.8811, 0.2362, 0.8137, 0.2522],\n",
       "        [0.5763, 0.5645, 0.0388, 0.8097, 0.5277]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, ind = torch.topk(torch.abs(vp),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.zeros(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "v[0,ind[0,:]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_sparsify(flat_g, k=1):\n",
    "    _, ind = torch.topk(torch.abs(flat_g), k)\n",
    "    print(\"ind:\", ind)\n",
    "    vec = torch.zeros((flat_g.shape[0], flat_g.shape[1]))\n",
    "    #ind = torch.LongTensor(ind)\n",
    "    vec = vec.scatter(1, ind, 1)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.rand(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9576],\n",
       "        [0.5557],\n",
       "        [0.0688],\n",
       "        [0.2389],\n",
       "        [0.8963],\n",
       "        [0.6011],\n",
       "        [0.5256],\n",
       "        [0.7192],\n",
       "        [0.3803],\n",
       "        [0.4638]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx = np.arange(10)\n",
    "np.random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5557],\n",
       "        [0.0688],\n",
       "        [0.2389],\n",
       "        [0.8963],\n",
       "        [0.6011],\n",
       "        [0.5256],\n",
       "        [0.7192],\n",
       "        [0.3803],\n",
       "        [0.4638]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind: tensor([[0, 7],\n",
      "        [7, 6]])\n"
     ]
    }
   ],
   "source": [
    "vec = topk_sparsify(torch.abs(g),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8682, 0.0000, 0.0000, 0.0000,\n",
       "         0.8178],\n",
       "        [0.0000, 0.0000, 0.8116, 0.0000, 0.8721, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(vec,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpsgd",
   "language": "python",
   "name": "dpsgd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
